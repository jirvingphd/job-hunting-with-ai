{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Copy of adding-onet-integration (Made 06/24/24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import app_functions as af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume_fpath = 'data/James Irving Resume 2024.pdf'\n",
    "\n",
    "# job_fpath='data/Data Scientist - Focus School Software _ Remote.pdf'\n",
    "# job_fpath_simplyhired = \"data/SimplyHired-Data Scientist - Tech Holding _ Remote.pdf\"\n",
    "# job_fpath_indeed = 'data/Indeed-Data Science-Columbia.pdf'\n",
    "# job_fpath_linkedin = 'data/LinkedIn- AI & ML Engineer _ BDO USA _ LinkedIn.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['username', 'password'])\n"
     ]
    }
   ],
   "source": [
    "# Onet web services API credentials\n",
    "import json\n",
    "login_fpath = \"/Users/codingdojo/.secret/onet.json\"\n",
    "with open(login_fpath) as f:\n",
    "    login = json.load(f)\n",
    "    print(login.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"query\": \"Data Scientist\",\n",
      "      \"results\": [\n",
      "        {\n",
      "          \"code\": \"15-2051.00\",\n",
      "          \"title\": \"Data Scientists\"\n",
      "        },\n",
      "        {\n",
      "          \"code\": \"15-1221.00\",\n",
      "          \"title\": \"Computer and Information Research Scientists\"\n",
      "        },\n",
      "        {\n",
      "          \"code\": \"19-4061.00\",\n",
      "          \"title\": \"Social Science Research Assistants\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"query\": \"Data Analyst\",\n",
      "      \"results\": [\n",
      "        {\n",
      "          \"code\": \"15-2051.00\",\n",
      "          \"title\": \"Data Scientists\"\n",
      "        },\n",
      "        {\n",
      "          \"code\": \"15-2051.01\",\n",
      "          \"title\": \"Business Intelligence Analysts\"\n",
      "        },\n",
      "        {\n",
      "          \"code\": \"13-2099.01\",\n",
      "          \"title\": \"Financial Quantitative Analysts\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"query\": \"AI Engineer\",\n",
      "      \"results\": [\n",
      "        {\n",
      "          \"code\": \"15-1221.00\",\n",
      "          \"title\": \"Computer and Information Research Scientists\"\n",
      "        },\n",
      "        {\n",
      "          \"code\": \"15-1299.05\",\n",
      "          \"title\": \"Information Security Engineers\"\n",
      "        },\n",
      "        {\n",
      "          \"code\": \"15-1252.00\",\n",
      "          \"title\": \"Software Developers\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}"
     ]
    }
   ],
   "source": [
    "## Starting code example\n",
    "# SOURCE: https://github.com/onetcenter/web-services-samples/blob/master/python-3/batch_coder.py\n",
    "#!python3\n",
    "# from OnetWebService import OnetWebService\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "# read JSON input\n",
    "# input = json.load(sys.stdin)\n",
    "config = {'max_results':3, }\n",
    "queries = ['Data Scientist','Data Analyst','AI Engineer']\n",
    "\n",
    "\n",
    "# initialize Web Services and results objects\n",
    "onet_ws = af.OnetWebService(login['username'], login['password'])#input['config']['username'], input['config']['password'])\n",
    "max_results = max(1, config['max_results'])\n",
    "output = { 'output': [] }\n",
    "\n",
    "\n",
    "# call keyword search for each input query\n",
    "for q in queries:#input['queries']:\n",
    "    res = []\n",
    "    kwresults = onet_ws.call('online/search',\n",
    "                             ('keyword', q),\n",
    "                             ('end', max_results))\n",
    "    time.sleep(.020)\n",
    "    if ('occupation' in kwresults) and (0 < len(kwresults['occupation'])):\n",
    "        for occ in kwresults['occupation']:\n",
    "            res.append({ 'code': occ['code'], 'title': occ['title'] })\n",
    "    output['output'].append({ 'query': q, 'results': res })\n",
    "\n",
    "json.dump(output, sys.stdout, indent=2, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'Data Scientist',\n",
       "  'results': [{'code': '15-2051.00', 'title': 'Data Scientists'},\n",
       "   {'code': '15-1221.00',\n",
       "    'title': 'Computer and Information Research Scientists'},\n",
       "   {'code': '19-4061.00', 'title': 'Social Science Research Assistants'},\n",
       "   {'code': '19-1029.01', 'title': 'Bioinformatics Scientists'},\n",
       "   {'code': '15-2099.01', 'title': 'Bioinformatics Technicians'}]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import time\n",
    "# from OnetWebService import OnetWebService\n",
    "\n",
    "def onet_keyword_search(login, config, queries):\n",
    "    \"\"\"\n",
    "    Perform a keyword search using the OnetWebService.\n",
    "\n",
    "    Args:\n",
    "        login (dict): A dictionary containing the login credentials for the OnetWebService.\n",
    "                      It should have 'username' and 'password' keys.\n",
    "        config (dict): A dictionary containing configuration options for the keyword search.\n",
    "                       It should have a 'max_results' key specifying the maximum number of results to retrieve.\n",
    "        queries (list): A list of queries to perform the keyword search on.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Side Effects:\n",
    "        Prints the search results in JSON format to the standard output.\n",
    "\n",
    "    \"\"\"\n",
    "    # initialize Web Services and results objects\n",
    "    onet_ws = af.OnetWebService(login['username'], login['password'])\n",
    "    max_results = max(1, config['max_results'])\n",
    "    output = { 'output': [],\n",
    "               'config': config,\n",
    "               'queries': queries}\n",
    "\n",
    "    # call keyword search for each input query\n",
    "    for q in queries:\n",
    "        res = []\n",
    "        kwresults = onet_ws.call('online/search',\n",
    "                                 ('keyword', q),\n",
    "                                 ('end', max_results))\n",
    "        time.sleep(.020)\n",
    "        if ('occupation' in kwresults) and (0 < len(kwresults['occupation'])):\n",
    "            for occ in kwresults['occupation']:\n",
    "                res.append({ 'code': occ['code'], 'title': occ['title'] })\n",
    "        output['output'].append({ 'query': q, 'results': res })\n",
    "\n",
    "    # json.dump(output, sys.stdout, indent=2, sort_keys=True)\n",
    "    return output\n",
    "    \n",
    "\n",
    "# usage\n",
    "# login = {'username': 'your_username', 'password': 'your_password'}\n",
    "config = {'max_results':5}\n",
    "queries = ['Data Scientist']#,'AI Engineer']\n",
    "job_results = onet_keyword_search(login, config, queries)\n",
    "job_results['output']#['results']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which Services to Use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- List of full services in API: https://services.onetcenter.org/reference/#full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Have ChatGPT use the resume or job listing to extract the job title.\n",
    "2. Call Onet services to get list of top X related results. \n",
    "    - Results include name and job code.\n",
    "3. Use job code to look up overview. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing Job Occupation Report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def onet_occupation_report(login,  job_code):\n",
    "    \"\"\"\n",
    "    Perform a keyword search using the OnetWebService.\n",
    "\n",
    "    Args:\n",
    "        login (dict): A dictionary containing the login credentials for the OnetWebService.\n",
    "                      It should have 'username' and 'password' keys.\n",
    "        config (dict): A dictionary containing configuration options for the keyword search.\n",
    "                       It should have a 'max_results' key specifying the maximum number of results to retrieve.\n",
    "        queries (list): A list of queries to perform the keyword search on.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Side Effects:\n",
    "        Prints the search results in JSON format to the standard output.\n",
    "\n",
    "    \"\"\"\n",
    "    # queries = [job_code]\n",
    "    # initialize Web Services and results objects\n",
    "    onet_ws = af.OnetWebService(login['username'], login['password'])\n",
    "    # max_results = #max(1, config['max_results'])\n",
    "    # output = { 'output': [],\n",
    "    #         #    'config': dict(max_results=max_results),\n",
    "    #            'query': job_code\n",
    "    #            }\n",
    "\n",
    "    # call keyword search for each input query\n",
    "    # for q in queries:\n",
    "        # res = []\n",
    "        # kwresults = onet_ws.call('online/occupations',\n",
    "        #                          ('keyword', q),\n",
    "        #                          ('end', max_results))\n",
    "    report = onet_ws.occupation_report(job_code)\n",
    "    # output['output'] = report\n",
    "        # if ('occupation' in kwresults) and (0 < len(kwresults['occupation'])):\n",
    "        #     for occ in kwresults['occupation']:\n",
    "        #         res.append({ 'code': occ['code'], 'title': occ['title'] })\n",
    "        # output['output'].append({ 'query': q, 'results': res })\n",
    "\n",
    "    # json.dump(output, sys.stdout, indent=2, sort_keys=True)\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://services.onetcenter.org/ws/online/occupations/15-2051.00/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occupation_base_url = \"https://services.onetcenter.org/ws/online/occupations/{job_code}/\"\n",
    "occupation_base_url.format(job_code=\"15-2051.00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': '15-2051.00', 'title': 'Data Scientists'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_code_results = job_results['output'][0]['results']#[0]['code']\n",
    "test_result = job_code_results[0]\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': '15-2051.00',\n",
       " 'title': 'Data Scientists',\n",
       " 'tags': {'bright_outlook': True, 'green': False},\n",
       " 'description': 'Develop and implement a set of techniques or analytics applications to transform raw data into meaningful information using data-oriented programming languages and visualization software. Apply data mining, data modeling, natural language processing, and machine learning to extract and analyze information from large structured and unstructured datasets. Visualize, interpret, and report data findings. May create dynamic data reports.',\n",
       " 'also_see': {'occupation': [{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.01/',\n",
       "    'code': '15-2051.01',\n",
       "    'title': 'Business Intelligence Analysts',\n",
       "    'tags': {'bright_outlook': True, 'green': False}},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.02/',\n",
       "    'code': '15-2051.02',\n",
       "    'title': 'Clinical Data Managers',\n",
       "    'tags': {'bright_outlook': True, 'green': False}}]},\n",
       " 'updated': {'partial': True,\n",
       "  'year': 2024,\n",
       "  'resource_updated': [{'title': 'Abilities'},\n",
       "   {'title': 'Alternate Titles', 'source': 'Multiple sources', 'year': 2023},\n",
       "   {'title': 'Detailed Work Activities', 'source': 'Analyst', 'year': 2020},\n",
       "   {'title': 'Education'},\n",
       "   {'title': 'Interests', 'source': 'Machine Learning', 'year': 2023},\n",
       "   {'title': 'Job Zone', 'source': 'Analyst - Preliminary', 'year': 2021},\n",
       "   {'title': 'Knowledge'},\n",
       "   {'title': 'Sample of Reported Titles'},\n",
       "   {'title': 'Skills'},\n",
       "   {'title': 'Tasks', 'source': 'Analyst', 'year': 2020},\n",
       "   {'title': 'Technology Skills & Tools', 'source': 'Analyst', 'year': 2024},\n",
       "   {'title': 'Work Activities'},\n",
       "   {'title': 'Work Context'},\n",
       "   {'title': 'Work Needs'},\n",
       "   {'title': 'Work Styles'},\n",
       "   {'title': 'Work Values'}]},\n",
       " 'bright_outlook': {'description': 'This occupation is expected to grow rapidly.',\n",
       "  'category': ['Grow Rapidly']},\n",
       " 'summary_resources': {'resource': [{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/tasks',\n",
       "    'title': 'Tasks'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/technology_skills',\n",
       "    'title': 'Technology Skills'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/tools_technology',\n",
       "    'title': 'Tools &amp; Technology'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/detailed_work_activities',\n",
       "    'title': 'Detailed Work Activities'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/job_zone',\n",
       "    'title': 'Job Zone'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/interests',\n",
       "    'title': 'Interests'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/related_occupations',\n",
       "    'title': 'Related Occupations'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/additional_information',\n",
       "    'title': 'Sources of Additional Information'}]},\n",
       " 'details_resources': {'resource': [{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/tasks',\n",
       "    'title': 'Tasks'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/technology_skills',\n",
       "    'title': 'Technology Skills'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/tools_technology',\n",
       "    'title': 'Tools &amp; Technology'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/detailed_work_activities',\n",
       "    'title': 'Detailed Work Activities'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/job_zone',\n",
       "    'title': 'Job Zone'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/interests',\n",
       "    'title': 'Interests'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/related_occupations',\n",
       "    'title': 'Related Occupations'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/additional_information',\n",
       "    'title': 'Sources of Additional Information'}]},\n",
       " 'custom_resources': {'resource': [{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/custom/work_activities_outline',\n",
       "    'title': 'Work Activities Outline'}]}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = onet_occupation_report(login, job_code=test_result['code'])\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['code', 'title', 'tags', 'description', 'also_see', 'updated', 'bright_outlook', 'summary_resources', 'details_resources', 'custom_resources'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing report results\n",
    "# report = results_report['output']\n",
    "report.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "      <th>description</th>\n",
       "      <th>also_see</th>\n",
       "      <th>updated</th>\n",
       "      <th>bright_outlook</th>\n",
       "      <th>summary_resources</th>\n",
       "      <th>details_resources</th>\n",
       "      <th>custom_resources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bright_outlook</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>True</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>green</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>False</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td></td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>[{'href': 'https://services.onetcenter.org/ws/...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td></td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td></td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td></td>\n",
       "      <td>2024</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resource_updated</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td></td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td></td>\n",
       "      <td>[{'title': 'Abilities'}, {'title': 'Alternate ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td></td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>This occupation is expected to grow rapidly.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td></td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[Grow Rapidly]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resource</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td></td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'href': 'https://services.onetcenter.org/ws/...</td>\n",
       "      <td>[{'href': 'https://services.onetcenter.org/ws/...</td>\n",
       "      <td>[{'href': 'https://services.onetcenter.org/ws/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        code            title   tags  \\\n",
       "bright_outlook    15-2051.00  Data Scientists   True   \n",
       "green             15-2051.00  Data Scientists  False   \n",
       "occupation        15-2051.00  Data Scientists          \n",
       "partial           15-2051.00  Data Scientists          \n",
       "year              15-2051.00  Data Scientists          \n",
       "resource_updated  15-2051.00  Data Scientists          \n",
       "description       15-2051.00  Data Scientists          \n",
       "category          15-2051.00  Data Scientists          \n",
       "resource          15-2051.00  Data Scientists          \n",
       "\n",
       "                                                        description  \\\n",
       "bright_outlook    Develop and implement a set of techniques or a...   \n",
       "green             Develop and implement a set of techniques or a...   \n",
       "occupation        Develop and implement a set of techniques or a...   \n",
       "partial           Develop and implement a set of techniques or a...   \n",
       "year              Develop and implement a set of techniques or a...   \n",
       "resource_updated  Develop and implement a set of techniques or a...   \n",
       "description       Develop and implement a set of techniques or a...   \n",
       "category          Develop and implement a set of techniques or a...   \n",
       "resource          Develop and implement a set of techniques or a...   \n",
       "\n",
       "                                                           also_see  \\\n",
       "bright_outlook                                                        \n",
       "green                                                                 \n",
       "occupation        [{'href': 'https://services.onetcenter.org/ws/...   \n",
       "partial                                                               \n",
       "year                                                                  \n",
       "resource_updated                                                      \n",
       "description                                                           \n",
       "category                                                              \n",
       "resource                                                              \n",
       "\n",
       "                                                            updated  \\\n",
       "bright_outlook                                                        \n",
       "green                                                                 \n",
       "occupation                                                            \n",
       "partial                                                        True   \n",
       "year                                                           2024   \n",
       "resource_updated  [{'title': 'Abilities'}, {'title': 'Alternate ...   \n",
       "description                                                           \n",
       "category                                                              \n",
       "resource                                                              \n",
       "\n",
       "                                                bright_outlook  \\\n",
       "bright_outlook                                                   \n",
       "green                                                            \n",
       "occupation                                                       \n",
       "partial                                                          \n",
       "year                                                             \n",
       "resource_updated                                                 \n",
       "description       This occupation is expected to grow rapidly.   \n",
       "category                                        [Grow Rapidly]   \n",
       "resource                                                         \n",
       "\n",
       "                                                  summary_resources  \\\n",
       "bright_outlook                                                        \n",
       "green                                                                 \n",
       "occupation                                                            \n",
       "partial                                                               \n",
       "year                                                                  \n",
       "resource_updated                                                      \n",
       "description                                                           \n",
       "category                                                              \n",
       "resource          [{'href': 'https://services.onetcenter.org/ws/...   \n",
       "\n",
       "                                                  details_resources  \\\n",
       "bright_outlook                                                        \n",
       "green                                                                 \n",
       "occupation                                                            \n",
       "partial                                                               \n",
       "year                                                                  \n",
       "resource_updated                                                      \n",
       "description                                                           \n",
       "category                                                              \n",
       "resource          [{'href': 'https://services.onetcenter.org/ws/...   \n",
       "\n",
       "                                                   custom_resources  \n",
       "bright_outlook                                                       \n",
       "green                                                                \n",
       "occupation                                                           \n",
       "partial                                                              \n",
       "year                                                                 \n",
       "resource_updated                                                     \n",
       "description                                                          \n",
       "category                                                             \n",
       "resource          [{'href': 'https://services.onetcenter.org/ws/...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Checking report as a dataframe\n",
    "report_df = pd.DataFrame(report).fillna('')\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code:\n",
      "    15-2051.00\n",
      "title:\n",
      "    Data Scientists\n",
      "tags:\n",
      "    {'bright_outlook': True, 'green': False}\n",
      "description:\n",
      "    Develop and implement a set of techniques or analytics applications to transform raw data into meaningful information using data-oriented programming languages and visualization software. Apply data mining, data modeling, natural language processing, and machine learning to extract and analyze information from large structured and unstructured datasets. Visualize, interpret, and report data findings. May create dynamic data reports.\n",
      "also_see:\n",
      "    {'occupation': [{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.01/', 'code': '15-2051.01', 'title': 'Business Intelligence Analysts', 'tags': {'bright_outlook': True, 'green': False}}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.02/', 'code': '15-2051.02', 'title': 'Clinical Data Managers', 'tags': {'bright_outlook': True, 'green': False}}]}\n",
      "updated:\n",
      "    {'partial': True, 'year': 2024, 'resource_updated': [{'title': 'Abilities'}, {'title': 'Alternate Titles', 'source': 'Multiple sources', 'year': 2023}, {'title': 'Detailed Work Activities', 'source': 'Analyst', 'year': 2020}, {'title': 'Education'}, {'title': 'Interests', 'source': 'Machine Learning', 'year': 2023}, {'title': 'Job Zone', 'source': 'Analyst - Preliminary', 'year': 2021}, {'title': 'Knowledge'}, {'title': 'Sample of Reported Titles'}, {'title': 'Skills'}, {'title': 'Tasks', 'source': 'Analyst', 'year': 2020}, {'title': 'Technology Skills & Tools', 'source': 'Analyst', 'year': 2024}, {'title': 'Work Activities'}, {'title': 'Work Context'}, {'title': 'Work Needs'}, {'title': 'Work Styles'}, {'title': 'Work Values'}]}\n",
      "bright_outlook:\n",
      "    {'description': 'This occupation is expected to grow rapidly.', 'category': ['Grow Rapidly']}\n",
      "summary_resources:\n",
      "    {'resource': [{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/tasks', 'title': 'Tasks'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/technology_skills', 'title': 'Technology Skills'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/tools_technology', 'title': 'Tools &amp; Technology'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/detailed_work_activities', 'title': 'Detailed Work Activities'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/job_zone', 'title': 'Job Zone'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/interests', 'title': 'Interests'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/related_occupations', 'title': 'Related Occupations'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/additional_information', 'title': 'Sources of Additional Information'}]}\n",
      "details_resources:\n",
      "    {'resource': [{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/tasks', 'title': 'Tasks'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/technology_skills', 'title': 'Technology Skills'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/tools_technology', 'title': 'Tools &amp; Technology'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/detailed_work_activities', 'title': 'Detailed Work Activities'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/job_zone', 'title': 'Job Zone'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/interests', 'title': 'Interests'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/related_occupations', 'title': 'Related Occupations'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/additional_information', 'title': 'Sources of Additional Information'}]}\n",
      "custom_resources:\n",
      "    {'resource': [{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/custom/work_activities_outline', 'title': 'Work Activities Outline'}]}\n"
     ]
    }
   ],
   "source": [
    "# Printing report\n",
    "for k,v in report.items():\n",
    "    print(f\"{k}:\\n    {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta_keys=['code', 'title', 'description']\n",
      "list_keys=[]\n",
      "dict_keys=['tags', 'also_see', 'updated', 'bright_outlook', 'summary_resources', 'details_resources', 'custom_resources']\n"
     ]
    }
   ],
   "source": [
    "# Separating the keys by type\n",
    "meta_keys = [k for k,v in report.items() if isinstance(v, str)]\n",
    "list_keys = [k for k,v in report.items() if isinstance(v, list)]\n",
    "dict_keys = [k for k,v in report.items() if isinstance(v, dict)]\n",
    "\n",
    "print(f\"{meta_keys=}\\n{list_keys=}\\n{dict_keys=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags:\n",
      "    dict_keys(['bright_outlook', 'green'])\n",
      "also_see:\n",
      "    dict_keys(['occupation'])\n",
      "updated:\n",
      "    dict_keys(['partial', 'year', 'resource_updated'])\n",
      "bright_outlook:\n",
      "    dict_keys(['description', 'category'])\n",
      "summary_resources:\n",
      "    dict_keys(['resource'])\n",
      "details_resources:\n",
      "    dict_keys(['resource'])\n",
      "custom_resources:\n",
      "    dict_keys(['resource'])\n"
     ]
    }
   ],
   "source": [
    "for k in dict_keys:\n",
    "    print(f\"{k}:\\n    {report[k].keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dont use type to separate, separate by resources ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['summary_resources', 'details_resources', 'custom_resources']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resource_keys = [k for k in report if 'resource' in k.lower()]\n",
    "resource_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/tasks',\n",
       "  'title': 'Tasks'},\n",
       " {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/technology_skills',\n",
       "  'title': 'Technology Skills'},\n",
       " {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/tools_technology',\n",
       "  'title': 'Tools &amp; Technology'},\n",
       " {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/detailed_work_activities',\n",
       "  'title': 'Detailed Work Activities'},\n",
       " {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/job_zone',\n",
       "  'title': 'Job Zone'},\n",
       " {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/interests',\n",
       "  'title': 'Interests'},\n",
       " {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/related_occupations',\n",
       "  'title': 'Related Occupations'},\n",
       " {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/additional_information',\n",
       "  'title': 'Sources of Additional Information'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report[resource_keys[0]]['resource']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/tasks', 'title': 'Tasks'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/technology_skills', 'title': 'Technology Skills'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/tools_technology', 'title': 'Tools &amp; Technology'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/detailed_work_activities', 'title': 'Detailed Work Activities'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/job_zone', 'title': 'Job Zone'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/interests', 'title': 'Interests'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/related_occupations', 'title': 'Related Occupations'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/additional_information', 'title': 'Sources of Additional Information'}\n",
      "\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/tasks', 'title': 'Tasks'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/technology_skills', 'title': 'Technology Skills'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/tools_technology', 'title': 'Tools &amp; Technology'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/detailed_work_activities', 'title': 'Detailed Work Activities'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/job_zone', 'title': 'Job Zone'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/interests', 'title': 'Interests'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/related_occupations', 'title': 'Related Occupations'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/additional_information', 'title': 'Sources of Additional Information'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_resources = report['summary_resources']['resource']\n",
    "detail_resources = report['details_resources']['resource']\n",
    "\n",
    "[print(k) for k in summary_resources]\n",
    "print()\n",
    "[print(k) for k in detail_resources]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>href</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tasks</th>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology Skills</th>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tools &amp;amp; Technology</th>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Detailed Work Activities</th>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Zone</th>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interests</th>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Related Occupations</th>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sources of Additional Information</th>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                href\n",
       "title                                                                               \n",
       "Tasks                              https://services.onetcenter.org/ws/online/occu...\n",
       "Technology Skills                  https://services.onetcenter.org/ws/online/occu...\n",
       "Tools &amp; Technology             https://services.onetcenter.org/ws/online/occu...\n",
       "Detailed Work Activities           https://services.onetcenter.org/ws/online/occu...\n",
       "Job Zone                           https://services.onetcenter.org/ws/online/occu...\n",
       "Interests                          https://services.onetcenter.org/ws/online/occu...\n",
       "Related Occupations                https://services.onetcenter.org/ws/online/occu...\n",
       "Sources of Additional Information  https://services.onetcenter.org/ws/online/occu..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "resources_df = pd.DataFrame(detail_resources)\n",
    "resources_df = resources_df.set_index(\"title\")\n",
    "resources_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing/Controlling Report DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>bright_outlook</th>\n",
       "      <th>green</th>\n",
       "      <th>resource type</th>\n",
       "      <th>resource title</th>\n",
       "      <th>href</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Tasks</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Technology Skills</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Tools &amp;amp; Technology</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Detailed Work Activities</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Job Zone</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Interests</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Related Occupations</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Sources of Additional Information</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Tasks</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Technology Skills</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Tools &amp;amp; Technology</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Detailed Work Activities</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Job Zone</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Interests</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Related Occupations</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Sources of Additional Information</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>custom_resources</td>\n",
       "      <td>Work Activities Outline</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          code            title  \\\n",
       "0   15-2051.00  Data Scientists   \n",
       "1   15-2051.00  Data Scientists   \n",
       "2   15-2051.00  Data Scientists   \n",
       "3   15-2051.00  Data Scientists   \n",
       "4   15-2051.00  Data Scientists   \n",
       "5   15-2051.00  Data Scientists   \n",
       "6   15-2051.00  Data Scientists   \n",
       "7   15-2051.00  Data Scientists   \n",
       "8   15-2051.00  Data Scientists   \n",
       "9   15-2051.00  Data Scientists   \n",
       "10  15-2051.00  Data Scientists   \n",
       "11  15-2051.00  Data Scientists   \n",
       "12  15-2051.00  Data Scientists   \n",
       "13  15-2051.00  Data Scientists   \n",
       "14  15-2051.00  Data Scientists   \n",
       "15  15-2051.00  Data Scientists   \n",
       "16  15-2051.00  Data Scientists   \n",
       "\n",
       "                                          description  bright_outlook  green  \\\n",
       "0   Develop and implement a set of techniques or a...            True  False   \n",
       "1   Develop and implement a set of techniques or a...            True  False   \n",
       "2   Develop and implement a set of techniques or a...            True  False   \n",
       "3   Develop and implement a set of techniques or a...            True  False   \n",
       "4   Develop and implement a set of techniques or a...            True  False   \n",
       "5   Develop and implement a set of techniques or a...            True  False   \n",
       "6   Develop and implement a set of techniques or a...            True  False   \n",
       "7   Develop and implement a set of techniques or a...            True  False   \n",
       "8   Develop and implement a set of techniques or a...            True  False   \n",
       "9   Develop and implement a set of techniques or a...            True  False   \n",
       "10  Develop and implement a set of techniques or a...            True  False   \n",
       "11  Develop and implement a set of techniques or a...            True  False   \n",
       "12  Develop and implement a set of techniques or a...            True  False   \n",
       "13  Develop and implement a set of techniques or a...            True  False   \n",
       "14  Develop and implement a set of techniques or a...            True  False   \n",
       "15  Develop and implement a set of techniques or a...            True  False   \n",
       "16  Develop and implement a set of techniques or a...            True  False   \n",
       "\n",
       "        resource type                     resource title  \\\n",
       "0   summary_resources                              Tasks   \n",
       "1   summary_resources                  Technology Skills   \n",
       "2   summary_resources             Tools &amp; Technology   \n",
       "3   summary_resources           Detailed Work Activities   \n",
       "4   summary_resources                           Job Zone   \n",
       "5   summary_resources                          Interests   \n",
       "6   summary_resources                Related Occupations   \n",
       "7   summary_resources  Sources of Additional Information   \n",
       "8   details_resources                              Tasks   \n",
       "9   details_resources                  Technology Skills   \n",
       "10  details_resources             Tools &amp; Technology   \n",
       "11  details_resources           Detailed Work Activities   \n",
       "12  details_resources                           Job Zone   \n",
       "13  details_resources                          Interests   \n",
       "14  details_resources                Related Occupations   \n",
       "15  details_resources  Sources of Additional Information   \n",
       "16   custom_resources            Work Activities Outline   \n",
       "\n",
       "                                                 href  \n",
       "0   https://services.onetcenter.org/ws/online/occu...  \n",
       "1   https://services.onetcenter.org/ws/online/occu...  \n",
       "2   https://services.onetcenter.org/ws/online/occu...  \n",
       "3   https://services.onetcenter.org/ws/online/occu...  \n",
       "4   https://services.onetcenter.org/ws/online/occu...  \n",
       "5   https://services.onetcenter.org/ws/online/occu...  \n",
       "6   https://services.onetcenter.org/ws/online/occu...  \n",
       "7   https://services.onetcenter.org/ws/online/occu...  \n",
       "8   https://services.onetcenter.org/ws/online/occu...  \n",
       "9   https://services.onetcenter.org/ws/online/occu...  \n",
       "10  https://services.onetcenter.org/ws/online/occu...  \n",
       "11  https://services.onetcenter.org/ws/online/occu...  \n",
       "12  https://services.onetcenter.org/ws/online/occu...  \n",
       "13  https://services.onetcenter.org/ws/online/occu...  \n",
       "14  https://services.onetcenter.org/ws/online/occu...  \n",
       "15  https://services.onetcenter.org/ws/online/occu...  \n",
       "16  https://services.onetcenter.org/ws/online/occu...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with columns for resources\n",
    "report_prep = [('resource type','resource title','href')]\n",
    "\n",
    "for k in  resource_keys:\n",
    "    \n",
    "    resources = report[k]['resource']\n",
    "    \n",
    "    for r in resources:\n",
    "        report_prep.append([k, r['title'], r['href']])\n",
    "        \n",
    "    # temp_df = pd.DataFrame(report[k]['resource'])\n",
    "    # temp_df.insert(0,'resource type',k)\n",
    "    # report_prep.append(temp_df)#.fillna('')\n",
    "\n",
    "# report_df = pd.DataFrame(report_prep).fillna('')\n",
    "# report_df\n",
    "\n",
    "\n",
    "# resources_df = pd.concat(report_prep)\n",
    "# resources_df = resources_df.set_index(['resource type','title'])\n",
    "# resources_df\n",
    "\n",
    "# Make into a DataFrame\n",
    "resources_df = pd.DataFrame(report_prep[1:], columns=report_prep[0])\n",
    "resources_cols = resources_df.columns\n",
    "\n",
    "\n",
    "# Insert the meta keys as columns\n",
    "info_cols = []\n",
    "for k in meta_keys:\n",
    "    #report_prep.append([k, report[k]])\n",
    "    resources_df[k] = report[k]\n",
    "    info_cols.append(k)\n",
    "    \n",
    "    \n",
    "for k in report['tags']:\n",
    "    resources_df[k] = report['tags'][k]\n",
    "    info_cols.append(k)\n",
    "\n",
    "    \n",
    "    \n",
    "resources_df = resources_df[[*info_cols, *resources_df.drop(columns=info_cols).columns]]\n",
    "resources_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tags', 'also_see', 'updated', 'bright_outlook']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_keys =  [k for k in report.keys() if k not in resource_keys and k not in meta_keys]\n",
    "remaining_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags:\n",
      "    {'bright_outlook': True, 'green': False}\n",
      "also_see:\n",
      "    {'occupation': [{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.01/', 'code': '15-2051.01', 'title': 'Business Intelligence Analysts', 'tags': {'bright_outlook': True, 'green': False}}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.02/', 'code': '15-2051.02', 'title': 'Clinical Data Managers', 'tags': {'bright_outlook': True, 'green': False}}]}\n",
      "updated:\n",
      "    {'partial': True, 'year': 2024, 'resource_updated': [{'title': 'Abilities'}, {'title': 'Alternate Titles', 'source': 'Multiple sources', 'year': 2023}, {'title': 'Detailed Work Activities', 'source': 'Analyst', 'year': 2020}, {'title': 'Education'}, {'title': 'Interests', 'source': 'Machine Learning', 'year': 2023}, {'title': 'Job Zone', 'source': 'Analyst - Preliminary', 'year': 2021}, {'title': 'Knowledge'}, {'title': 'Sample of Reported Titles'}, {'title': 'Skills'}, {'title': 'Tasks', 'source': 'Analyst', 'year': 2020}, {'title': 'Technology Skills & Tools', 'source': 'Analyst', 'year': 2024}, {'title': 'Work Activities'}, {'title': 'Work Context'}, {'title': 'Work Needs'}, {'title': 'Work Styles'}, {'title': 'Work Values'}]}\n",
      "bright_outlook:\n",
      "    {'description': 'This occupation is expected to grow rapidly.', 'category': ['Grow Rapidly']}\n"
     ]
    }
   ],
   "source": [
    "for k in remaining_keys:\n",
    "    print(f\"{k}:\\n    {report[k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'occupation': [{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.01/',\n",
       "   'code': '15-2051.01',\n",
       "   'title': 'Business Intelligence Analysts',\n",
       "   'tags': {'bright_outlook': True, 'green': False}},\n",
       "  {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.02/',\n",
       "   'code': '15-2051.02',\n",
       "   'title': 'Clinical Data Managers',\n",
       "   'tags': {'bright_outlook': True, 'green': False}}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report['also_see']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rf/vw4r41jd7vd95x1w0dth7v9h0000gp/T/ipykernel_4750/4012382594.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  also_see_df[info_cols] = resources_df[info_cols].iloc[0]\n",
      "/var/folders/rf/vw4r41jd7vd95x1w0dth7v9h0000gp/T/ipykernel_4750/4012382594.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  also_see_df[info_cols] = resources_df[info_cols].iloc[0]\n",
      "/var/folders/rf/vw4r41jd7vd95x1w0dth7v9h0000gp/T/ipykernel_4750/4012382594.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  also_see_df[info_cols] = resources_df[info_cols].iloc[0]\n",
      "/var/folders/rf/vw4r41jd7vd95x1w0dth7v9h0000gp/T/ipykernel_4750/4012382594.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  also_see_df[info_cols] = resources_df[info_cols].iloc[0]\n",
      "/var/folders/rf/vw4r41jd7vd95x1w0dth7v9h0000gp/T/ipykernel_4750/4012382594.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  also_see_df[info_cols] = resources_df[info_cols].iloc[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>href</th>\n",
       "      <th>also_see_code</th>\n",
       "      <th>resource title</th>\n",
       "      <th>tags</th>\n",
       "      <th>resource type</th>\n",
       "      <th>code</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>bright_outlook</th>\n",
       "      <th>green</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>15-2051.01</td>\n",
       "      <td>Business Intelligence Analysts</td>\n",
       "      <td>{'bright_outlook': True, 'green': False}</td>\n",
       "      <td>also see</td>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>15-2051.02</td>\n",
       "      <td>Clinical Data Managers</td>\n",
       "      <td>{'bright_outlook': True, 'green': False}</td>\n",
       "      <td>also see</td>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                href also_see_code  \\\n",
       "0  https://services.onetcenter.org/ws/online/occu...    15-2051.01   \n",
       "1  https://services.onetcenter.org/ws/online/occu...    15-2051.02   \n",
       "\n",
       "                   resource title                                      tags  \\\n",
       "0  Business Intelligence Analysts  {'bright_outlook': True, 'green': False}   \n",
       "1          Clinical Data Managers  {'bright_outlook': True, 'green': False}   \n",
       "\n",
       "  resource type        code            title  \\\n",
       "0      also see  15-2051.00  Data Scientists   \n",
       "1      also see  15-2051.00  Data Scientists   \n",
       "\n",
       "                                         description  bright_outlook  green  \n",
       "0  Develop and implement a set of techniques or a...            True  False  \n",
       "1  Develop and implement a set of techniques or a...            True  False  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "also_see_df = pd.DataFrame(report['also_see']['occupation'])\n",
    "also_see_df = also_see_df.rename({'code':'also_see_code','title':'resource title'}, axis=1)\n",
    "also_see_df['resource type'] = 'also see'\n",
    "also_see_df[info_cols] = resources_df[info_cols].iloc[0]\n",
    "also_see_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resources_df[info_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>bright_outlook</th>\n",
       "      <th>green</th>\n",
       "      <th>resource type</th>\n",
       "      <th>resource title</th>\n",
       "      <th>href</th>\n",
       "      <th>also_see_code</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Tasks</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Technology Skills</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Tools &amp;amp; Technology</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Detailed Work Activities</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Job Zone</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Interests</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Related Occupations</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Sources of Additional Information</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Tasks</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Technology Skills</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Tools &amp;amp; Technology</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Detailed Work Activities</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Job Zone</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Interests</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Related Occupations</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Sources of Additional Information</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>custom_resources</td>\n",
       "      <td>Work Activities Outline</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>also see</td>\n",
       "      <td>Business Intelligence Analysts</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>15-2051.01</td>\n",
       "      <td>{'bright_outlook': True, 'green': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>also see</td>\n",
       "      <td>Clinical Data Managers</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>15-2051.02</td>\n",
       "      <td>{'bright_outlook': True, 'green': False}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          code            title  \\\n",
       "0   15-2051.00  Data Scientists   \n",
       "1   15-2051.00  Data Scientists   \n",
       "2   15-2051.00  Data Scientists   \n",
       "3   15-2051.00  Data Scientists   \n",
       "4   15-2051.00  Data Scientists   \n",
       "5   15-2051.00  Data Scientists   \n",
       "6   15-2051.00  Data Scientists   \n",
       "7   15-2051.00  Data Scientists   \n",
       "8   15-2051.00  Data Scientists   \n",
       "9   15-2051.00  Data Scientists   \n",
       "10  15-2051.00  Data Scientists   \n",
       "11  15-2051.00  Data Scientists   \n",
       "12  15-2051.00  Data Scientists   \n",
       "13  15-2051.00  Data Scientists   \n",
       "14  15-2051.00  Data Scientists   \n",
       "15  15-2051.00  Data Scientists   \n",
       "16  15-2051.00  Data Scientists   \n",
       "0   15-2051.00  Data Scientists   \n",
       "1   15-2051.00  Data Scientists   \n",
       "\n",
       "                                          description  bright_outlook  green  \\\n",
       "0   Develop and implement a set of techniques or a...            True  False   \n",
       "1   Develop and implement a set of techniques or a...            True  False   \n",
       "2   Develop and implement a set of techniques or a...            True  False   \n",
       "3   Develop and implement a set of techniques or a...            True  False   \n",
       "4   Develop and implement a set of techniques or a...            True  False   \n",
       "5   Develop and implement a set of techniques or a...            True  False   \n",
       "6   Develop and implement a set of techniques or a...            True  False   \n",
       "7   Develop and implement a set of techniques or a...            True  False   \n",
       "8   Develop and implement a set of techniques or a...            True  False   \n",
       "9   Develop and implement a set of techniques or a...            True  False   \n",
       "10  Develop and implement a set of techniques or a...            True  False   \n",
       "11  Develop and implement a set of techniques or a...            True  False   \n",
       "12  Develop and implement a set of techniques or a...            True  False   \n",
       "13  Develop and implement a set of techniques or a...            True  False   \n",
       "14  Develop and implement a set of techniques or a...            True  False   \n",
       "15  Develop and implement a set of techniques or a...            True  False   \n",
       "16  Develop and implement a set of techniques or a...            True  False   \n",
       "0   Develop and implement a set of techniques or a...            True  False   \n",
       "1   Develop and implement a set of techniques or a...            True  False   \n",
       "\n",
       "        resource type                     resource title  \\\n",
       "0   summary_resources                              Tasks   \n",
       "1   summary_resources                  Technology Skills   \n",
       "2   summary_resources             Tools &amp; Technology   \n",
       "3   summary_resources           Detailed Work Activities   \n",
       "4   summary_resources                           Job Zone   \n",
       "5   summary_resources                          Interests   \n",
       "6   summary_resources                Related Occupations   \n",
       "7   summary_resources  Sources of Additional Information   \n",
       "8   details_resources                              Tasks   \n",
       "9   details_resources                  Technology Skills   \n",
       "10  details_resources             Tools &amp; Technology   \n",
       "11  details_resources           Detailed Work Activities   \n",
       "12  details_resources                           Job Zone   \n",
       "13  details_resources                          Interests   \n",
       "14  details_resources                Related Occupations   \n",
       "15  details_resources  Sources of Additional Information   \n",
       "16   custom_resources            Work Activities Outline   \n",
       "0            also see     Business Intelligence Analysts   \n",
       "1            also see             Clinical Data Managers   \n",
       "\n",
       "                                                 href also_see_code  \\\n",
       "0   https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "1   https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "2   https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "3   https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "4   https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "5   https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "6   https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "7   https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "8   https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "9   https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "10  https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "11  https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "12  https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "13  https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "14  https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "15  https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "16  https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "0   https://services.onetcenter.org/ws/online/occu...    15-2051.01   \n",
       "1   https://services.onetcenter.org/ws/online/occu...    15-2051.02   \n",
       "\n",
       "                                        tags  \n",
       "0                                        NaN  \n",
       "1                                        NaN  \n",
       "2                                        NaN  \n",
       "3                                        NaN  \n",
       "4                                        NaN  \n",
       "5                                        NaN  \n",
       "6                                        NaN  \n",
       "7                                        NaN  \n",
       "8                                        NaN  \n",
       "9                                        NaN  \n",
       "10                                       NaN  \n",
       "11                                       NaN  \n",
       "12                                       NaN  \n",
       "13                                       NaN  \n",
       "14                                       NaN  \n",
       "15                                       NaN  \n",
       "16                                       NaN  \n",
       "0   {'bright_outlook': True, 'green': False}  \n",
       "1   {'bright_outlook': True, 'green': False}  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_df = pd.concat([resources_df, also_see_df],axis=0)\n",
    "# report_df[info_cols] = \n",
    "# report_df = pd.concat([resources_df[info_cols],report_df ],axis=1, ignore_index=True)\n",
    "report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📌BOOKMARK: LUNCH.  (06/16/24)\n",
    "> note: was all of the report df stuff even necessary? Take a step back and ask yourself how you plan to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also_see_df['resource type'] = 'also_see'\n",
    "# also_see_df['resource title'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>bright_outlook</th>\n",
       "      <th>green</th>\n",
       "      <th>resource type</th>\n",
       "      <th>resource title</th>\n",
       "      <th>href</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Tasks</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Technology Skills</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Tools &amp;amp; Technology</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Detailed Work Activities</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Job Zone</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Interests</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Related Occupations</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Sources of Additional Information</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Tasks</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Technology Skills</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Tools &amp;amp; Technology</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Detailed Work Activities</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Job Zone</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Interests</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Related Occupations</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Sources of Additional Information</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>custom_resources</td>\n",
       "      <td>Work Activities Outline</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          code            title  \\\n",
       "0   15-2051.00  Data Scientists   \n",
       "1   15-2051.00  Data Scientists   \n",
       "2   15-2051.00  Data Scientists   \n",
       "3   15-2051.00  Data Scientists   \n",
       "4   15-2051.00  Data Scientists   \n",
       "5   15-2051.00  Data Scientists   \n",
       "6   15-2051.00  Data Scientists   \n",
       "7   15-2051.00  Data Scientists   \n",
       "8   15-2051.00  Data Scientists   \n",
       "9   15-2051.00  Data Scientists   \n",
       "10  15-2051.00  Data Scientists   \n",
       "11  15-2051.00  Data Scientists   \n",
       "12  15-2051.00  Data Scientists   \n",
       "13  15-2051.00  Data Scientists   \n",
       "14  15-2051.00  Data Scientists   \n",
       "15  15-2051.00  Data Scientists   \n",
       "16  15-2051.00  Data Scientists   \n",
       "\n",
       "                                          description  bright_outlook  green  \\\n",
       "0   Develop and implement a set of techniques or a...            True  False   \n",
       "1   Develop and implement a set of techniques or a...            True  False   \n",
       "2   Develop and implement a set of techniques or a...            True  False   \n",
       "3   Develop and implement a set of techniques or a...            True  False   \n",
       "4   Develop and implement a set of techniques or a...            True  False   \n",
       "5   Develop and implement a set of techniques or a...            True  False   \n",
       "6   Develop and implement a set of techniques or a...            True  False   \n",
       "7   Develop and implement a set of techniques or a...            True  False   \n",
       "8   Develop and implement a set of techniques or a...            True  False   \n",
       "9   Develop and implement a set of techniques or a...            True  False   \n",
       "10  Develop and implement a set of techniques or a...            True  False   \n",
       "11  Develop and implement a set of techniques or a...            True  False   \n",
       "12  Develop and implement a set of techniques or a...            True  False   \n",
       "13  Develop and implement a set of techniques or a...            True  False   \n",
       "14  Develop and implement a set of techniques or a...            True  False   \n",
       "15  Develop and implement a set of techniques or a...            True  False   \n",
       "16  Develop and implement a set of techniques or a...            True  False   \n",
       "\n",
       "        resource type                     resource title  \\\n",
       "0   summary_resources                              Tasks   \n",
       "1   summary_resources                  Technology Skills   \n",
       "2   summary_resources             Tools &amp; Technology   \n",
       "3   summary_resources           Detailed Work Activities   \n",
       "4   summary_resources                           Job Zone   \n",
       "5   summary_resources                          Interests   \n",
       "6   summary_resources                Related Occupations   \n",
       "7   summary_resources  Sources of Additional Information   \n",
       "8   details_resources                              Tasks   \n",
       "9   details_resources                  Technology Skills   \n",
       "10  details_resources             Tools &amp; Technology   \n",
       "11  details_resources           Detailed Work Activities   \n",
       "12  details_resources                           Job Zone   \n",
       "13  details_resources                          Interests   \n",
       "14  details_resources                Related Occupations   \n",
       "15  details_resources  Sources of Additional Information   \n",
       "16   custom_resources            Work Activities Outline   \n",
       "\n",
       "                                                 href  \n",
       "0   https://services.onetcenter.org/ws/online/occu...  \n",
       "1   https://services.onetcenter.org/ws/online/occu...  \n",
       "2   https://services.onetcenter.org/ws/online/occu...  \n",
       "3   https://services.onetcenter.org/ws/online/occu...  \n",
       "4   https://services.onetcenter.org/ws/online/occu...  \n",
       "5   https://services.onetcenter.org/ws/online/occu...  \n",
       "6   https://services.onetcenter.org/ws/online/occu...  \n",
       "7   https://services.onetcenter.org/ws/online/occu...  \n",
       "8   https://services.onetcenter.org/ws/online/occu...  \n",
       "9   https://services.onetcenter.org/ws/online/occu...  \n",
       "10  https://services.onetcenter.org/ws/online/occu...  \n",
       "11  https://services.onetcenter.org/ws/online/occu...  \n",
       "12  https://services.onetcenter.org/ws/online/occu...  \n",
       "13  https://services.onetcenter.org/ws/online/occu...  \n",
       "14  https://services.onetcenter.org/ws/online/occu...  \n",
       "15  https://services.onetcenter.org/ws/online/occu...  \n",
       "16  https://services.onetcenter.org/ws/online/occu...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resources_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the results with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_results = onet_ws.generic_request(full_path=resources_df.loc['Tasks','href'])\n",
    "# task_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(task_results))\n",
    "# task_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(results['task'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 👉Start Here for LLM code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "import PyPDF2\n",
    "from io import StringIO\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.prompts import  MessagesPlaceholder, PromptTemplate, ChatPromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "# from langchain.memory import ConversationBufferWindowMemory\n",
    "import os, json\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "import streamlit as st\n",
    "ai_avatar  = \"🤖\"\n",
    "user_avatar = \"💬\"\n",
    "model_type = 'gpt-4o'\n",
    "model_tone='friendly and encouraging'\n",
    "\n",
    "\n",
    "def get_system_prompt_str(with_context=True, with_onet=False):\n",
    "    \"\"\"Helper function for get_prompt_template. New v2.0\"\"\"\n",
    "    system_prompt = (\" You are a a specialized career coach for the {sector}, focused on delivering tailored, concise job application advice and practice. \" \n",
    "    \" You are proficient in resume analysis, cover letter guidance, and interview preparation, adapting to each user's unique requirements. \"\n",
    "    \" You maintain a professional, {model_tone} tone, ensuring advice is efficient, clear, and easily understandable, \"\n",
    "    \" with the goal of aiding their career progression. Ask the user for their resume and job listing if not provided and they are needed to asnwer .\")\n",
    "    context = \"\\nUse the following context, if provided, to help answer the questions:\\n\\nHere is my resume:\\n-------------\\n {resume}\\n\\n Here is the job listing:\\n-------------\\n{job}\\n\\n \"    \n",
    "\n",
    "    if with_context:        \n",
    "        if with_onet:\n",
    "            context += \"\\nHere is the Onet occupation report:\\n-------------\\n{onet_report}\\n\\n\"\n",
    "        return system_prompt + context\n",
    "    else:\n",
    "        return system_prompt\n",
    "\n",
    "\n",
    "def get_llm_no_memory(model_type='gpt-4o', temperature=0.1, #\n",
    "            system_prompt_template_func= get_system_prompt_str,#verbose=False,\n",
    "            system_prompt_template_func_kws = dict(with_context=True, with_onet=False),\n",
    "            model_tone='friendly and encouraging',\n",
    "             verbose=True, sector=\"data science and analytics\",\n",
    "             partial_prompt_kws= {}):#, resume='', job=''):\n",
    "    \"\"\"Version 2.0\"\"\"\n",
    "    # ## get prompt string\n",
    "    system_prompt = system_prompt_template_func(**system_prompt_template_func_kws)\n",
    "    \n",
    "    # final_promp_str = system_prompt + \"\"\"\n",
    "    #     Current conversation:\n",
    "    #     {history}\n",
    "    #     Human: {input}\n",
    "    #     AI:\"\"\"\n",
    "        \n",
    "    # final_prompt_template = ChatPromptTemplate.from_template(final_promp_str)\n",
    "    final_prompt_template = ChatPromptTemplate.from_messages([\n",
    "        ('system',system_prompt),\n",
    "         MessagesPlaceholder(variable_name='history', optional=True),\n",
    "         ('human', '{input}'),\n",
    "    ])\n",
    "    \n",
    "    final_prompt_template = final_prompt_template.partial(sector=sector,\n",
    "                                                          model_tone=model_tone,\n",
    "                                                          **partial_prompt_kws)#, resume=resume, job=job)\n",
    "\n",
    "    try:\n",
    "        api_key = st.session_state.OPENAI_API_KEY\n",
    "    except:\n",
    "        api_key = os.getenv('OPENAI_API_KEY')\n",
    "    llm = ChatOpenAI(temperature=temperature, model=model_type, api_key=api_key)\n",
    "    \n",
    "    llm_chain = final_prompt_template | llm | StrOutputParser(output_key=\"response\")\n",
    "    # llm_chain = ConversationChain(prompt=final_prompt_template, \n",
    "    #                               llm=llm, \n",
    "    #                               memory=None, \n",
    "    #                               verbose=verbose, \n",
    "    #                             #   input_key=\"input\",\n",
    "    #                               output_key=\"response\")#,#callbacks=callbacks)\n",
    "    \n",
    "    return llm_chain\n",
    "            \n",
    "            \n",
    "\n",
    "def stream_response(llm_no_mem, input, resume='', job='', \n",
    "                    model_tone='friendly and encouraging',\n",
    "                    model_type='gpt-4o',\n",
    "                    history=[],\n",
    "                    system_prompt_template_func= get_system_prompt_str,\n",
    "                    system_prompt_template_func_kws= dict(with_context=True, with_onet=False),\n",
    "                    partial_prompt_kws = {},\n",
    "                    prompt_kws={}):\n",
    "    \"\"\"Stream response from ChatGPT. Version 2.0.\"\"\"\n",
    "    if llm_no_mem is None:\n",
    "        llm_no_mem = get_llm_no_memory(model_type=model_type,\n",
    "                                       model_tone=model_tone,\n",
    "                                       sector=\"data science and analytics\", \n",
    "                                       partial_prompt_kws=partial_prompt_kws,\n",
    "                                        system_prompt_template_func=system_prompt_template_func,\n",
    "                                        system_prompt_template_func_kws=system_prompt_template_func_kws,\n",
    "                                       )\n",
    "\n",
    "    ## Add input to history\n",
    "    history.append(HumanMessage(content=input))\n",
    "\n",
    "    return llm_no_mem.stream({'input':input,\n",
    "                   'resume':resume,\n",
    "                   'job':job,\n",
    "                   'history':history,\n",
    "                   **prompt_kws})\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `stream_response` updated with flexible args for partial prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_fpath = \"../data/James Irving Resume 2024.pdf\"\n",
    "job_fpath='../data/bah-473.pdf'\n",
    "\n",
    "resume_text = af.read_pdf(resume_fpath)\n",
    "job_text = af.read_pdf(job_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NameError(\"name 'results_report' is not defined\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    chat_history = []\n",
    "    user_text = \"What can you tell me about this profession from the ONET report?\"\n",
    "\n",
    "    chat_history.append(HumanMessage(content=user_text))\n",
    "\n",
    "    response= \"\"\n",
    "    for chunk in  stream_response(llm_no_mem=None, input=user_text, \n",
    "                            resume=resume_text, job=job_text, model_tone=model_tone,\n",
    "                            partial_prompt_kws=dict(report=results_report['output']),\n",
    "                            history=chat_history):\n",
    "        response+=chunk\n",
    "    print(response)\n",
    "        # response += s\n",
    "        # print(s)\n",
    "except Exception as e:\n",
    "    display(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_report['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Resume Creation/Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pypi.org/project/python-docx/\n",
    "# !pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robert Half\n",
      "Senior Data Scientist\n",
      "$115K/yr - $173K/yr···Mid-Senior level\n",
      "10,001+ employees · Staffing and Recruiting\n",
      "2 company alumni work here·3 school alumni work here\n",
      "3 of 3 skills match your profile - you may be a good fit\n",
      "Apply SavedCalifornia, United States·4 hours ago·29 applicants\n",
      "RemoteFull-time\n",
      "Am I a good fit for this job? How can I best position myself fo\n",
      "Meet the hiring team\n",
      "Kelli Griffin3rd\n",
      "Lead Talent Acquisition Partner\n",
      "Job posterMessage\n",
      "About the job\n",
      "Ready to revolutionize the future of data-driven decision-making? Join our\n",
      "pioneering Data Science team as we embark on an exciting journey to unlock\n",
      "insights, drive innovation, and shape the landscape of our organization's success.\n",
      "If you're passionate about leveraging cutting-edge generative AI technologies\n",
      "and transforming raw data into actionable insight, we want you on our team!\"\n",
      "The Senior Data Scientist will be responsible for leading advanced data analytics\n",
      "projects, leveraging Azure and Microsoft data services. Th\n"
     ]
    }
   ],
   "source": [
    "job_fpath_senior_rh = '../data/Senior Data Scientist _ Robert Half _ LinkedIn copy.pdf'\n",
    "job_text_senior_rh = af.read_pdf(job_fpath_senior_rh)\n",
    "print(job_text_senior_rh[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LONG MASTER RESUME]  James M. Irving, Ph.D. 8222 Spadderdock Way, Laurel, MD, 20724 | (518) 322-6750 | james.irving.phd@gmail.com |  LinkedIn: james-irving-phd | GitHub: https://github.com/jirvingphd  SUMMARY V1 Innovative and enterprising data scientist with extensive experience in applying advanced data science techniques to real-world problems. Known for excellent problem-solving skills and the ability to rapidly master and implement new technologies. Committed to leveraging data to drive innovation and support data-driven decision-making. SUMMARY V2 Neuroscientist-turned-data scientist with an insatiable curiosity and a proven track record in mastering cutting-edge technologies. Exceptional communication and interpersonal skills paired with a robust history of problem-solving and critical thinking. Proven ability to self-teach complex concepts and technologies, including in vivo electrophysiology recordings and analysis. Successfully trained generations of collaborators, technicia\n"
     ]
    }
   ],
   "source": [
    "long_resume_fpath = \"../data/James Irving LONG MASTER Resume 2024.pdf\"\n",
    "long_resume = af.read_pdf(long_resume_fpath)\n",
    "print(long_resume[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 16:40:49.793 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input', 'job', 'resume'], input_types={'history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'history': [], 'sector': 'data science and analytics', 'model_tone': 'friendly and encouraging'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['job', 'model_tone', 'resume', 'sector'], template=\" You are a a specialized career coach for the {sector}, focused on delivering tailored, concise job application advice and practice.  You are proficient in resume analysis, cover letter guidance, and interview preparation, adapting to each user's unique requirements.  You maintain a professional, {model_tone} tone, ensuring advice is efficient, clear, and easily understandable,  with the goal of aiding their career progression. Ask the user for their resume and job listing if not provided and they are needed to asnwer .\\nUse the following context, if provided, to help answer the questions:\\n\\nHere is my resume:\\n-------------\\n {resume}\\n\\n Here is the job listing:\\n-------------\\n{job}\\n\\n \")), MessagesPlaceholder(variable_name='history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x1765344f0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x1765360e0>, model_name='gpt-4o', temperature=0.1, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = get_llm_no_memory(model_type='gpt-4o', temperature=0.1)\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Help me take my longer cv (that has more bullet points per item than I want to keep)  to craft a tailor-made 2-page resume for the job listing by cherry-picking the most relevant/best items.  Do not make anything up or mention skills or accomplishments that I do not have. '"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_prompt = ( \" Help me take my longer cv (that has more bullet points per item than I want to keep) \"\n",
    "                  \" to craft a tailor-made 2-page resume for the job listing by cherry-picking the most relevant/best items. \" \n",
    "                  \" Do not make anything up or mention skills or accomplishments that I do not have. \"\n",
    "                  )\n",
    "resume_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using OpenAI Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve a more controlled and structured response from the LLM, you can define a detailed prompt and use LangChain to orchestrate the interactions. Here’s how you can do it step by step:\n",
    "\n",
    "### Step-by-Step Guide\n",
    "\n",
    "#### Step 1: Set Up the Environment\n",
    "\n",
    "Ensure you have the necessary packages installed:\n",
    "\n",
    "```bash\n",
    "pip install langchain openai\n",
    "```\n",
    "\n",
    "#### Step 2: Initialize the OpenAI API\n",
    "\n",
    "Set up your OpenAI API key:\n",
    "\n",
    "```python\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# Set up your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'your-openai-api-key'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Step 3: Define Functions for Structured Response\n",
    "\n",
    "Create functions to handle each part of the structured response you need.\n",
    "\n",
    "**Example Functions**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def get_llm(model_type='gpt-4o', temperature=0.1, #\n",
    "#             prompt_template = None,\n",
    "#             # system_prompt_template_func= get_system_prompt_str,#verbose=False,\n",
    "#             # system_prompt_template_func_kws = dict(with_context=True, with_onet=False),\n",
    "#             # model_tone='friendly and encouraging',\n",
    "#              verbose=True, \n",
    "#             #  sector=\"data science and analytics\",\n",
    "#             #  partial_prompt_kws= {}):#, resume='', job=''\n",
    "#             ):\n",
    "#     \"\"\"Version 2.0\"\"\"\n",
    "#     # ## get prompt string\n",
    "#     if prompt_template is None:\n",
    "        \n",
    "#     system_prompt = system_prompt_template_func(**system_prompt_template_func_kws)\n",
    "    \n",
    "#     # final_promp_str = system_prompt + \"\"\"\n",
    "#     #     Current conversation:\n",
    "#     #     {history}\n",
    "#     #     Human: {input}\n",
    "#     #     AI:\"\"\"\n",
    "        \n",
    "#     # final_prompt_template = ChatPromptTemplate.from_template(final_promp_str)\n",
    "#     final_prompt_template = ChatPromptTemplate.from_messages([\n",
    "#         ('system',system_prompt),\n",
    "#          MessagesPlaceholder(variable_name='history', optional=True),\n",
    "#          ('human', '{input}'),\n",
    "#     ])\n",
    "    \n",
    "#     final_prompt_template = final_prompt_template.partial(sector=sector,\n",
    "#                                                           model_tone=model_tone,\n",
    "#                                                           **partial_prompt_kws)#, resume=resume, job=job)\n",
    "\n",
    "#     try:\n",
    "#         api_key = st.session_state.OPENAI_API_KEY\n",
    "#     except:\n",
    "#         api_key = os.getenv('OPENAI_API_KEY')\n",
    "#     llm = ChatOpenAI(temperature=temperature, model=model_type, api_key=api_key)\n",
    "    \n",
    "#     llm_chain = final_prompt_template | llm | StrOutputParser(output_key=\"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_resume_vs_job(resume: str, job_listing: str, temperature=0.1, model_type='gpt-4o') -> str:\n",
    "    prompt = f\"\"\"\n",
    "    I need you to rate this resume against the following job listing out of 5 stars. Please provide a rating and 1-2 sentence justification.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "    \"\"\"\n",
    "    #     Response format:\n",
    "    # {{\n",
    "    #     \"rating\": <number>,\n",
    "    #     \"justification\": \"<string>\"\n",
    "    # }}\n",
    "\n",
    "    final_prompt_template = PromptTemplate.from_template(prompt)\n",
    "    # final_prompt_template = final_prompt_template.partial(resume=resume, job=job_listing)\n",
    "        \n",
    "    # final_prompt_template = final_prompt_template.partial(sector=sector,\n",
    "    #                                                       model_tone=model_tone,\n",
    "    #                                                       **partial_prompt_kws)#, resume=resume, job=job)\n",
    "    try:\n",
    "        api_key = st.session_state.OPENAI_API_KEY\n",
    "    except:\n",
    "        api_key = os.getenv('OPENAI_API_KEY')\n",
    "    llm = ChatOpenAI(temperature=temperature, model=model_type, api_key=api_key)\n",
    "    \n",
    "    llm_chain = final_prompt_template | llm | StrOutputParser(output_key=\"response\")\n",
    "    response = llm_chain.invoke(dict(resume=resume, job=job_listing))\n",
    "    return response\n",
    "    # response = openai.Completion.create(\n",
    "    #     engine=\"gpt-4\",\n",
    "    #     prompt=prompt,\n",
    "    #     max_tokens=150,\n",
    "    #     n=1,\n",
    "    #     stop=None,\n",
    "    #     temperature=0.7,\n",
    "    # )\n",
    "    # return response.choices[0].text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 06/23/24 Notes: Can't get job_listing passed to tools\n",
    "- [ ] Try swapping StrOutputParser for Json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Robert Half\\nSenior Data Scientist\\n$115K/yr - $173K/yr···Mid-Senior level\\n10,001+ employees · Staffing and Recruiting\\n2 company alumni work here·3 school alumni work here\\n3 of 3 skills match your profile - you may be a good fit\\nApply SavedCalifornia, United States·4 hours ago·29 applicants\\nRemoteFull-time\\nAm I a good fit for this job? How can I best position myself fo\\nMeet the hiring team\\nKelli Griffin3rd\\nLead Talent Acquisition Partner\\nJob posterMessage\\nAbout the job\\nReady to revolutionize the future of data-driven decision-making? Join our\\npioneering Data Science team as we embark on an exciting journey to unlock\\ninsights, drive innovation, and shape the landscape of our organization\\'s success.\\nIf you\\'re passionate about leveraging cutting-edge generative AI technologies\\nand transforming raw data into actionable insight, we want you on our team!\"\\nThe Senior Data Scientist will be responsible for leading advanced data analytics\\nprojects, leveraging Azure and Microsoft data services. This role demands a deep\\nunderstanding of data science methodologies, machine learning algorithms, and\\nbig data technologies. The incumbent will work closely with cross-functional\\nteams to understand business needs and formulate and execute data science\\nsolutions that drive significant business impact.\\nKey Responsibilities:\\nData Analytics and Modeling:\\nDevelop and implement advanced predictive models and statistical\\nanalysis using a variety of machine learning algorithms.\\nSuggest algorithms or models appropriate for specific use cases and\\napplications.\\nAnalyze and extract relevant information from large amounts of historical\\nbusiness data to help automate and optimize key processes with business\\nteams.\\nApply technical solutions to business problems and questions using large\\nscale data analytics and machine learning; create highly calibrated\\nsolutions for business problems.\\nWork closely with software engineering teams to drive real-time model\\nexperiments, implementations and new feature creations.\\nContinuously evaluate and refine models based on performance metrics.\\nUtilize cloud technologies such as Azure Machine Learning, Azure\\nDatabricks, and other Microsoft data services for data processing, modelHomeMy NetworkJobsMessagingNotificationsMe\\n For BusinessLear\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 1/7\\nSee lessbuilding, and deployment.\\nLarge Language Model Fine-tuning:\\nEnhance and evolve the performance of large language models by\\nrefining their capabilities through targeted fine-tuning.\\nSteer both the research trajectory and the practical engineering efforts of\\nthe team.\\nFormulate and enact algorithms for model enhancement, tweak critical\\nhyperparameters, and heighten overall model efficiency.\\nGuarantee the integrity and relevance of datasets by conducting thorough\\npreprocessing and data analysis within the fine-tuning workflow.\\nConduct assessments on fine-tuned models, making necessary\\nmodifications to boost their effectiveness.\\nFoster a cooperative environment within the team, providing guidance to\\npeers to ensure a smooth fine-tuning operation that yields superior\\nresults.\\nStay at the forefront of advancements in large language model\\ntechnologies and applications, perpetually refining technical expertise in\\nmodel fine-tuning.\\nData Management and Strategy:\\nCollaborate with IT and data engineering teams in an enterprise setting to\\nintegrate data science solutions into the broader tech stack and data\\nstrategy.\\nBusiness Collaboration and Insights:\\nWork closely with business stakeholders to identify opportunities for\\nleveraging company data to drive business solutions.\\nTranslate complex data-driven findings into actionable business insights\\nand communicate these effectively to non-technical stakeholders.\\nResearch and Development:\\nStay abreast of industry trends and advancements in data science and\\nAzure technologies.\\nConduct research to explore new methodologies and technologies that\\ncan enhance the organization\\'s data analytics capabilities.\\nPreferred Qualifications and Skills:\\nBachelor\\'s degree in Statistics, Computer Science, Mathematics or\\nequivalent required; Master\\'s or PhD highly preferred\\n5 years of professional experience in data science, with a record in\\ndesigning and implementing large-scale data science projects.\\n5 years of industry experience in predictive modeling and large data\\nanalysis\\nKnowledge of open-source large language models and experience with\\nevaluating and recommending appropriate models for specific use cases.\\n3+ years of experience in using big data platforms and technologies such\\nas Hadoop, Azure data lake, Azure Cosmos DB, Pig, Hive, HBase, etc.\\n3+ years of hands-on experience in statistical modeling, data mining,\\nlarge data analysis and predictive modeling; text mining a major plus\\n3+ years of experience in regression, classification and clustering\\nmethods such as GLM, LR, SVM, LVQ, SOM, Neural Networks\\nExperience with two or more of the following: Python, PERL, Matlab or\\nScala\\nExpertise in various machine learning frameworks and libraries (e.g.,\\nTensorFlow, PyTorch, Scikit-learn).\\nExcellent analytical, problem-solving, and communication skills.\\nExcellent communication skills, with a proven ability to translate technical\\nfindings into business recommendations and strategies.\\nCertifications in Azure data services or advanced analytics preferred\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 2/7\\nSet alert for similar jobs\\nData Scientist, California, United StatesSet alert\\nEmployer-provided\\nPay range in California, United States\\nExact compensation may vary based on skills, experience, and location.\\nBase salary\\n$115,000/yr - $173,000/yr\\nFeatured benefits\\nMedical insurance\\nVision insurance\\nDental insurance\\n401(k)\\nTuition assistance\\nQualifications\\n3 of 3 skills match your profile - you may be a good fit\\nSkills added by the job poster\\nBig Data · Large Language Models (LLM) · Natural Language Processing (NLP)\\nAdditional skills among applicants\\nData Analysis · Data Science · Data Visualization · Machine Learning · Microsoft\\nPower BI · Python (Programming Language) · R (Programming Language) · SQL …\\nShow qualification details\\nPut your best foot forward with your application\\nHire a resume writer\\nGet a resume review\\nSee how you compare to other applicants\\nApplicants for this job\\n29Applicants\\n29Applicants in the past day\\nApplicant seniority level\\n15 Entry level applicants\\n10 Senior level applicants\\n1 Director level applicant Youʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 3/7\\nApplicant education level\\n19%have a Doctor of Philosophy (Similar to you)\\n59%have a Master\\'s Degree\\n15%have a Bachelor\\'s Degree\\n7%have other degrees\\nApplicants are in these locations\\n1-5 applicants\\nNew York City Metropolitan\\nArea\\n1-5 applicants\\nGreater Pittsburgh Region\\n1-5 applicants\\nDallas-Fort Worth Metroplex\\nSee if Robert Half is hiring people like you\\nThe latest hiring trends.\\n29,307\\nTotal employees3%\\nCompany-wide\\n2 year growth2%\\nEngineering\\n2 year growth\\nMedian employee tenure ‧6 yearsMay 2022 Nov 2022 May 2023 Nov 2023 May 202410,00020,00030,00040,000\\nRobert Half hires candidates from some of these companies and schools\\nRobert Half hired 2 people\\nfrom Coding Dojo.See all\\nRobert Half hired 3 people from\\nFlatiron School.See all\\nEngineering hires at Robert Half came\\nfrom these companies and more.Engineering hires at Robert Half came\\nfrom these schools and more.\\nReset map\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 4/7\\nMore jobsShow more Premium insightsSee more companies See more schools\\nAbout the company\\nRobert Half\\n3,147,224 followersFollow\\nStaffing and Recruiting•10,001+ employees•29,320 on LinkedIn\\nTrending employee content PreviousNext\\nShow more\\nRobert Half, the worldʼs first and largest specialized talent solutions firm,\\nconnects opportunities at great companies with highly skilled job seekers. We\\noffer contract, temporary and permanent placement solutions for roles in financ……show more\\nInterested in working with us in the future?\\nPrivately share your profile with our recruiters – youʼll be noted as\\nexpressing interest for up to a year.Learn more\\nIʼm interested\\nLead Data Scientist\\nCigniti Technologies\\nUnited States (Remote)\\nActively recruiting\\n4 weeks agoEasy ApplySenior Data Scientist\\nDTN\\nUnited States (Remote)\\nActively recruiting\\n2 weeks ago\\nData Scientist\\nQuantum World Technologies…\\nUnited States (Remote)\\nActively recruiting\\nSr. Data Scientist\\nAKASA\\nUnited States (Remote)\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 5/7\\nSee more jobs like this10 minutes agoEasy Apply 2 weeks ago\\nSenior Data Scientist\\nPhreesia\\nUnited States (Remote)\\nActively recruiting\\n3 weeks agoSr. Data Scientist\\nAppFolio\\nUnited States (Remote)\\nActively recruiting\\n1 week ago\\nSenior Data Scientist,\\nProduct\\nUniswap Labs\\nNew York, NY (Remote)\\nActively recruiting\\n1 week agoSenior Data Scientist\\nAustin Fraser\\nUnited States (Remote)\\nActively recruiting\\n6 days agoEasy Apply\\nSenior Data Scientist\\nWebflow\\nUnited States (Remote)\\n1 company alum works here\\n2 days agoSenior Data Scientist\\nXOi\\nUnited States (Remote)\\n2 weeks ago\\nLead Data Scientist\\nLittle Place Labs\\nUnited States (Remote)\\n1 month agoEasy ApplyStaff Data Scientist\\nDemandbase\\nUnited States (Remote)\\n3 school alumni work here\\n3 weeks ago\\nLearn skills to get a new job with these courses\\n135,378 viewers\\nThe New Rules of Work\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 6/7\\nAbout Accessibility Talent Solutions\\nCommunity Guidelines Careers Marketing Solutions\\nAd Choices Advertising\\nSales Solutions Mobile Small Business\\nSafety CenterQuestions?\\nVisit our Help Center.\\nManage your account and privacy\\nGo to your Settings.\\nRecommendation transparency\\nLearn more about Recommended Content.Select Language\\nLinkedIn Corporation © 2024282,784 viewers\\nShow more on LinkedIn Learning\\nDeveloping Your Professional Image in a New Job\\nLooking for talent?Post a job\\nPrivacy & Terms\\nEnglish (English)\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 7/7\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_text_senior_rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Rating: 4.5 out of 5 stars\n",
      "\n",
      "### Justification:\n",
      "James M. Irving, Ph.D., has a robust background in data science and neuroscience, with extensive experience in machine learning, data analysis, and model deployment, which aligns well with the job requirements at Robert Half. His experience with Python, deep learning, and NLP, as well as his history of developing and delivering data science curricula, demonstrates his capability to lead advanced data analytics projects. Additionally, his work with large datasets and various machine learning frameworks (TensorFlow, scikit-learn) matches the job's technical demands.\n",
      "\n",
      "However, the resume does not explicitly mention experience with Azure Machine Learning, Azure Databricks, or other Microsoft data services, which are critical for this role. While his skills and experience are highly relevant, the lack of specific mention of Azure technologies slightly reduces the fit for the position.\n"
     ]
    }
   ],
   "source": [
    "compare_response = rate_resume_vs_job(long_resume, job_text_senior_rh)\n",
    "print(compare_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def list_matching_qualifications(resume: str, job_listing: str, \n",
    "                                 temperature=0.1, model_type='gpt-4o',\n",
    "                                 ) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Identify and list the most important matching qualifications between the following resume and job listing. \n",
    "    Mention the qualification first,what the job listing desires, then how the resume meets it. Be concise and to the point. Do not mention the gaps or missing qualifications.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "    \"\"\"\n",
    "    final_prompt_template = PromptTemplate.from_template(prompt)\n",
    "        \n",
    "    # final_prompt_template = final_prompt_template.partial(sector=sector,\n",
    "    #                                                       model_tone=model_tone,\n",
    "    #                                                       **partial_prompt_kws)#, resume=resume, job=job)\n",
    "    try:\n",
    "        api_key = st.session_state.OPENAI_API_KEY\n",
    "    except:\n",
    "        api_key = os.getenv('OPENAI_API_KEY')\n",
    "    llm = ChatOpenAI(temperature=temperature, model=model_type, api_key=api_key,\n",
    "                    #  max_tokens=max_tokens\n",
    "                     )\n",
    "    \n",
    "    llm_chain = final_prompt_template | llm | StrOutputParser(output_key=\"response\")\n",
    "    response = llm_chain.invoke(dict(resume=resume, job=job_listing))\n",
    "    return response\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Advanced Predictive Models and Statistical Analysis**\n",
      "   - **Job Listing**: Develop and implement advanced predictive models and statistical analysis using a variety of machine learning algorithms.\n",
      "   - **Resume**: Extensive experience in developing predictive models and statistical analysis, including projects like \"Recidivism Risk Assessment\" and \"Forecasting Stock Market Fluctuations with Trump’s Tweets.\"\n",
      "\n",
      "2. **Machine Learning Algorithms**\n",
      "   - **Job Listing**: Expertise in various machine learning frameworks and libraries (e.g., TensorFlow, PyTorch, Scikit-learn).\n",
      "   - **Resume**: Proficient in machine learning frameworks and libraries such as TensorFlow, Keras, and scikit-learn, demonstrated through multiple projects and teaching experience.\n",
      "\n",
      "3. **Natural Language Processing (NLP)**\n",
      "   - **Job Listing**: Experience with NLP and large language models.\n",
      "   - **Resume**: Developed and delivered courses in NLP, and conducted NLP analysis in projects like \"NLP Analysis of Amazon Reviews + AI Recommendations\" and \"How to Spot a Troll.\"\n",
      "\n",
      "4. **Big Data Technologies**\n",
      "   - **Job Listing**: Experience with big data platforms and technologies such as Hadoop, Azure data lake, Azure Cosmos DB.\n",
      "   - **Resume**: Experience with large data analysis and predictive modeling, including the use of big data platforms in various projects.\n",
      "\n",
      "5. **Python Programming**\n",
      "   - **Job Listing**: Experience with Python.\n",
      "   - **Resume**: Extensive experience in Python programming, demonstrated through multiple data science projects and teaching roles.\n",
      "\n",
      "6. **Data Visualization**\n",
      "   - **Job Listing**: Ability to translate complex data-driven findings into actionable business insights.\n",
      "   - **Resume**: Proficient in data visualization tools like Tableau and Plotly/Dash, demonstrated through projects like \"How to Make a Successful Movie\" and teaching experience.\n",
      "\n",
      "7. **Communication Skills**\n",
      "   - **Job Listing**: Excellent communication skills, with a proven ability to translate technical findings into business recommendations and strategies.\n",
      "   - **Resume**: Proven communication skills through teaching roles, mentoring, and presenting research findings to mixed audiences.\n",
      "\n",
      "8. **Research and Development**\n",
      "   - **Job Listing**: Conduct research to explore new methodologies and technologies.\n",
      "   - **Resume**: Conducted extensive research in neuroscience and data science, resulting in publications and innovative projects.\n",
      "\n",
      "9. **Collaboration with Cross-Functional Teams**\n",
      "   - **Job Listing**: Work closely with business stakeholders and cross-functional teams.\n",
      "   - **Resume**: Demonstrated ability to collaborate with various teams in roles at Coding Dojo and Flatiron School, as well as in academic research settings.\n",
      "\n",
      "10. **Educational Background**\n",
      "    - **Job Listing**: PhD highly preferred.\n",
      "    - **Resume**: Holds a PhD in Neuroscience, along with additional certifications in data science.\n"
     ]
    }
   ],
   "source": [
    "response_matching = list_matching_qualifications(long_resume, job_text_senior_rh)\n",
    "print(response_matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Missing Qualifications\n",
      "\n",
      "1. **Experience with Azure and Microsoft Data Services**\n",
      "   - **Job Listing:** Requires experience with Azure Machine Learning, Azure Databricks, and other Microsoft data services.\n",
      "   - **Resume:** No mention of experience with Azure or Microsoft data services.\n",
      "\n",
      "2. **Large Language Model Fine-tuning**\n",
      "   - **Job Listing:** Requires experience in fine-tuning large language models.\n",
      "   - **Resume:** No specific mention of fine-tuning large language models, although there is experience with NLP and AI.\n",
      "\n",
      "3. **Big Data Platforms and Technologies**\n",
      "   - **Job Listing:** Requires 3+ years of experience with big data platforms such as Hadoop, Azure data lake, Azure Cosmos DB, Pig, Hive, HBase.\n",
      "   - **Resume:** No mention of experience with these specific big data platforms and technologies.\n",
      "\n",
      "4. **Statistical Modeling and Predictive Modeling**\n",
      "   - **Job Listing:** Requires 3+ years of experience in statistical modeling, data mining, large data analysis, and predictive modeling.\n",
      "   - **Resume:** While there is experience in machine learning and data analysis, specific mention of statistical modeling and predictive modeling experience is limited.\n",
      "\n",
      "5. **Regression, Classification, and Clustering Methods**\n",
      "   - **Job Listing:** Requires experience with methods such as GLM, LR, SVM, LVQ, SOM, Neural Networks.\n",
      "   - **Resume:** Experience with neural networks is mentioned, but there is no specific mention of GLM, LR, SVM, LVQ, or SOM.\n",
      "\n",
      "6. **Certifications in Azure Data Services or Advanced Analytics**\n",
      "   - **Job Listing:** Prefers certifications in Azure data services or advanced analytics.\n",
      "   - **Resume:** No certifications in Azure data services or advanced analytics are mentioned.\n",
      "\n",
      "7. **Business Collaboration and Insights**\n",
      "   - **Job Listing:** Requires translating complex data-driven findings into actionable business insights and communicating these effectively to non-technical stakeholders.\n",
      "   - **Resume:** While there is experience in communication and teaching, specific examples of translating data findings into business insights are not highlighted.\n",
      "\n",
      "8. **Research and Development in Data Science and Azure Technologies**\n",
      "   - **Job Listing:** Requires staying abreast of industry trends and advancements in data science and Azure technologies.\n",
      "   - **Resume:** No specific mention of research and development in Azure technologies.\n",
      "\n",
      "### Summary\n",
      "James M. Irving, Ph.D., has a strong background in data science, machine learning, and NLP, but lacks specific experience and qualifications in Azure and Microsoft data services, fine-tuning large language models, big data platforms, and certain statistical and predictive modeling methods. Additionally, certifications in Azure data services or advanced analytics and specific examples of translating data findings into business insights are missing.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def list_missing_qualifications(resume: str, job_listing: str, \n",
    "                                 temperature=0.1, model_type='gpt-4o',\n",
    "                                 ) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Identify and list the most important missing qualifications between the following resume and job listing. \n",
    "    Mention the qualification first, what the job listing desires, then how the resume does not meet it. Be concise and to the point. \n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "    \"\"\"\n",
    "    final_prompt_template = PromptTemplate.from_template(prompt)\n",
    "        \n",
    "    # final_prompt_template = final_prompt_template.partial(sector=sector,\n",
    "    #                                                       model_tone=model_tone,\n",
    "    #                                                       **partial_prompt_kws)#, resume=resume, job=job)\n",
    "    try:\n",
    "        api_key = st.session_state.OPENAI_API_KEY\n",
    "    except:\n",
    "        api_key = os.getenv('OPENAI_API_KEY')\n",
    "    llm = ChatOpenAI(temperature=temperature, model=model_type, api_key=api_key,\n",
    "                    #  max_tokens=max_tokens\n",
    "                     )\n",
    "    \n",
    "    llm_chain = final_prompt_template | llm | StrOutputParser(output_key=\"response\")\n",
    "    response = llm_chain.invoke(dict(resume=resume, job=job_listing))\n",
    "    return response\n",
    "\n",
    "\n",
    "\n",
    "missing_response = list_missing_qualifications(long_resume, job_text_senior_rh)\n",
    "print(missing_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine if there is additional information that could be added to the resume to address the missing qualifications, consider asking the following questions:\n",
      "\n",
      "### Experience with Azure and Microsoft Data Services\n",
      "1. **Azure Experience:**\n",
      "   - Have you had any experience working with Azure Machine Learning, Azure Databricks, or other Microsoft data services that might not be listed on your resume?\n",
      "   - Have you completed any projects or coursework involving Azure technologies?\n",
      "\n",
      "### Large Language Model Fine-tuning\n",
      "2. **Fine-tuning Large Language Models:**\n",
      "   - Have you had any experience fine-tuning large language models, such as GPT-3 or BERT, in your projects or research?\n",
      "   - Can you provide examples of any work or research involving the customization or fine-tuning of large language models?\n",
      "\n",
      "### Big Data Platforms and Technologies\n",
      "3. **Specific Big Data Technologies:**\n",
      "   - Have you worked with big data platforms such as Hadoop, Azure Data Lake, Azure Cosmos DB, Pig, Hive, or HBase in any capacity?\n",
      "   - Can you describe any projects where you utilized these specific big data technologies?\n",
      "\n",
      "### Statistical Modeling and Predictive Modeling\n",
      "4. **Detailed Experience in Statistical Modeling:**\n",
      "   - Can you provide more details about your experience with statistical modeling and predictive modeling, including specific methods and tools you have used?\n",
      "   - Have you worked on any projects that involved extensive statistical modeling or data mining?\n",
      "\n",
      "### Regression, Classification, and Clustering Methods\n",
      "5. **Specific Methods:**\n",
      "   - Have you used regression, classification, and clustering methods such as GLM, LR, SVM, LVQ, or SOM in your work?\n",
      "   - Can you provide examples of projects where you applied these specific methods?\n",
      "\n",
      "### Certifications in Azure Data Services or Advanced Analytics\n",
      "6. **Certifications:**\n",
      "   - Do you have any certifications in Azure data services or advanced analytics that are not mentioned on your resume?\n",
      "   - Are you currently pursuing any certifications in these areas?\n",
      "\n",
      "### Business Collaboration and Insights\n",
      "7. **Translating Data Findings:**\n",
      "   - Can you provide specific examples of how you have translated complex data-driven findings into actionable business insights?\n",
      "   - Have you worked on projects where you communicated technical findings to non-technical stakeholders and helped shape business strategies?\n",
      "\n",
      "### Research and Development in Data Science and Azure Technologies\n",
      "8. **Research in Azure Technologies:**\n",
      "   - Have you conducted any research or stayed updated on industry trends and advancements specifically in Azure technologies?\n",
      "   - Can you describe any initiatives or projects where you explored new methodologies or technologies in data science, particularly related to Azure?\n",
      "\n",
      "By asking these questions, you can uncover additional relevant experiences and qualifications that may not be explicitly mentioned on the resume, thereby providing a more comprehensive view of the candidate's capabilities.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# def questions_for_additional_info(resume: str, job_listing: str,\n",
    "                                       \n",
    "def questions_for_additional_info(matching_qualifications: str, missing_qualifications: str,\n",
    "                                  temperature=0.1, model_type='gpt-4o') -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following matching and missing qualifications, list questions that could help determine if there is additional information that could be added to the resume.\n",
    "\n",
    "    Matching Qualifications:\n",
    "    {matching_qualifications}\n",
    "\n",
    "    Missing Qualifications:\n",
    "    {missing_qualifications}\n",
    "    \"\"\"\n",
    "    final_prompt_template = PromptTemplate.from_template(prompt)\n",
    "        \n",
    "    # final_prompt_template = final_prompt_template.partial(sector=sector,\n",
    "    #                                                       model_tone=model_tone,\n",
    "    #                                                       **partial_prompt_kws)#, resume=resume, job=job)\n",
    "    try:\n",
    "        api_key = st.session_state.OPENAI_API_KEY\n",
    "    except:\n",
    "        api_key = os.getenv('OPENAI_API_KEY')\n",
    "    llm = ChatOpenAI(temperature=temperature, model=model_type, api_key=api_key,\n",
    "                    #  max_tokens=max_tokens\n",
    "                     )\n",
    "    \n",
    "    llm_chain = final_prompt_template | llm | StrOutputParser(output_key=\"response\")\n",
    "    response = llm_chain.invoke(dict(matching_qualifications=matching_qualifications, missing_qualifications=missing_qualifications))\n",
    "    return response\n",
    "\n",
    "response_questions  = questions_for_additional_info(matching_qualifications=response_matching, missing_qualifications=missing_response)\n",
    "print(response_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Step 4: Define Tools for LangChain Agent\n",
    "\n",
    "Create tools that the LangChain agent can use to perform these tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.agents import Tool\n",
    "\n",
    "rate_resume_tool = Tool(\"RateResume\",\n",
    "                        rate_resume_vs_job,\n",
    "                        description=\"Rates the resume against the job listing and provides a justification.\"\n",
    ")\n",
    " \n",
    "matching_qualifications_tool = Tool(\"ListMatchingQualifications\",\n",
    "                                    list_matching_qualifications,\n",
    "                                    description=\"Lists the matching qualifications between the resume and job listing.\",\n",
    "                                    resume = long_resume,\n",
    "                                    job_listing = job_text_senior_rh\n",
    ")\n",
    "\n",
    "missing_qualifications_tool = Tool(\"ListMissingQualifications\",\n",
    "                                   list_missing_qualifications,\n",
    "                                   description=\"Lists the missing qualifications in the resume based on the job listing.\",\n",
    "                                   resume = long_resume,\n",
    "                                   job_listing = job_text_senior_rh\n",
    ")\n",
    "\n",
    "additional_info_questions_tool = Tool(\"QuestionsForAdditionalInfo\",\n",
    "                                      questions_for_additional_info,\n",
    "                                      description=\"Lists questions to determine if there is additional information that could be added to the resume.\",\n",
    "                                        matching_qualifications = response_matching,\n",
    "                                        missing_qualifications = missing_response\n",
    "                                      \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Step 5: Initialize the Language Model and Create the Agent\n",
    "\n",
    "Initialize the language model and create an agent that uses the defined tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['agent_scratchpad', 'input'] input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]} metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-tools-agent', 'lc_hub_commit_hash': 'c18672812789a3b9697656dd539edf0120285dcae36396d0b548ae42a4ed66f5'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')]\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "# Get the prompt to use - you can modify this!\n",
    "tools_prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "print(tools_prompt)\n",
    "# tools_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.prompts.chat.ChatPromptTemplate"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tools_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Config',\n",
       " 'InputType',\n",
       " 'OutputType',\n",
       " 'abatch',\n",
       " 'abatch_as_completed',\n",
       " 'aformat',\n",
       " 'aformat_messages',\n",
       " 'aformat_prompt',\n",
       " 'ainvoke',\n",
       " 'append',\n",
       " 'assign',\n",
       " 'astream',\n",
       " 'astream_events',\n",
       " 'astream_log',\n",
       " 'atransform',\n",
       " 'batch',\n",
       " 'batch_as_completed',\n",
       " 'bind',\n",
       " 'config_schema',\n",
       " 'config_specs',\n",
       " 'configurable_alternatives',\n",
       " 'configurable_fields',\n",
       " 'construct',\n",
       " 'copy',\n",
       " 'dict',\n",
       " 'extend',\n",
       " 'format',\n",
       " 'format_messages',\n",
       " 'format_prompt',\n",
       " 'from_messages',\n",
       " 'from_orm',\n",
       " 'from_role_strings',\n",
       " 'from_strings',\n",
       " 'from_template',\n",
       " 'get_graph',\n",
       " 'get_input_schema',\n",
       " 'get_lc_namespace',\n",
       " 'get_name',\n",
       " 'get_output_schema',\n",
       " 'get_prompts',\n",
       " 'input_schema',\n",
       " 'input_types',\n",
       " 'input_variables',\n",
       " 'invoke',\n",
       " 'is_lc_serializable',\n",
       " 'json',\n",
       " 'lc_attributes',\n",
       " 'lc_id',\n",
       " 'lc_secrets',\n",
       " 'map',\n",
       " 'messages',\n",
       " 'metadata',\n",
       " 'name',\n",
       " 'output_parser',\n",
       " 'output_schema',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'partial',\n",
       " 'partial_variables',\n",
       " 'pick',\n",
       " 'pipe',\n",
       " 'pretty_print',\n",
       " 'pretty_repr',\n",
       " 'save',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'stream',\n",
       " 'tags',\n",
       " 'to_json',\n",
       " 'to_json_not_implemented',\n",
       " 'transform',\n",
       " 'update_forward_refs',\n",
       " 'validate',\n",
       " 'validate_input_variables',\n",
       " 'validate_template',\n",
       " 'validate_variable_names',\n",
       " 'with_config',\n",
       " 'with_fallbacks',\n",
       " 'with_listeners',\n",
       " 'with_retry',\n",
       " 'with_types']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: not x.startswith('_'),dir(tools_prompt), ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Must replace system message with custom prompt\n",
    "tools_prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_prompt_formatted( sector=\"data science and analytics\",\n",
    "                          model_tone='friendly and encouraging',\n",
    "                          resume='', job_listing='',\n",
    "                          return_formatted=True):\n",
    "    \"\"\"Helper function for get_prompt_template. New v2.0\"\"\"\n",
    "    system_prompt_template = \"\"\"\n",
    "    You are a a specialized career coach for the {sector}, focused on delivering tailored, concise job application advice and practice.\n",
    "    You are proficient in resume analysis, cover letter guidance, and interview preparation, adapting to each user's unique requirements. \n",
    "    You maintain a professional, {model_tone} tone, ensuring advice is efficient, clear, and easily understandable, with the goal of aiding their career progression. \n",
    "    Ask the user for their resume and job listing if not provided and they are needed to answer .\" \n",
    "    \n",
    "    Use the following context, if provided, to help answer the questions:\n",
    "    \n",
    "    -------------\n",
    "    My Resume:\n",
    "    {resume}\n",
    "    \n",
    "    -------------\n",
    "    The job listing:\n",
    "    {job_listing}\n",
    "    \"\"\"  \n",
    "    system_prompt =  PromptTemplate.from_template(system_prompt_template)\n",
    "    \n",
    "    if return_formatted:\n",
    "        print(\"- Returning formatted system prompt\")\n",
    "        return system_prompt.partial(sector=sector, model_tone=model_tone, resume=resume, job_listing=job_listing)\n",
    "    else:\n",
    "        print(\"- Returning unformatted system prompt\")\n",
    "        return system_prompt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Returning formatted system prompt\n",
      "\n",
      "    You are a a specialized career coach for the {sector}, focused on delivering tailored, concise job application advice and practice.\n",
      "    You are proficient in resume analysis, cover letter guidance, and interview preparation, adapting to each user's unique requirements. \n",
      "    You maintain a professional, {model_tone} tone, ensuring advice is efficient, clear, and easily understandable, with the goal of aiding their career progression. \n",
      "    Ask the user for their resume and job listing if not provided and they are needed to answer .\" \n",
      "    \n",
      "    Use the following context, if provided, to help answer the questions:\n",
      "    \n",
      "    -------------\n",
      "    My Resume:\n",
      "    {resume}\n",
      "    \n",
      "    -------------\n",
      "    The job listing:\n",
      "    {job_listing}\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=[], partial_variables={'sector': 'data science and analytics', 'model_tone': 'friendly and encouraging', 'resume': '[LONG MASTER RESUME]  James M. Irving, Ph.D. 8222 Spadderdock Way, Laurel, MD, 20724 | (518) 322-6750 | james.irving.phd@gmail.com |  LinkedIn: james-irving-phd | GitHub: https://github.com/jirvingphd  SUMMARY V1 Innovative and enterprising data scientist with extensive experience in applying advanced data science techniques to real-world problems. Known for excellent problem-solving skills and the ability to rapidly master and implement new technologies. Committed to leveraging data to drive innovation and support data-driven decision-making. SUMMARY V2 Neuroscientist-turned-data scientist with an insatiable curiosity and a proven track record in mastering cutting-edge technologies. Exceptional communication and interpersonal skills paired with a robust history of problem-solving and critical thinking. Proven ability to self-teach complex concepts and technologies, including in vivo electrophysiology recordings and analysis. Successfully trained generations of collaborators, technicians, research fellows, and undergraduate volunteers by customizing the training to match the specific trainee’s experience and knowledge. COMPETENCIES • Data Analysis, Statistical Modeling, Machine Learning, Data Visualization • Experimental Design, Quantitative Research Methods, Time Series Analysis, Signal Processing • Cognitive Neuroscience, Behavioral Analysis, Database Management, Pattern Recognition • Python Programming, Deep Learning, Natural Language Processing, AI/LLM Implementation • Adaptive Communication Style, Problem-Solving & Critical Thinking EXPERIENCE  Coding Dojo | Remote Curriculum Writer - Data Science March 2023 - January 2024 • Developed and delivered advanced courses in Time Series Modeling, NLP, and Model Deployment, enhancing data science skills for over 100 professionals. • Expanded a 16-week boot camp to a 24-week comprehensive training program, increasing curriculum depth by 50%, which boosted learner engagement and program satisfaction. • Implemented project management and automation tools using Monday.com, optimizing workflow efficiency and resolving operational bottlenecks. • Developed and implemented Monday.com boards, including public forms and executive-facing Gantt charts, to automate internal workflows and streamline curriculum management, resolving over 100 issues. • Integrated cutting-edge technologies like APIs, Web Scraping, and Computer Vision into the curriculum, aligning educational content with evolving industry standards and practical application needs. • Developed a workflow and process to test and identify datasets for curriculum use, including template Python notebooks for preprocessing, visualization, EDA, modeling, and interpretations. • Constructed the Dojo Environment Setup for Students, ensuring compatibility with various OS and facilitating smooth installation of necessary tools and libraries. • Created and maintained a GitHub Organization for curriculum-related activities, solutions, and packages, providing a centralized resource hub for students and instructors. • Designed an extended case study for the 6-month curriculum, applying all phases of CRISP-DM to a specially constructed subset of the Ames housing dataset, enhancing practical application and understanding of the data science lifecycle. • Achieved tight deadlines throughout the year despite unexpected demands related to getting the curriculum accredited ensuring timely delivery and high-quality content for the program.  Data Science Instructor November 2021 - March 2023 • Achieved high Net Promoter Scores (NPS) exceeding 90% through engaging and interactive live lectures, demonstrating strong communication and pedagogical skills. • Revolutionized administrative workflow by automating tasks, resulting in a 99% reduction in student onboarding time—from 5 hours to just 2 minutes—dramatically enhancing operational efficiency and productivity. \\n• Developed and delivered a highly acclaimed 4-week course with perfect feedback ratings, showcasing expertise in curriculum development and instructional delivery. • Designed and led over 16 interactive live lectures and code-along projects, enhancing student participation and creating a dynamic learning environment. Flatiron School | Remote Data Science Instructor  October 2019 - October 2021 • Mentored and supervised over 60 students, helping them transition into successful data science careers with a high post-program employment rate. • Conducted weekly 90-minute study groups, accumulating over 270 hours of recorded lessons, significantly enhancing student comprehension and engagement. • Spearheaded the development and implementation of the \"Flex\" boot camp program, refining instructional design and delivery methods to meet diverse learning needs. • Created and maintained three student-progress-tracking Looker dashboards, providing real-time insights into student performance and facilitating timely interventions. • Guided students in selecting capstone project subjects, identifying job sectors of interest, and selecting appropriate data sources. Topics included time series analysis, NLP analysis, Covid cough classification (via Computer Vision),  and customer segmentation. • Offered bonus lectures on Object-Oriented Programming, dashboarding with Plotly and Dash, and advanced visualizations with matplotlib and seaborn. • Updated the entire lecture and activity content to accommodate a new teaching model, integrating recorded lectures from a national \"Central Lecturer\" with expanded hands-on activities. University of Maryland, School of Medicine | Baltimore, MD  Laboratory Manager  July 2017 - August 2018 • Ensured full compliance with regulatory standards as the lab\\'s public representative, achieving a flawless inspection record. • Successfully represented lab and guided inspectors through 4 regulatory inspections from 2 agencies, demonstrating knowledge of and compliance with protocols and regulations. • Negotiated and finalized a $100,000 technical hardware contract with vendors, optimizing procurement processes and ensuring cost-effectiveness. • Managed and administered over 20 TBs of data storage systems, ensuring data accessibility, security, and efficient retrieval. • Overhauled mouse colony management procedures, reducing housing costs by 60%  (from approximately $3.8k/month to $1.5k/month ) through strategic resource allocation and process optimization. • Created and instituted new surgery logs to simplify record keeping while ensuring regularity compliance. • Managed lab supplies and equipment purchasing, maintaining appropriate documentation and financial records. • Consolidated and encrypted all sensitive and proprietary lab information vendor accounts, log-in information, and secure information into an encrypted data vault Postdoctoral Research Fellow  June 2015 - July 2017 • Led neuroscience research using advanced techniques such as in vivo optogenetics and electrophysiology recordings, resulting in groundbreaking insights into neural functioning. • Developed approximately 30 custom analysis scripts in Matlab, NexScript, MedPC, and Arduino, enhancing data processing capabilities and facilitating comprehensive statistical analyses. • Mentored and guided a diverse team, fostering a collaborative learning environment and achieving research excellence (1 postdoc, 2 Ph.D. students, 3 lab techs, and 3 undergraduate volunteers.) • Demonstrated self-directed learning by mastering Matlab programming and creating custom-designed analysis programs for large datasets, streamlining data interpretation and enhancing research efficiency. • Researched the role of extended amygdala stress neurons in binge drinking, using multiple genetic tools and in vivo electrophysiology recordings. • Recorded changes in the activity of amygdala neurons during binge drinking. Identified neuron populations using a combination of single-unit recordings and optogenetic stimulation using targeted viral vectors. • Founded in vivo electrophysiology recordings and in vivo deep-brain structure calcium imaging in awake and behaving mice. • Directed several research projects simultaneously and managed a staff of postdoctoral fellows, technicians and student volunteers. • Programmed custom-designed analysis programs (~30) for large datasets in 4 programming languages (see skills). • Communicated research findings to mixed audiences with varying degrees of background knowledge and experience via seminars, presentations, as well as scientific posters. •  Wrote user guides on various complicated technical procedures and techniques to train lab members and collaborators. • Trained and mentored 1 research fellow, 2 graduate students, 2 lab technicians, and 3 undergraduate volunteers on several complex technical procedures and the underlying scientific principles/theory.  Graduate Research Assistant \\nSeptember 2009 -  May 2015 • Pioneered application of optogenetics with fast-scan cyclic voltammetry to discover previously unknown modulation of dopamine release via cholinergic interneurons. • Communicated research findings to audiences with varying degrees of background knowledge and familiarity in seminars, as well as scientific posters. • Trained and mentored 4 fellows, 3 graduate students, 5 lab technicians, 6 collaborators, and 1 undergraduate volunteer on various complex procedures and techniques. • Wrote user guides on various complex technical procedures and techniques to train current and future lab members Tulane University | New Orleans, LA Research Assistant January 2009 – May 2009 • Continued master’s thesis study of the role of histone deacetylase (HDAC) inhibition in aggression under chronic stress. • Tested changes in stress hormones and protein expression in stressed rats with HDAC inhibition.  DISTINCTIONS & HONORS  Happy Camper Award, University of Maryland 2012 – 2013 • Awarded to the Ph.D. student with the most positive attitude in the face of adversity, as voted by fellow students.  Summer Research Program Award, Tulane University  May 2008 to August 2008 • Awarded for distinguished scientific research, including salary.  Tulane Distinguished Scholars, Tulane University  Fall 2004 - Fall 2007 • Awarded for outstanding academic performance.  Tulane-Newcomb College Dean’s List  Fall 2004 - Fall 2005 • Awarded for achieving a GPA greater than 3.7 EDUCATION Certificate of Completion, Data Science, Flatiron School, Online (February 2019 - August 2019) • Intensive 5-month program, approximately 50 hours per week Doctor of Philosophy, Neuroscience, University of Maryland, Baltimore, MD (August 2009 - May 2015) • Including specialized optional training: Entrepreneurship in Life Sciences course, Science Communication internship. Master of Science, Neuroscience, Tulane University, New Orleans, LA (January 2008 - December 2008) Bachelor of Science, Neuroscience (Sociology Minor), Tulane University, New Orleans, LA (August 2004 - December 2007) ADDITIONAL EXPERIENCE AND SERVICE University of Maryland | Baltimore, MD Science Communication Internship – Office of Public Affairs  June 2013 - September 2013 • Selected as one of four founding members for an internship with Office of Public Affairs at the University of Maryland School of Medicine. • Trained in many aspects of university public affairs communications, relaying complex scientific material to a lay audience for both educational and promotional purposes. • Wrote press releases on university-associated research and novel findings to disseminate to inspire media coverage. • Wrote an in-depth interview featuring a university scientist’s high-impact research developing a novel anti-depressant. • Practiced live television interviews in the university’s satellite teleconferencing suite as both interviewer and interviewee. • Weekly training classes + independent assignments – 5-10 hours/week.  Entrepreneurship in Life Sciences – Interdisciplinary Course January 2014 to June 2014 • Trained by visiting experts in aspects of developing, promoting, and acquiring venture funding for a biomedical technology company.  \\n• Wrote and presented funding proposals for venture capitalist firms for a resource-sharing/saving cloud-based software solution for universities. • Wrote a business plan, patent applications, and promotional materials. • Weekly classes + group work – 10 hours/week.  Student Training Committee Member January 2013 - June 2015 • Served graduate student community as proponent and liaison to the Ph.D. program administration. • Reformed graduate program policies and procedures for the mutual benefit of students and faculty. • Advised administration on student outreach and prospective student application/interview process.  Big Brother – Program in Neuroscience  August 2010 - December 2013 • Volunteered as “Big Brother” mentor for 3 incoming doctoral students. • Advised “little brothers” on research lab choices, handling graduate coursework, and navigating university politics. Tulane University | New Orleans, LA Green Wave Ambassador Fall 2004 – Spring 2005 • Led guided tours of the campus for prospective students and their families, providing comprehensive information about academic programs, campus facilities, and student life. • Served as a host for visiting students, organizing and facilitating events to enhance their campus experience. • Engaged with visitors to answer questions, provide insights into the student experience, and assist with logistical needs. • Represented the university positively, contributing to recruitment and outreach efforts by sharing personal experiences and highlighting unique aspects of the campus community.  Student Calling Center Representative Fall 2005 – Spring 2007 • Contacted alumni to provide updates about university events, achievements, and developments. • Engaged alumni in meaningful conversations to foster a connection between them and the university. • Solicited donations, explaining the impact of their contributions on university programs, scholarships, and facilities. • Maintained accurate records of interactions and feedback, contributing to the continuous improvement of alumni relations and fundraising strategies.  PUBLICATIONS • Aroni S, Marino RAM, Girven KS, Irving JM, Cheer JF, Sparta DR. (2021) Repeated binge ethanol drinking enhances electrical activity of central amygdala corticotropin releasing factor neurons in vivo. Neuropharmacology. • Girven, K., Irving, J., Aroni, S., Sparta, D. The Role of Interconnections between the vBNST and insula in the modulation of reward processing. Manuscript in preparation. • Cachope, R., Mateo, Y., Mathur, B.N., Irving, J., Wang, H.-L., Morales, M., Lovinger, D.M., and Cheer, J.F. (2012). Selective Activation of Cholinergic Interneurons Enhances Accumbal Phasic Dopamine Release: Setting the Tone for Reward Processing. Cell Reports 2, 33–41. • Mateo, Y., Atwood, B., Wang, H.-L., Zhang, S., Irving, J., Gildish, I., Cachope, R., Bellochio, L., Guzman, M., Morales, M., Cheer, J.F., and Lovinger, D.M. Cortical afferents expressing CB1 receptors control accumbal phasic dopamine release caused by selective activation of cholinergic interneurons. Manuscript submitted for publication. POSTER ABTRACTS • Irving, J.M., Maehler, C.J., Qadir, H., Girven, K.S., Sparta, D.R. Central Amygdala Corticotropin Releasing FactorNeurons Encode and Modulate Binge Drinking and Relapse American College of Neuropsychopharmacology Annual Meeting 2016. • Irving, J.M., Maehler, C.J., Girven, K.S., Sparta, D.R. The Role of Extended Amygdala Corticotropin Neurons in Binge Ethanol Drinking. Society for Neuroscience Annual Meeting 2016. • Irving, J.M., Maehler, C.J., Sparta, D.R. Optogenetic and Pharmacogenetic Interrogation of Central Amygdala Corticotropin Neurons on Binge Ethanol Drinking. Research Society on Alcoholism Annual Meeting 2016. • Irving, J.M., Gluskin, K.H., Cheer, J.F. Optogenetic activation of accumbal fast-spiking interneurons is reinforcing. Society for Neuroscience Annual Meeting 2014. • Kashtelyan, V., Irving, J.M., Fitoussi, A., Wang, H., Morales, M., Cheer, J.F. Conditional deletion of CB1 receptors on cholinergic terminals and its functional consequences. Society for Neuroscience Meeting Annual 2014. • Irving, J.M., Mateo, Y., Cheer, J.F. Optogenetic Stimulation of Cholinergic Interneurons in the Nucleus Accumbens Causes Dopamine Release. Society for Neuroscience Meeting 2011. \\n• Irving, J.M., Mateo, Y., Cheer, J.F. Endogenous Activity of Cholinergic Interneurons in the Nucleus Accumbens is Sufficient to Evoke Dopamine Release. Graduate Research Conference 2012.  PROFERRED COMMUNICATIONS •  Irving, J.M., Sparta, D.R. “Modulation of Binge Drinking by Central Amygdala Corticotropin-Releasing Factor Neurons.” Department of Anatomy & Neurobiology, Second-Monday Program, University of Maryland School of Medicine, 2016. • Irving, J.M., Cheer, J.F. “The Role of Local Activity of the Nucleus Accumbens in Reward: Interneurons and Gamma Oscillations,”, Public Dissertation Defense, 2016. • Irving, J.M..Cheer, J.F., “Selective activation of cholinergic interneurons enhances accumbal phasic dopamine release: setting the tone for reward processing.”, Department of Anatomy & Neurobiology, Second-Monday Program, University of Maryland, Baltimore, 2012. • Irving, J.M..Cheer, J.F., “Selective activation of cholinergic interneurons enhances accumbal phasic dopamine release: setting the tone for reward processing.”, Program in Neuroscience Retreat, Notre Dame of Maryland, 2012. • Irving, J.M., Cheer, J.F., “The Role of CB1 Receptors on GABAergic Interneurons of the Nucleus Accumbens in Motivated-Behavior and Modulation of Accumbal Gamma Rhythms” University of Maryland, Baltimore, Thesis Proposal, 2014. • Irving. J.M., Cheer, J.F., “The Reinforcing Effects of Gamma-Frequency Stimulation of Accumbal Parvalbumin Interneurons and the Role of CB1 Receptors”, University of Pittsburgh, Department of Psychiatry, 2015. DATA SCIENCE PROJECTS Computer Vision Classification of American Sign Language – GitHub Link Applied tensorflow and transfer learning to classify an image as the correct letter of the ASL alphabet. • COMING SOON AI Job Application Assistant – App Link – GitHub Link Developed a Streamlit application to assist job seekers with resumes and cover letters • Developed a Streamlit application to assist job seekers by analyzing resumes and job listings using AI. • Integrated ChatGPT for tailored advice, resume improvements, and cover letter creation. • Automated job application process with AI-driven insights and recommendations. • Enhanced user experience with an interactive and user-friendly interface. • Provided actionable advice to job seekers, improving their chances of success. • Key Technologies Used: Streamlit, LangChain, OpenAI API  NLP Analysis of Amazon Reviews + AI Recommendations - GitHub Link Natural Language Processing Analysis, Modeling, and Deployment with Actionable Insights • Designed and deployed a user-centric Streamlit dashboard, integrating live sentiment predictions and interactive analysis of trends to guide strategic decision-making. • Conducted sentiment analysis on over 5 million Amazon Grocery & Gourmet Food reviews, utilizing NLP and machine learning techniques (Logistic Regression, Tf-idf vectorization) to identify key factors affecting customer satisfaction and achieve 95% accuracy in sentiment classification. • Employed Hugging Face transformers and Lang Chain/ChatGPT within the dashboard with a vectorized database used for summarization and insights, translating vast consumer feedback into actionable product enhancement strategies. • Key Technologies Used: Python, Hugging Face, OpenAI API, LangChain, spacy, scikit-learn. How to Make a Successful Movie – GitHub Link Constructing and analyzing an extensive movie database with hypothesis-testing insights + Tableau Dashboard • Integrated and normalized datasets from IMDB and TMDB API for comprehensive movie analysis. • Engineered a MySQL database on AWS RDS for robust data storage and retrieval. • Designed an interactive Tableau dashboard to communicate findings to stakeholders, enhancing decision-making processes (see GitHub link). • Applied A/B Testing to identify key factors influencing movie performance and success to provide business recommendations on what movies to create for high box office returns on factors like MPAA rating, runtime, and genre. • Key Technologies Used: Python, SQL, Tableau, TMDB API, Pandas, sqlalchemy, MySQL Workbench, statsmodels, AWS RDS How to Spot a Troll – GitHub Link Classifying Russian Troll Tweets vs Authentic Tweets • Performed EDA on 3 million tweets from accounts from the Internet Research Agency (the Russian Troll Farm) to identify an appropriate control dataset (which time period and content to extract to construct control group). •  Harvested control tweets for use in supervised learning using the TwitterAPI and TweetDeck to target the top 40 most frequent mentions, which produced 40,000 control tweets.  • Conducted natural language processing (NLP) on 80,000 tweets using nltk, Word2Vec, and Keras to tokenize, vectorize, and train word embeddings for Logistic Regression and multiple Keras Neural Networks.  • Final models achieved 90% accuracy with a dense neural network (training time: 32 sec) and 88% accuracy using Logistic Regression (training time: 0.6 sec)  • Key Technologies Used: Python, Tweepy, Neural Networks (Tensorflow & Keras),  \\nRecidivism Risk Assessment – GitHub Link Classifying which released prisoners in Iowa will return to a life of crime using Next-Gen Gradient Boosted Trees • Developed a predictive model to classify which released prisoners in Iowa are likely to return to crime using Gradient Boosted Trees. with over 70% accuracy (via scikit-learn and Catboost). • Researched Iowa\\'s state sentencing guidelines and sentencing enhancements to engineer new numerical features to capture the severity of the crimes committed and the duration of sentences. • Achieved high recall rates for predicting recidivism using XGBoost. • Identified key features influencing recidivism, such as age, release type, and offense subtype. • Provided actionable insights and recommendations to the Iowa Department of Corrections. • Implemented various machine learning models and utilized SHAP for feature importance analysis. • Key Technologies: Python, Jupyter Notebooks, XGBoost, CatBoost, SHAP, SMOTE   Forecasting Stock Market Fluctuations with Trump’s Tweets – GitHub Link Combining Natural Language Processing of Trump’s Tweets with Time Series Forecasting S&P500 Price  • Employed Natural Language Processing with nltk and word embeddings (both Word2Vec & GloVe pre-trained) to classify Trump’s tweets by S&P 500 price change (increase/decrease/no change) 60 minutes after tweeting. • Compared tweet NLP classification models using Keras neural networks (LSTM, GRU, and CNN) to predict the direction of stock market price change from NLP alone. • Used Keras neural networks for time series forecasting of S&P 500 price. • Compared multiple data sources: price alone, price + 7 market technical indicators. • Compared forecasting models: Keras LSTM vs. XGBoost Regressor. • Final model stacked NLP classification predictions with S&P 500 time series forecasting and additional tweet features (sentiment analysis with Vader, number of retweets/favorites, uppercase-to-lowercase ratio). PROFESSIONAL SKILLS Programming: Python, OOP, SQL (MySQL, SQLAlchemy), MATLAB, HTML/CSS, Git/GitHub, NexScript, MedState Notation Data Analysis: ETL (numpy, pandas), AB Testing (scipy, statsmodels), Machine Learning (scikit-learn, Catboost, XGBoost), Deep Learning (Tensorflow, Keras) Natural Language Processing: nltk, spaCy, Tensorflow, HuggingFace transformers, LLMs(OpenAI, LangChain) Visualization/Dashboarding: Plotly/Dash, Tableau, Streamlit Dashboards & Deployment, Seaborn/Matplotlib, Looker Software: Adobe Illustrator, Adobe Photoshop, GraphPad Prism, SPSS, Microsoft Office, VS Code, Jupyter Notebook/Lab, Google Suite, Plexon OfflineSorter, NeuroExplorer  LEADERSHIP & COMMUNITY INVOLVEMENT SECTION IS WORK-IN-PROGRESS • Key Club Lt. Governor \\n', 'job_listing': 'Robert Half\\nSenior Data Scientist\\n$115K/yr - $173K/yr···Mid-Senior level\\n10,001+ employees · Staffing and Recruiting\\n2 company alumni work here·3 school alumni work here\\n3 of 3 skills match your profile - you may be a good fit\\nApply SavedCalifornia, United States·4 hours ago·29 applicants\\nRemoteFull-time\\nAm I a good fit for this job? How can I best position myself fo\\nMeet the hiring team\\nKelli Griffin3rd\\nLead Talent Acquisition Partner\\nJob posterMessage\\nAbout the job\\nReady to revolutionize the future of data-driven decision-making? Join our\\npioneering Data Science team as we embark on an exciting journey to unlock\\ninsights, drive innovation, and shape the landscape of our organization\\'s success.\\nIf you\\'re passionate about leveraging cutting-edge generative AI technologies\\nand transforming raw data into actionable insight, we want you on our team!\"\\nThe Senior Data Scientist will be responsible for leading advanced data analytics\\nprojects, leveraging Azure and Microsoft data services. This role demands a deep\\nunderstanding of data science methodologies, machine learning algorithms, and\\nbig data technologies. The incumbent will work closely with cross-functional\\nteams to understand business needs and formulate and execute data science\\nsolutions that drive significant business impact.\\nKey Responsibilities:\\nData Analytics and Modeling:\\nDevelop and implement advanced predictive models and statistical\\nanalysis using a variety of machine learning algorithms.\\nSuggest algorithms or models appropriate for specific use cases and\\napplications.\\nAnalyze and extract relevant information from large amounts of historical\\nbusiness data to help automate and optimize key processes with business\\nteams.\\nApply technical solutions to business problems and questions using large\\nscale data analytics and machine learning; create highly calibrated\\nsolutions for business problems.\\nWork closely with software engineering teams to drive real-time model\\nexperiments, implementations and new feature creations.\\nContinuously evaluate and refine models based on performance metrics.\\nUtilize cloud technologies such as Azure Machine Learning, Azure\\nDatabricks, and other Microsoft data services for data processing, modelHomeMy NetworkJobsMessagingNotificationsMe\\n For BusinessLear\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 1/7\\nSee lessbuilding, and deployment.\\nLarge Language Model Fine-tuning:\\nEnhance and evolve the performance of large language models by\\nrefining their capabilities through targeted fine-tuning.\\nSteer both the research trajectory and the practical engineering efforts of\\nthe team.\\nFormulate and enact algorithms for model enhancement, tweak critical\\nhyperparameters, and heighten overall model efficiency.\\nGuarantee the integrity and relevance of datasets by conducting thorough\\npreprocessing and data analysis within the fine-tuning workflow.\\nConduct assessments on fine-tuned models, making necessary\\nmodifications to boost their effectiveness.\\nFoster a cooperative environment within the team, providing guidance to\\npeers to ensure a smooth fine-tuning operation that yields superior\\nresults.\\nStay at the forefront of advancements in large language model\\ntechnologies and applications, perpetually refining technical expertise in\\nmodel fine-tuning.\\nData Management and Strategy:\\nCollaborate with IT and data engineering teams in an enterprise setting to\\nintegrate data science solutions into the broader tech stack and data\\nstrategy.\\nBusiness Collaboration and Insights:\\nWork closely with business stakeholders to identify opportunities for\\nleveraging company data to drive business solutions.\\nTranslate complex data-driven findings into actionable business insights\\nand communicate these effectively to non-technical stakeholders.\\nResearch and Development:\\nStay abreast of industry trends and advancements in data science and\\nAzure technologies.\\nConduct research to explore new methodologies and technologies that\\ncan enhance the organization\\'s data analytics capabilities.\\nPreferred Qualifications and Skills:\\nBachelor\\'s degree in Statistics, Computer Science, Mathematics or\\nequivalent required; Master\\'s or PhD highly preferred\\n5 years of professional experience in data science, with a record in\\ndesigning and implementing large-scale data science projects.\\n5 years of industry experience in predictive modeling and large data\\nanalysis\\nKnowledge of open-source large language models and experience with\\nevaluating and recommending appropriate models for specific use cases.\\n3+ years of experience in using big data platforms and technologies such\\nas Hadoop, Azure data lake, Azure Cosmos DB, Pig, Hive, HBase, etc.\\n3+ years of hands-on experience in statistical modeling, data mining,\\nlarge data analysis and predictive modeling; text mining a major plus\\n3+ years of experience in regression, classification and clustering\\nmethods such as GLM, LR, SVM, LVQ, SOM, Neural Networks\\nExperience with two or more of the following: Python, PERL, Matlab or\\nScala\\nExpertise in various machine learning frameworks and libraries (e.g.,\\nTensorFlow, PyTorch, Scikit-learn).\\nExcellent analytical, problem-solving, and communication skills.\\nExcellent communication skills, with a proven ability to translate technical\\nfindings into business recommendations and strategies.\\nCertifications in Azure data services or advanced analytics preferred\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 2/7\\nSet alert for similar jobs\\nData Scientist, California, United StatesSet alert\\nEmployer-provided\\nPay range in California, United States\\nExact compensation may vary based on skills, experience, and location.\\nBase salary\\n$115,000/yr - $173,000/yr\\nFeatured benefits\\nMedical insurance\\nVision insurance\\nDental insurance\\n401(k)\\nTuition assistance\\nQualifications\\n3 of 3 skills match your profile - you may be a good fit\\nSkills added by the job poster\\nBig Data · Large Language Models (LLM) · Natural Language Processing (NLP)\\nAdditional skills among applicants\\nData Analysis · Data Science · Data Visualization · Machine Learning · Microsoft\\nPower BI · Python (Programming Language) · R (Programming Language) · SQL …\\nShow qualification details\\nPut your best foot forward with your application\\nHire a resume writer\\nGet a resume review\\nSee how you compare to other applicants\\nApplicants for this job\\n29Applicants\\n29Applicants in the past day\\nApplicant seniority level\\n15 Entry level applicants\\n10 Senior level applicants\\n1 Director level applicant Youʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 3/7\\nApplicant education level\\n19%have a Doctor of Philosophy (Similar to you)\\n59%have a Master\\'s Degree\\n15%have a Bachelor\\'s Degree\\n7%have other degrees\\nApplicants are in these locations\\n1-5 applicants\\nNew York City Metropolitan\\nArea\\n1-5 applicants\\nGreater Pittsburgh Region\\n1-5 applicants\\nDallas-Fort Worth Metroplex\\nSee if Robert Half is hiring people like you\\nThe latest hiring trends.\\n29,307\\nTotal employees3%\\nCompany-wide\\n2 year growth2%\\nEngineering\\n2 year growth\\nMedian employee tenure ‧6 yearsMay 2022 Nov 2022 May 2023 Nov 2023 May 202410,00020,00030,00040,000\\nRobert Half hires candidates from some of these companies and schools\\nRobert Half hired 2 people\\nfrom Coding Dojo.See all\\nRobert Half hired 3 people from\\nFlatiron School.See all\\nEngineering hires at Robert Half came\\nfrom these companies and more.Engineering hires at Robert Half came\\nfrom these schools and more.\\nReset map\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 4/7\\nMore jobsShow more Premium insightsSee more companies See more schools\\nAbout the company\\nRobert Half\\n3,147,224 followersFollow\\nStaffing and Recruiting•10,001+ employees•29,320 on LinkedIn\\nTrending employee content PreviousNext\\nShow more\\nRobert Half, the worldʼs first and largest specialized talent solutions firm,\\nconnects opportunities at great companies with highly skilled job seekers. We\\noffer contract, temporary and permanent placement solutions for roles in financ……show more\\nInterested in working with us in the future?\\nPrivately share your profile with our recruiters – youʼll be noted as\\nexpressing interest for up to a year.Learn more\\nIʼm interested\\nLead Data Scientist\\nCigniti Technologies\\nUnited States (Remote)\\nActively recruiting\\n4 weeks agoEasy ApplySenior Data Scientist\\nDTN\\nUnited States (Remote)\\nActively recruiting\\n2 weeks ago\\nData Scientist\\nQuantum World Technologies…\\nUnited States (Remote)\\nActively recruiting\\nSr. Data Scientist\\nAKASA\\nUnited States (Remote)\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 5/7\\nSee more jobs like this10 minutes agoEasy Apply 2 weeks ago\\nSenior Data Scientist\\nPhreesia\\nUnited States (Remote)\\nActively recruiting\\n3 weeks agoSr. Data Scientist\\nAppFolio\\nUnited States (Remote)\\nActively recruiting\\n1 week ago\\nSenior Data Scientist,\\nProduct\\nUniswap Labs\\nNew York, NY (Remote)\\nActively recruiting\\n1 week agoSenior Data Scientist\\nAustin Fraser\\nUnited States (Remote)\\nActively recruiting\\n6 days agoEasy Apply\\nSenior Data Scientist\\nWebflow\\nUnited States (Remote)\\n1 company alum works here\\n2 days agoSenior Data Scientist\\nXOi\\nUnited States (Remote)\\n2 weeks ago\\nLead Data Scientist\\nLittle Place Labs\\nUnited States (Remote)\\n1 month agoEasy ApplyStaff Data Scientist\\nDemandbase\\nUnited States (Remote)\\n3 school alumni work here\\n3 weeks ago\\nLearn skills to get a new job with these courses\\n135,378 viewers\\nThe New Rules of Work\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 6/7\\nAbout Accessibility Talent Solutions\\nCommunity Guidelines Careers Marketing Solutions\\nAd Choices Advertising\\nSales Solutions Mobile Small Business\\nSafety CenterQuestions?\\nVisit our Help Center.\\nManage your account and privacy\\nGo to your Settings.\\nRecommendation transparency\\nLearn more about Recommended Content.Select Language\\nLinkedIn Corporation © 2024282,784 viewers\\nShow more on LinkedIn Learning\\nDeveloping Your Professional Image in a New Job\\nLooking for talent?Post a job\\nPrivacy & Terms\\nEnglish (English)\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 7/7\\n'}, template='\\n    You are a a specialized career coach for the {sector}, focused on delivering tailored, concise job application advice and practice.\\n    You are proficient in resume analysis, cover letter guidance, and interview preparation, adapting to each user\\'s unique requirements. \\n    You maintain a professional, {model_tone} tone, ensuring advice is efficient, clear, and easily understandable, with the goal of aiding their career progression. \\n    Ask the user for their resume and job listing if not provided and they are needed to answer .\" \\n    \\n    Use the following context, if provided, to help answer the questions:\\n    \\n    -------------\\n    My Resume:\\n    {resume}\\n    \\n    -------------\\n    The job listing:\\n    {job_listing}\\n    ')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the new sytem prompt to use for the tools agent\n",
    "system_prompt = get_system_prompt_formatted(sector=\"data science and analytics\",\n",
    "                            model_tone='friendly and encouraging',\n",
    "                            resume=long_resume, job_listing=job_text_senior_rh,\n",
    "                            return_formatted=True)\n",
    "print(system_prompt.template)\n",
    "system_prompt\n",
    "# print(system_prompt.for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=\" You are a a specialized career coach for the {sector}, focused on delivering tailored, concise job application advice and practice.  You are proficient in resume analysis, cover letter guidance, and interview preparation, adapting to each user's unique requirements.  You maintain a professional, {model_tone} tone, ensuring advice is efficient, clear, and easily understandable,  with the goal of aiding their career progression. Ask the user for their resume and job listing if not provided and they are needed to asnwer .\\nUse the following context, if provided, to help answer the questions:\\n\\nHere is my resume:\\n-------------\\n {resume}\\n\\n Here is the job listing:\\n-------------\\n{job}\\n\\n \"),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools_prompt.messages[0].prompt = get_system_prompt_str(with_context=True, with_onet=False)\n",
    "tools_prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Returning formatted system prompt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'chat_history': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], partial_variables={'sector': 'data science and analytics', 'model_tone': 'friendly and encouraging', 'resume': '[LONG MASTER RESUME]  James M. Irving, Ph.D. 8222 Spadderdock Way, Laurel, MD, 20724 | (518) 322-6750 | james.irving.phd@gmail.com |  LinkedIn: james-irving-phd | GitHub: https://github.com/jirvingphd  SUMMARY V1 Innovative and enterprising data scientist with extensive experience in applying advanced data science techniques to real-world problems. Known for excellent problem-solving skills and the ability to rapidly master and implement new technologies. Committed to leveraging data to drive innovation and support data-driven decision-making. SUMMARY V2 Neuroscientist-turned-data scientist with an insatiable curiosity and a proven track record in mastering cutting-edge technologies. Exceptional communication and interpersonal skills paired with a robust history of problem-solving and critical thinking. Proven ability to self-teach complex concepts and technologies, including in vivo electrophysiology recordings and analysis. Successfully trained generations of collaborators, technicians, research fellows, and undergraduate volunteers by customizing the training to match the specific trainee’s experience and knowledge. COMPETENCIES • Data Analysis, Statistical Modeling, Machine Learning, Data Visualization • Experimental Design, Quantitative Research Methods, Time Series Analysis, Signal Processing • Cognitive Neuroscience, Behavioral Analysis, Database Management, Pattern Recognition • Python Programming, Deep Learning, Natural Language Processing, AI/LLM Implementation • Adaptive Communication Style, Problem-Solving & Critical Thinking EXPERIENCE  Coding Dojo | Remote Curriculum Writer - Data Science March 2023 - January 2024 • Developed and delivered advanced courses in Time Series Modeling, NLP, and Model Deployment, enhancing data science skills for over 100 professionals. • Expanded a 16-week boot camp to a 24-week comprehensive training program, increasing curriculum depth by 50%, which boosted learner engagement and program satisfaction. • Implemented project management and automation tools using Monday.com, optimizing workflow efficiency and resolving operational bottlenecks. • Developed and implemented Monday.com boards, including public forms and executive-facing Gantt charts, to automate internal workflows and streamline curriculum management, resolving over 100 issues. • Integrated cutting-edge technologies like APIs, Web Scraping, and Computer Vision into the curriculum, aligning educational content with evolving industry standards and practical application needs. • Developed a workflow and process to test and identify datasets for curriculum use, including template Python notebooks for preprocessing, visualization, EDA, modeling, and interpretations. • Constructed the Dojo Environment Setup for Students, ensuring compatibility with various OS and facilitating smooth installation of necessary tools and libraries. • Created and maintained a GitHub Organization for curriculum-related activities, solutions, and packages, providing a centralized resource hub for students and instructors. • Designed an extended case study for the 6-month curriculum, applying all phases of CRISP-DM to a specially constructed subset of the Ames housing dataset, enhancing practical application and understanding of the data science lifecycle. • Achieved tight deadlines throughout the year despite unexpected demands related to getting the curriculum accredited ensuring timely delivery and high-quality content for the program.  Data Science Instructor November 2021 - March 2023 • Achieved high Net Promoter Scores (NPS) exceeding 90% through engaging and interactive live lectures, demonstrating strong communication and pedagogical skills. • Revolutionized administrative workflow by automating tasks, resulting in a 99% reduction in student onboarding time—from 5 hours to just 2 minutes—dramatically enhancing operational efficiency and productivity. \\n• Developed and delivered a highly acclaimed 4-week course with perfect feedback ratings, showcasing expertise in curriculum development and instructional delivery. • Designed and led over 16 interactive live lectures and code-along projects, enhancing student participation and creating a dynamic learning environment. Flatiron School | Remote Data Science Instructor  October 2019 - October 2021 • Mentored and supervised over 60 students, helping them transition into successful data science careers with a high post-program employment rate. • Conducted weekly 90-minute study groups, accumulating over 270 hours of recorded lessons, significantly enhancing student comprehension and engagement. • Spearheaded the development and implementation of the \"Flex\" boot camp program, refining instructional design and delivery methods to meet diverse learning needs. • Created and maintained three student-progress-tracking Looker dashboards, providing real-time insights into student performance and facilitating timely interventions. • Guided students in selecting capstone project subjects, identifying job sectors of interest, and selecting appropriate data sources. Topics included time series analysis, NLP analysis, Covid cough classification (via Computer Vision),  and customer segmentation. • Offered bonus lectures on Object-Oriented Programming, dashboarding with Plotly and Dash, and advanced visualizations with matplotlib and seaborn. • Updated the entire lecture and activity content to accommodate a new teaching model, integrating recorded lectures from a national \"Central Lecturer\" with expanded hands-on activities. University of Maryland, School of Medicine | Baltimore, MD  Laboratory Manager  July 2017 - August 2018 • Ensured full compliance with regulatory standards as the lab\\'s public representative, achieving a flawless inspection record. • Successfully represented lab and guided inspectors through 4 regulatory inspections from 2 agencies, demonstrating knowledge of and compliance with protocols and regulations. • Negotiated and finalized a $100,000 technical hardware contract with vendors, optimizing procurement processes and ensuring cost-effectiveness. • Managed and administered over 20 TBs of data storage systems, ensuring data accessibility, security, and efficient retrieval. • Overhauled mouse colony management procedures, reducing housing costs by 60%  (from approximately $3.8k/month to $1.5k/month ) through strategic resource allocation and process optimization. • Created and instituted new surgery logs to simplify record keeping while ensuring regularity compliance. • Managed lab supplies and equipment purchasing, maintaining appropriate documentation and financial records. • Consolidated and encrypted all sensitive and proprietary lab information vendor accounts, log-in information, and secure information into an encrypted data vault Postdoctoral Research Fellow  June 2015 - July 2017 • Led neuroscience research using advanced techniques such as in vivo optogenetics and electrophysiology recordings, resulting in groundbreaking insights into neural functioning. • Developed approximately 30 custom analysis scripts in Matlab, NexScript, MedPC, and Arduino, enhancing data processing capabilities and facilitating comprehensive statistical analyses. • Mentored and guided a diverse team, fostering a collaborative learning environment and achieving research excellence (1 postdoc, 2 Ph.D. students, 3 lab techs, and 3 undergraduate volunteers.) • Demonstrated self-directed learning by mastering Matlab programming and creating custom-designed analysis programs for large datasets, streamlining data interpretation and enhancing research efficiency. • Researched the role of extended amygdala stress neurons in binge drinking, using multiple genetic tools and in vivo electrophysiology recordings. • Recorded changes in the activity of amygdala neurons during binge drinking. Identified neuron populations using a combination of single-unit recordings and optogenetic stimulation using targeted viral vectors. • Founded in vivo electrophysiology recordings and in vivo deep-brain structure calcium imaging in awake and behaving mice. • Directed several research projects simultaneously and managed a staff of postdoctoral fellows, technicians and student volunteers. • Programmed custom-designed analysis programs (~30) for large datasets in 4 programming languages (see skills). • Communicated research findings to mixed audiences with varying degrees of background knowledge and experience via seminars, presentations, as well as scientific posters. •  Wrote user guides on various complicated technical procedures and techniques to train lab members and collaborators. • Trained and mentored 1 research fellow, 2 graduate students, 2 lab technicians, and 3 undergraduate volunteers on several complex technical procedures and the underlying scientific principles/theory.  Graduate Research Assistant \\nSeptember 2009 -  May 2015 • Pioneered application of optogenetics with fast-scan cyclic voltammetry to discover previously unknown modulation of dopamine release via cholinergic interneurons. • Communicated research findings to audiences with varying degrees of background knowledge and familiarity in seminars, as well as scientific posters. • Trained and mentored 4 fellows, 3 graduate students, 5 lab technicians, 6 collaborators, and 1 undergraduate volunteer on various complex procedures and techniques. • Wrote user guides on various complex technical procedures and techniques to train current and future lab members Tulane University | New Orleans, LA Research Assistant January 2009 – May 2009 • Continued master’s thesis study of the role of histone deacetylase (HDAC) inhibition in aggression under chronic stress. • Tested changes in stress hormones and protein expression in stressed rats with HDAC inhibition.  DISTINCTIONS & HONORS  Happy Camper Award, University of Maryland 2012 – 2013 • Awarded to the Ph.D. student with the most positive attitude in the face of adversity, as voted by fellow students.  Summer Research Program Award, Tulane University  May 2008 to August 2008 • Awarded for distinguished scientific research, including salary.  Tulane Distinguished Scholars, Tulane University  Fall 2004 - Fall 2007 • Awarded for outstanding academic performance.  Tulane-Newcomb College Dean’s List  Fall 2004 - Fall 2005 • Awarded for achieving a GPA greater than 3.7 EDUCATION Certificate of Completion, Data Science, Flatiron School, Online (February 2019 - August 2019) • Intensive 5-month program, approximately 50 hours per week Doctor of Philosophy, Neuroscience, University of Maryland, Baltimore, MD (August 2009 - May 2015) • Including specialized optional training: Entrepreneurship in Life Sciences course, Science Communication internship. Master of Science, Neuroscience, Tulane University, New Orleans, LA (January 2008 - December 2008) Bachelor of Science, Neuroscience (Sociology Minor), Tulane University, New Orleans, LA (August 2004 - December 2007) ADDITIONAL EXPERIENCE AND SERVICE University of Maryland | Baltimore, MD Science Communication Internship – Office of Public Affairs  June 2013 - September 2013 • Selected as one of four founding members for an internship with Office of Public Affairs at the University of Maryland School of Medicine. • Trained in many aspects of university public affairs communications, relaying complex scientific material to a lay audience for both educational and promotional purposes. • Wrote press releases on university-associated research and novel findings to disseminate to inspire media coverage. • Wrote an in-depth interview featuring a university scientist’s high-impact research developing a novel anti-depressant. • Practiced live television interviews in the university’s satellite teleconferencing suite as both interviewer and interviewee. • Weekly training classes + independent assignments – 5-10 hours/week.  Entrepreneurship in Life Sciences – Interdisciplinary Course January 2014 to June 2014 • Trained by visiting experts in aspects of developing, promoting, and acquiring venture funding for a biomedical technology company.  \\n• Wrote and presented funding proposals for venture capitalist firms for a resource-sharing/saving cloud-based software solution for universities. • Wrote a business plan, patent applications, and promotional materials. • Weekly classes + group work – 10 hours/week.  Student Training Committee Member January 2013 - June 2015 • Served graduate student community as proponent and liaison to the Ph.D. program administration. • Reformed graduate program policies and procedures for the mutual benefit of students and faculty. • Advised administration on student outreach and prospective student application/interview process.  Big Brother – Program in Neuroscience  August 2010 - December 2013 • Volunteered as “Big Brother” mentor for 3 incoming doctoral students. • Advised “little brothers” on research lab choices, handling graduate coursework, and navigating university politics. Tulane University | New Orleans, LA Green Wave Ambassador Fall 2004 – Spring 2005 • Led guided tours of the campus for prospective students and their families, providing comprehensive information about academic programs, campus facilities, and student life. • Served as a host for visiting students, organizing and facilitating events to enhance their campus experience. • Engaged with visitors to answer questions, provide insights into the student experience, and assist with logistical needs. • Represented the university positively, contributing to recruitment and outreach efforts by sharing personal experiences and highlighting unique aspects of the campus community.  Student Calling Center Representative Fall 2005 – Spring 2007 • Contacted alumni to provide updates about university events, achievements, and developments. • Engaged alumni in meaningful conversations to foster a connection between them and the university. • Solicited donations, explaining the impact of their contributions on university programs, scholarships, and facilities. • Maintained accurate records of interactions and feedback, contributing to the continuous improvement of alumni relations and fundraising strategies.  PUBLICATIONS • Aroni S, Marino RAM, Girven KS, Irving JM, Cheer JF, Sparta DR. (2021) Repeated binge ethanol drinking enhances electrical activity of central amygdala corticotropin releasing factor neurons in vivo. Neuropharmacology. • Girven, K., Irving, J., Aroni, S., Sparta, D. The Role of Interconnections between the vBNST and insula in the modulation of reward processing. Manuscript in preparation. • Cachope, R., Mateo, Y., Mathur, B.N., Irving, J., Wang, H.-L., Morales, M., Lovinger, D.M., and Cheer, J.F. (2012). Selective Activation of Cholinergic Interneurons Enhances Accumbal Phasic Dopamine Release: Setting the Tone for Reward Processing. Cell Reports 2, 33–41. • Mateo, Y., Atwood, B., Wang, H.-L., Zhang, S., Irving, J., Gildish, I., Cachope, R., Bellochio, L., Guzman, M., Morales, M., Cheer, J.F., and Lovinger, D.M. Cortical afferents expressing CB1 receptors control accumbal phasic dopamine release caused by selective activation of cholinergic interneurons. Manuscript submitted for publication. POSTER ABTRACTS • Irving, J.M., Maehler, C.J., Qadir, H., Girven, K.S., Sparta, D.R. Central Amygdala Corticotropin Releasing FactorNeurons Encode and Modulate Binge Drinking and Relapse American College of Neuropsychopharmacology Annual Meeting 2016. • Irving, J.M., Maehler, C.J., Girven, K.S., Sparta, D.R. The Role of Extended Amygdala Corticotropin Neurons in Binge Ethanol Drinking. Society for Neuroscience Annual Meeting 2016. • Irving, J.M., Maehler, C.J., Sparta, D.R. Optogenetic and Pharmacogenetic Interrogation of Central Amygdala Corticotropin Neurons on Binge Ethanol Drinking. Research Society on Alcoholism Annual Meeting 2016. • Irving, J.M., Gluskin, K.H., Cheer, J.F. Optogenetic activation of accumbal fast-spiking interneurons is reinforcing. Society for Neuroscience Annual Meeting 2014. • Kashtelyan, V., Irving, J.M., Fitoussi, A., Wang, H., Morales, M., Cheer, J.F. Conditional deletion of CB1 receptors on cholinergic terminals and its functional consequences. Society for Neuroscience Meeting Annual 2014. • Irving, J.M., Mateo, Y., Cheer, J.F. Optogenetic Stimulation of Cholinergic Interneurons in the Nucleus Accumbens Causes Dopamine Release. Society for Neuroscience Meeting 2011. \\n• Irving, J.M., Mateo, Y., Cheer, J.F. Endogenous Activity of Cholinergic Interneurons in the Nucleus Accumbens is Sufficient to Evoke Dopamine Release. Graduate Research Conference 2012.  PROFERRED COMMUNICATIONS •  Irving, J.M., Sparta, D.R. “Modulation of Binge Drinking by Central Amygdala Corticotropin-Releasing Factor Neurons.” Department of Anatomy & Neurobiology, Second-Monday Program, University of Maryland School of Medicine, 2016. • Irving, J.M., Cheer, J.F. “The Role of Local Activity of the Nucleus Accumbens in Reward: Interneurons and Gamma Oscillations,”, Public Dissertation Defense, 2016. • Irving, J.M..Cheer, J.F., “Selective activation of cholinergic interneurons enhances accumbal phasic dopamine release: setting the tone for reward processing.”, Department of Anatomy & Neurobiology, Second-Monday Program, University of Maryland, Baltimore, 2012. • Irving, J.M..Cheer, J.F., “Selective activation of cholinergic interneurons enhances accumbal phasic dopamine release: setting the tone for reward processing.”, Program in Neuroscience Retreat, Notre Dame of Maryland, 2012. • Irving, J.M., Cheer, J.F., “The Role of CB1 Receptors on GABAergic Interneurons of the Nucleus Accumbens in Motivated-Behavior and Modulation of Accumbal Gamma Rhythms” University of Maryland, Baltimore, Thesis Proposal, 2014. • Irving. J.M., Cheer, J.F., “The Reinforcing Effects of Gamma-Frequency Stimulation of Accumbal Parvalbumin Interneurons and the Role of CB1 Receptors”, University of Pittsburgh, Department of Psychiatry, 2015. DATA SCIENCE PROJECTS Computer Vision Classification of American Sign Language – GitHub Link Applied tensorflow and transfer learning to classify an image as the correct letter of the ASL alphabet. • COMING SOON AI Job Application Assistant – App Link – GitHub Link Developed a Streamlit application to assist job seekers with resumes and cover letters • Developed a Streamlit application to assist job seekers by analyzing resumes and job listings using AI. • Integrated ChatGPT for tailored advice, resume improvements, and cover letter creation. • Automated job application process with AI-driven insights and recommendations. • Enhanced user experience with an interactive and user-friendly interface. • Provided actionable advice to job seekers, improving their chances of success. • Key Technologies Used: Streamlit, LangChain, OpenAI API  NLP Analysis of Amazon Reviews + AI Recommendations - GitHub Link Natural Language Processing Analysis, Modeling, and Deployment with Actionable Insights • Designed and deployed a user-centric Streamlit dashboard, integrating live sentiment predictions and interactive analysis of trends to guide strategic decision-making. • Conducted sentiment analysis on over 5 million Amazon Grocery & Gourmet Food reviews, utilizing NLP and machine learning techniques (Logistic Regression, Tf-idf vectorization) to identify key factors affecting customer satisfaction and achieve 95% accuracy in sentiment classification. • Employed Hugging Face transformers and Lang Chain/ChatGPT within the dashboard with a vectorized database used for summarization and insights, translating vast consumer feedback into actionable product enhancement strategies. • Key Technologies Used: Python, Hugging Face, OpenAI API, LangChain, spacy, scikit-learn. How to Make a Successful Movie – GitHub Link Constructing and analyzing an extensive movie database with hypothesis-testing insights + Tableau Dashboard • Integrated and normalized datasets from IMDB and TMDB API for comprehensive movie analysis. • Engineered a MySQL database on AWS RDS for robust data storage and retrieval. • Designed an interactive Tableau dashboard to communicate findings to stakeholders, enhancing decision-making processes (see GitHub link). • Applied A/B Testing to identify key factors influencing movie performance and success to provide business recommendations on what movies to create for high box office returns on factors like MPAA rating, runtime, and genre. • Key Technologies Used: Python, SQL, Tableau, TMDB API, Pandas, sqlalchemy, MySQL Workbench, statsmodels, AWS RDS How to Spot a Troll – GitHub Link Classifying Russian Troll Tweets vs Authentic Tweets • Performed EDA on 3 million tweets from accounts from the Internet Research Agency (the Russian Troll Farm) to identify an appropriate control dataset (which time period and content to extract to construct control group). •  Harvested control tweets for use in supervised learning using the TwitterAPI and TweetDeck to target the top 40 most frequent mentions, which produced 40,000 control tweets.  • Conducted natural language processing (NLP) on 80,000 tweets using nltk, Word2Vec, and Keras to tokenize, vectorize, and train word embeddings for Logistic Regression and multiple Keras Neural Networks.  • Final models achieved 90% accuracy with a dense neural network (training time: 32 sec) and 88% accuracy using Logistic Regression (training time: 0.6 sec)  • Key Technologies Used: Python, Tweepy, Neural Networks (Tensorflow & Keras),  \\nRecidivism Risk Assessment – GitHub Link Classifying which released prisoners in Iowa will return to a life of crime using Next-Gen Gradient Boosted Trees • Developed a predictive model to classify which released prisoners in Iowa are likely to return to crime using Gradient Boosted Trees. with over 70% accuracy (via scikit-learn and Catboost). • Researched Iowa\\'s state sentencing guidelines and sentencing enhancements to engineer new numerical features to capture the severity of the crimes committed and the duration of sentences. • Achieved high recall rates for predicting recidivism using XGBoost. • Identified key features influencing recidivism, such as age, release type, and offense subtype. • Provided actionable insights and recommendations to the Iowa Department of Corrections. • Implemented various machine learning models and utilized SHAP for feature importance analysis. • Key Technologies: Python, Jupyter Notebooks, XGBoost, CatBoost, SHAP, SMOTE   Forecasting Stock Market Fluctuations with Trump’s Tweets – GitHub Link Combining Natural Language Processing of Trump’s Tweets with Time Series Forecasting S&P500 Price  • Employed Natural Language Processing with nltk and word embeddings (both Word2Vec & GloVe pre-trained) to classify Trump’s tweets by S&P 500 price change (increase/decrease/no change) 60 minutes after tweeting. • Compared tweet NLP classification models using Keras neural networks (LSTM, GRU, and CNN) to predict the direction of stock market price change from NLP alone. • Used Keras neural networks for time series forecasting of S&P 500 price. • Compared multiple data sources: price alone, price + 7 market technical indicators. • Compared forecasting models: Keras LSTM vs. XGBoost Regressor. • Final model stacked NLP classification predictions with S&P 500 time series forecasting and additional tweet features (sentiment analysis with Vader, number of retweets/favorites, uppercase-to-lowercase ratio). PROFESSIONAL SKILLS Programming: Python, OOP, SQL (MySQL, SQLAlchemy), MATLAB, HTML/CSS, Git/GitHub, NexScript, MedState Notation Data Analysis: ETL (numpy, pandas), AB Testing (scipy, statsmodels), Machine Learning (scikit-learn, Catboost, XGBoost), Deep Learning (Tensorflow, Keras) Natural Language Processing: nltk, spaCy, Tensorflow, HuggingFace transformers, LLMs(OpenAI, LangChain) Visualization/Dashboarding: Plotly/Dash, Tableau, Streamlit Dashboards & Deployment, Seaborn/Matplotlib, Looker Software: Adobe Illustrator, Adobe Photoshop, GraphPad Prism, SPSS, Microsoft Office, VS Code, Jupyter Notebook/Lab, Google Suite, Plexon OfflineSorter, NeuroExplorer  LEADERSHIP & COMMUNITY INVOLVEMENT SECTION IS WORK-IN-PROGRESS • Key Club Lt. Governor \\n', 'job_listing': 'Robert Half\\nSenior Data Scientist\\n$115K/yr - $173K/yr···Mid-Senior level\\n10,001+ employees · Staffing and Recruiting\\n2 company alumni work here·3 school alumni work here\\n3 of 3 skills match your profile - you may be a good fit\\nApply SavedCalifornia, United States·4 hours ago·29 applicants\\nRemoteFull-time\\nAm I a good fit for this job? How can I best position myself fo\\nMeet the hiring team\\nKelli Griffin3rd\\nLead Talent Acquisition Partner\\nJob posterMessage\\nAbout the job\\nReady to revolutionize the future of data-driven decision-making? Join our\\npioneering Data Science team as we embark on an exciting journey to unlock\\ninsights, drive innovation, and shape the landscape of our organization\\'s success.\\nIf you\\'re passionate about leveraging cutting-edge generative AI technologies\\nand transforming raw data into actionable insight, we want you on our team!\"\\nThe Senior Data Scientist will be responsible for leading advanced data analytics\\nprojects, leveraging Azure and Microsoft data services. This role demands a deep\\nunderstanding of data science methodologies, machine learning algorithms, and\\nbig data technologies. The incumbent will work closely with cross-functional\\nteams to understand business needs and formulate and execute data science\\nsolutions that drive significant business impact.\\nKey Responsibilities:\\nData Analytics and Modeling:\\nDevelop and implement advanced predictive models and statistical\\nanalysis using a variety of machine learning algorithms.\\nSuggest algorithms or models appropriate for specific use cases and\\napplications.\\nAnalyze and extract relevant information from large amounts of historical\\nbusiness data to help automate and optimize key processes with business\\nteams.\\nApply technical solutions to business problems and questions using large\\nscale data analytics and machine learning; create highly calibrated\\nsolutions for business problems.\\nWork closely with software engineering teams to drive real-time model\\nexperiments, implementations and new feature creations.\\nContinuously evaluate and refine models based on performance metrics.\\nUtilize cloud technologies such as Azure Machine Learning, Azure\\nDatabricks, and other Microsoft data services for data processing, modelHomeMy NetworkJobsMessagingNotificationsMe\\n For BusinessLear\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 1/7\\nSee lessbuilding, and deployment.\\nLarge Language Model Fine-tuning:\\nEnhance and evolve the performance of large language models by\\nrefining their capabilities through targeted fine-tuning.\\nSteer both the research trajectory and the practical engineering efforts of\\nthe team.\\nFormulate and enact algorithms for model enhancement, tweak critical\\nhyperparameters, and heighten overall model efficiency.\\nGuarantee the integrity and relevance of datasets by conducting thorough\\npreprocessing and data analysis within the fine-tuning workflow.\\nConduct assessments on fine-tuned models, making necessary\\nmodifications to boost their effectiveness.\\nFoster a cooperative environment within the team, providing guidance to\\npeers to ensure a smooth fine-tuning operation that yields superior\\nresults.\\nStay at the forefront of advancements in large language model\\ntechnologies and applications, perpetually refining technical expertise in\\nmodel fine-tuning.\\nData Management and Strategy:\\nCollaborate with IT and data engineering teams in an enterprise setting to\\nintegrate data science solutions into the broader tech stack and data\\nstrategy.\\nBusiness Collaboration and Insights:\\nWork closely with business stakeholders to identify opportunities for\\nleveraging company data to drive business solutions.\\nTranslate complex data-driven findings into actionable business insights\\nand communicate these effectively to non-technical stakeholders.\\nResearch and Development:\\nStay abreast of industry trends and advancements in data science and\\nAzure technologies.\\nConduct research to explore new methodologies and technologies that\\ncan enhance the organization\\'s data analytics capabilities.\\nPreferred Qualifications and Skills:\\nBachelor\\'s degree in Statistics, Computer Science, Mathematics or\\nequivalent required; Master\\'s or PhD highly preferred\\n5 years of professional experience in data science, with a record in\\ndesigning and implementing large-scale data science projects.\\n5 years of industry experience in predictive modeling and large data\\nanalysis\\nKnowledge of open-source large language models and experience with\\nevaluating and recommending appropriate models for specific use cases.\\n3+ years of experience in using big data platforms and technologies such\\nas Hadoop, Azure data lake, Azure Cosmos DB, Pig, Hive, HBase, etc.\\n3+ years of hands-on experience in statistical modeling, data mining,\\nlarge data analysis and predictive modeling; text mining a major plus\\n3+ years of experience in regression, classification and clustering\\nmethods such as GLM, LR, SVM, LVQ, SOM, Neural Networks\\nExperience with two or more of the following: Python, PERL, Matlab or\\nScala\\nExpertise in various machine learning frameworks and libraries (e.g.,\\nTensorFlow, PyTorch, Scikit-learn).\\nExcellent analytical, problem-solving, and communication skills.\\nExcellent communication skills, with a proven ability to translate technical\\nfindings into business recommendations and strategies.\\nCertifications in Azure data services or advanced analytics preferred\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 2/7\\nSet alert for similar jobs\\nData Scientist, California, United StatesSet alert\\nEmployer-provided\\nPay range in California, United States\\nExact compensation may vary based on skills, experience, and location.\\nBase salary\\n$115,000/yr - $173,000/yr\\nFeatured benefits\\nMedical insurance\\nVision insurance\\nDental insurance\\n401(k)\\nTuition assistance\\nQualifications\\n3 of 3 skills match your profile - you may be a good fit\\nSkills added by the job poster\\nBig Data · Large Language Models (LLM) · Natural Language Processing (NLP)\\nAdditional skills among applicants\\nData Analysis · Data Science · Data Visualization · Machine Learning · Microsoft\\nPower BI · Python (Programming Language) · R (Programming Language) · SQL …\\nShow qualification details\\nPut your best foot forward with your application\\nHire a resume writer\\nGet a resume review\\nSee how you compare to other applicants\\nApplicants for this job\\n29Applicants\\n29Applicants in the past day\\nApplicant seniority level\\n15 Entry level applicants\\n10 Senior level applicants\\n1 Director level applicant Youʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 3/7\\nApplicant education level\\n19%have a Doctor of Philosophy (Similar to you)\\n59%have a Master\\'s Degree\\n15%have a Bachelor\\'s Degree\\n7%have other degrees\\nApplicants are in these locations\\n1-5 applicants\\nNew York City Metropolitan\\nArea\\n1-5 applicants\\nGreater Pittsburgh Region\\n1-5 applicants\\nDallas-Fort Worth Metroplex\\nSee if Robert Half is hiring people like you\\nThe latest hiring trends.\\n29,307\\nTotal employees3%\\nCompany-wide\\n2 year growth2%\\nEngineering\\n2 year growth\\nMedian employee tenure ‧6 yearsMay 2022 Nov 2022 May 2023 Nov 2023 May 202410,00020,00030,00040,000\\nRobert Half hires candidates from some of these companies and schools\\nRobert Half hired 2 people\\nfrom Coding Dojo.See all\\nRobert Half hired 3 people from\\nFlatiron School.See all\\nEngineering hires at Robert Half came\\nfrom these companies and more.Engineering hires at Robert Half came\\nfrom these schools and more.\\nReset map\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 4/7\\nMore jobsShow more Premium insightsSee more companies See more schools\\nAbout the company\\nRobert Half\\n3,147,224 followersFollow\\nStaffing and Recruiting•10,001+ employees•29,320 on LinkedIn\\nTrending employee content PreviousNext\\nShow more\\nRobert Half, the worldʼs first and largest specialized talent solutions firm,\\nconnects opportunities at great companies with highly skilled job seekers. We\\noffer contract, temporary and permanent placement solutions for roles in financ……show more\\nInterested in working with us in the future?\\nPrivately share your profile with our recruiters – youʼll be noted as\\nexpressing interest for up to a year.Learn more\\nIʼm interested\\nLead Data Scientist\\nCigniti Technologies\\nUnited States (Remote)\\nActively recruiting\\n4 weeks agoEasy ApplySenior Data Scientist\\nDTN\\nUnited States (Remote)\\nActively recruiting\\n2 weeks ago\\nData Scientist\\nQuantum World Technologies…\\nUnited States (Remote)\\nActively recruiting\\nSr. Data Scientist\\nAKASA\\nUnited States (Remote)\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 5/7\\nSee more jobs like this10 minutes agoEasy Apply 2 weeks ago\\nSenior Data Scientist\\nPhreesia\\nUnited States (Remote)\\nActively recruiting\\n3 weeks agoSr. Data Scientist\\nAppFolio\\nUnited States (Remote)\\nActively recruiting\\n1 week ago\\nSenior Data Scientist,\\nProduct\\nUniswap Labs\\nNew York, NY (Remote)\\nActively recruiting\\n1 week agoSenior Data Scientist\\nAustin Fraser\\nUnited States (Remote)\\nActively recruiting\\n6 days agoEasy Apply\\nSenior Data Scientist\\nWebflow\\nUnited States (Remote)\\n1 company alum works here\\n2 days agoSenior Data Scientist\\nXOi\\nUnited States (Remote)\\n2 weeks ago\\nLead Data Scientist\\nLittle Place Labs\\nUnited States (Remote)\\n1 month agoEasy ApplyStaff Data Scientist\\nDemandbase\\nUnited States (Remote)\\n3 school alumni work here\\n3 weeks ago\\nLearn skills to get a new job with these courses\\n135,378 viewers\\nThe New Rules of Work\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 6/7\\nAbout Accessibility Talent Solutions\\nCommunity Guidelines Careers Marketing Solutions\\nAd Choices Advertising\\nSales Solutions Mobile Small Business\\nSafety CenterQuestions?\\nVisit our Help Center.\\nManage your account and privacy\\nGo to your Settings.\\nRecommendation transparency\\nLearn more about Recommended Content.Select Language\\nLinkedIn Corporation © 2024282,784 viewers\\nShow more on LinkedIn Learning\\nDeveloping Your Professional Image in a New Job\\nLooking for talent?Post a job\\nPrivacy & Terms\\nEnglish (English)\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 7/7\\n'}, template='\\n    You are a a specialized career coach for the {sector}, focused on delivering tailored, concise job application advice and practice.\\n    You are proficient in resume analysis, cover letter guidance, and interview preparation, adapting to each user\\'s unique requirements. \\n    You maintain a professional, {model_tone} tone, ensuring advice is efficient, clear, and easily understandable, with the goal of aiding their career progression. \\n    Ask the user for their resume and job listing if not provided and they are needed to answer .\" \\n    \\n    Use the following context, if provided, to help answer the questions:\\n    \\n    -------------\\n    My Resume:\\n    {resume}\\n    \\n    -------------\\n    The job listing:\\n    {job_listing}\\n    ')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, PromptTemplate, MessagesPlaceholder\n",
    "\n",
    "#Custom tools prompt\n",
    "system_prompt = get_system_prompt_formatted(sector=\"data science and analytics\",\n",
    "                            model_tone='friendly and encouraging',\n",
    "                            resume=long_resume, job_listing=job_text_senior_rh,\n",
    "                            return_formatted=True)\n",
    "\n",
    "manual_tools_prompt_messages = [SystemMessagePromptTemplate(prompt=system_prompt),\n",
    "                       MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
    "                       HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
    "                       MessagesPlaceholder(variable_name='agent_scratchpad')]\n",
    "\n",
    "manual_tools_prompt  = ChatPromptTemplate.from_messages(manual_tools_prompt_messages)\n",
    "manual_tools_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agent_scratchpad', 'input']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_tools_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'chat_history': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], partial_variables={'sector': 'data science and analytics', 'model_tone': 'friendly and encouraging', 'resume': '[LONG MASTER RESUME]  James M. Irving, Ph.D. 8222 Spadderdock Way, Laurel, MD, 20724 | (518) 322-6750 | james.irving.phd@gmail.com |  LinkedIn: james-irving-phd | GitHub: https://github.com/jirvingphd  SUMMARY V1 Innovative and enterprising data scientist with extensive experience in applying advanced data science techniques to real-world problems. Known for excellent problem-solving skills and the ability to rapidly master and implement new technologies. Committed to leveraging data to drive innovation and support data-driven decision-making. SUMMARY V2 Neuroscientist-turned-data scientist with an insatiable curiosity and a proven track record in mastering cutting-edge technologies. Exceptional communication and interpersonal skills paired with a robust history of problem-solving and critical thinking. Proven ability to self-teach complex concepts and technologies, including in vivo electrophysiology recordings and analysis. Successfully trained generations of collaborators, technicians, research fellows, and undergraduate volunteers by customizing the training to match the specific trainee’s experience and knowledge. COMPETENCIES • Data Analysis, Statistical Modeling, Machine Learning, Data Visualization • Experimental Design, Quantitative Research Methods, Time Series Analysis, Signal Processing • Cognitive Neuroscience, Behavioral Analysis, Database Management, Pattern Recognition • Python Programming, Deep Learning, Natural Language Processing, AI/LLM Implementation • Adaptive Communication Style, Problem-Solving & Critical Thinking EXPERIENCE  Coding Dojo | Remote Curriculum Writer - Data Science March 2023 - January 2024 • Developed and delivered advanced courses in Time Series Modeling, NLP, and Model Deployment, enhancing data science skills for over 100 professionals. • Expanded a 16-week boot camp to a 24-week comprehensive training program, increasing curriculum depth by 50%, which boosted learner engagement and program satisfaction. • Implemented project management and automation tools using Monday.com, optimizing workflow efficiency and resolving operational bottlenecks. • Developed and implemented Monday.com boards, including public forms and executive-facing Gantt charts, to automate internal workflows and streamline curriculum management, resolving over 100 issues. • Integrated cutting-edge technologies like APIs, Web Scraping, and Computer Vision into the curriculum, aligning educational content with evolving industry standards and practical application needs. • Developed a workflow and process to test and identify datasets for curriculum use, including template Python notebooks for preprocessing, visualization, EDA, modeling, and interpretations. • Constructed the Dojo Environment Setup for Students, ensuring compatibility with various OS and facilitating smooth installation of necessary tools and libraries. • Created and maintained a GitHub Organization for curriculum-related activities, solutions, and packages, providing a centralized resource hub for students and instructors. • Designed an extended case study for the 6-month curriculum, applying all phases of CRISP-DM to a specially constructed subset of the Ames housing dataset, enhancing practical application and understanding of the data science lifecycle. • Achieved tight deadlines throughout the year despite unexpected demands related to getting the curriculum accredited ensuring timely delivery and high-quality content for the program.  Data Science Instructor November 2021 - March 2023 • Achieved high Net Promoter Scores (NPS) exceeding 90% through engaging and interactive live lectures, demonstrating strong communication and pedagogical skills. • Revolutionized administrative workflow by automating tasks, resulting in a 99% reduction in student onboarding time—from 5 hours to just 2 minutes—dramatically enhancing operational efficiency and productivity. \\n• Developed and delivered a highly acclaimed 4-week course with perfect feedback ratings, showcasing expertise in curriculum development and instructional delivery. • Designed and led over 16 interactive live lectures and code-along projects, enhancing student participation and creating a dynamic learning environment. Flatiron School | Remote Data Science Instructor  October 2019 - October 2021 • Mentored and supervised over 60 students, helping them transition into successful data science careers with a high post-program employment rate. • Conducted weekly 90-minute study groups, accumulating over 270 hours of recorded lessons, significantly enhancing student comprehension and engagement. • Spearheaded the development and implementation of the \"Flex\" boot camp program, refining instructional design and delivery methods to meet diverse learning needs. • Created and maintained three student-progress-tracking Looker dashboards, providing real-time insights into student performance and facilitating timely interventions. • Guided students in selecting capstone project subjects, identifying job sectors of interest, and selecting appropriate data sources. Topics included time series analysis, NLP analysis, Covid cough classification (via Computer Vision),  and customer segmentation. • Offered bonus lectures on Object-Oriented Programming, dashboarding with Plotly and Dash, and advanced visualizations with matplotlib and seaborn. • Updated the entire lecture and activity content to accommodate a new teaching model, integrating recorded lectures from a national \"Central Lecturer\" with expanded hands-on activities. University of Maryland, School of Medicine | Baltimore, MD  Laboratory Manager  July 2017 - August 2018 • Ensured full compliance with regulatory standards as the lab\\'s public representative, achieving a flawless inspection record. • Successfully represented lab and guided inspectors through 4 regulatory inspections from 2 agencies, demonstrating knowledge of and compliance with protocols and regulations. • Negotiated and finalized a $100,000 technical hardware contract with vendors, optimizing procurement processes and ensuring cost-effectiveness. • Managed and administered over 20 TBs of data storage systems, ensuring data accessibility, security, and efficient retrieval. • Overhauled mouse colony management procedures, reducing housing costs by 60%  (from approximately $3.8k/month to $1.5k/month ) through strategic resource allocation and process optimization. • Created and instituted new surgery logs to simplify record keeping while ensuring regularity compliance. • Managed lab supplies and equipment purchasing, maintaining appropriate documentation and financial records. • Consolidated and encrypted all sensitive and proprietary lab information vendor accounts, log-in information, and secure information into an encrypted data vault Postdoctoral Research Fellow  June 2015 - July 2017 • Led neuroscience research using advanced techniques such as in vivo optogenetics and electrophysiology recordings, resulting in groundbreaking insights into neural functioning. • Developed approximately 30 custom analysis scripts in Matlab, NexScript, MedPC, and Arduino, enhancing data processing capabilities and facilitating comprehensive statistical analyses. • Mentored and guided a diverse team, fostering a collaborative learning environment and achieving research excellence (1 postdoc, 2 Ph.D. students, 3 lab techs, and 3 undergraduate volunteers.) • Demonstrated self-directed learning by mastering Matlab programming and creating custom-designed analysis programs for large datasets, streamlining data interpretation and enhancing research efficiency. • Researched the role of extended amygdala stress neurons in binge drinking, using multiple genetic tools and in vivo electrophysiology recordings. • Recorded changes in the activity of amygdala neurons during binge drinking. Identified neuron populations using a combination of single-unit recordings and optogenetic stimulation using targeted viral vectors. • Founded in vivo electrophysiology recordings and in vivo deep-brain structure calcium imaging in awake and behaving mice. • Directed several research projects simultaneously and managed a staff of postdoctoral fellows, technicians and student volunteers. • Programmed custom-designed analysis programs (~30) for large datasets in 4 programming languages (see skills). • Communicated research findings to mixed audiences with varying degrees of background knowledge and experience via seminars, presentations, as well as scientific posters. •  Wrote user guides on various complicated technical procedures and techniques to train lab members and collaborators. • Trained and mentored 1 research fellow, 2 graduate students, 2 lab technicians, and 3 undergraduate volunteers on several complex technical procedures and the underlying scientific principles/theory.  Graduate Research Assistant \\nSeptember 2009 -  May 2015 • Pioneered application of optogenetics with fast-scan cyclic voltammetry to discover previously unknown modulation of dopamine release via cholinergic interneurons. • Communicated research findings to audiences with varying degrees of background knowledge and familiarity in seminars, as well as scientific posters. • Trained and mentored 4 fellows, 3 graduate students, 5 lab technicians, 6 collaborators, and 1 undergraduate volunteer on various complex procedures and techniques. • Wrote user guides on various complex technical procedures and techniques to train current and future lab members Tulane University | New Orleans, LA Research Assistant January 2009 – May 2009 • Continued master’s thesis study of the role of histone deacetylase (HDAC) inhibition in aggression under chronic stress. • Tested changes in stress hormones and protein expression in stressed rats with HDAC inhibition.  DISTINCTIONS & HONORS  Happy Camper Award, University of Maryland 2012 – 2013 • Awarded to the Ph.D. student with the most positive attitude in the face of adversity, as voted by fellow students.  Summer Research Program Award, Tulane University  May 2008 to August 2008 • Awarded for distinguished scientific research, including salary.  Tulane Distinguished Scholars, Tulane University  Fall 2004 - Fall 2007 • Awarded for outstanding academic performance.  Tulane-Newcomb College Dean’s List  Fall 2004 - Fall 2005 • Awarded for achieving a GPA greater than 3.7 EDUCATION Certificate of Completion, Data Science, Flatiron School, Online (February 2019 - August 2019) • Intensive 5-month program, approximately 50 hours per week Doctor of Philosophy, Neuroscience, University of Maryland, Baltimore, MD (August 2009 - May 2015) • Including specialized optional training: Entrepreneurship in Life Sciences course, Science Communication internship. Master of Science, Neuroscience, Tulane University, New Orleans, LA (January 2008 - December 2008) Bachelor of Science, Neuroscience (Sociology Minor), Tulane University, New Orleans, LA (August 2004 - December 2007) ADDITIONAL EXPERIENCE AND SERVICE University of Maryland | Baltimore, MD Science Communication Internship – Office of Public Affairs  June 2013 - September 2013 • Selected as one of four founding members for an internship with Office of Public Affairs at the University of Maryland School of Medicine. • Trained in many aspects of university public affairs communications, relaying complex scientific material to a lay audience for both educational and promotional purposes. • Wrote press releases on university-associated research and novel findings to disseminate to inspire media coverage. • Wrote an in-depth interview featuring a university scientist’s high-impact research developing a novel anti-depressant. • Practiced live television interviews in the university’s satellite teleconferencing suite as both interviewer and interviewee. • Weekly training classes + independent assignments – 5-10 hours/week.  Entrepreneurship in Life Sciences – Interdisciplinary Course January 2014 to June 2014 • Trained by visiting experts in aspects of developing, promoting, and acquiring venture funding for a biomedical technology company.  \\n• Wrote and presented funding proposals for venture capitalist firms for a resource-sharing/saving cloud-based software solution for universities. • Wrote a business plan, patent applications, and promotional materials. • Weekly classes + group work – 10 hours/week.  Student Training Committee Member January 2013 - June 2015 • Served graduate student community as proponent and liaison to the Ph.D. program administration. • Reformed graduate program policies and procedures for the mutual benefit of students and faculty. • Advised administration on student outreach and prospective student application/interview process.  Big Brother – Program in Neuroscience  August 2010 - December 2013 • Volunteered as “Big Brother” mentor for 3 incoming doctoral students. • Advised “little brothers” on research lab choices, handling graduate coursework, and navigating university politics. Tulane University | New Orleans, LA Green Wave Ambassador Fall 2004 – Spring 2005 • Led guided tours of the campus for prospective students and their families, providing comprehensive information about academic programs, campus facilities, and student life. • Served as a host for visiting students, organizing and facilitating events to enhance their campus experience. • Engaged with visitors to answer questions, provide insights into the student experience, and assist with logistical needs. • Represented the university positively, contributing to recruitment and outreach efforts by sharing personal experiences and highlighting unique aspects of the campus community.  Student Calling Center Representative Fall 2005 – Spring 2007 • Contacted alumni to provide updates about university events, achievements, and developments. • Engaged alumni in meaningful conversations to foster a connection between them and the university. • Solicited donations, explaining the impact of their contributions on university programs, scholarships, and facilities. • Maintained accurate records of interactions and feedback, contributing to the continuous improvement of alumni relations and fundraising strategies.  PUBLICATIONS • Aroni S, Marino RAM, Girven KS, Irving JM, Cheer JF, Sparta DR. (2021) Repeated binge ethanol drinking enhances electrical activity of central amygdala corticotropin releasing factor neurons in vivo. Neuropharmacology. • Girven, K., Irving, J., Aroni, S., Sparta, D. The Role of Interconnections between the vBNST and insula in the modulation of reward processing. Manuscript in preparation. • Cachope, R., Mateo, Y., Mathur, B.N., Irving, J., Wang, H.-L., Morales, M., Lovinger, D.M., and Cheer, J.F. (2012). Selective Activation of Cholinergic Interneurons Enhances Accumbal Phasic Dopamine Release: Setting the Tone for Reward Processing. Cell Reports 2, 33–41. • Mateo, Y., Atwood, B., Wang, H.-L., Zhang, S., Irving, J., Gildish, I., Cachope, R., Bellochio, L., Guzman, M., Morales, M., Cheer, J.F., and Lovinger, D.M. Cortical afferents expressing CB1 receptors control accumbal phasic dopamine release caused by selective activation of cholinergic interneurons. Manuscript submitted for publication. POSTER ABTRACTS • Irving, J.M., Maehler, C.J., Qadir, H., Girven, K.S., Sparta, D.R. Central Amygdala Corticotropin Releasing FactorNeurons Encode and Modulate Binge Drinking and Relapse American College of Neuropsychopharmacology Annual Meeting 2016. • Irving, J.M., Maehler, C.J., Girven, K.S., Sparta, D.R. The Role of Extended Amygdala Corticotropin Neurons in Binge Ethanol Drinking. Society for Neuroscience Annual Meeting 2016. • Irving, J.M., Maehler, C.J., Sparta, D.R. Optogenetic and Pharmacogenetic Interrogation of Central Amygdala Corticotropin Neurons on Binge Ethanol Drinking. Research Society on Alcoholism Annual Meeting 2016. • Irving, J.M., Gluskin, K.H., Cheer, J.F. Optogenetic activation of accumbal fast-spiking interneurons is reinforcing. Society for Neuroscience Annual Meeting 2014. • Kashtelyan, V., Irving, J.M., Fitoussi, A., Wang, H., Morales, M., Cheer, J.F. Conditional deletion of CB1 receptors on cholinergic terminals and its functional consequences. Society for Neuroscience Meeting Annual 2014. • Irving, J.M., Mateo, Y., Cheer, J.F. Optogenetic Stimulation of Cholinergic Interneurons in the Nucleus Accumbens Causes Dopamine Release. Society for Neuroscience Meeting 2011. \\n• Irving, J.M., Mateo, Y., Cheer, J.F. Endogenous Activity of Cholinergic Interneurons in the Nucleus Accumbens is Sufficient to Evoke Dopamine Release. Graduate Research Conference 2012.  PROFERRED COMMUNICATIONS •  Irving, J.M., Sparta, D.R. “Modulation of Binge Drinking by Central Amygdala Corticotropin-Releasing Factor Neurons.” Department of Anatomy & Neurobiology, Second-Monday Program, University of Maryland School of Medicine, 2016. • Irving, J.M., Cheer, J.F. “The Role of Local Activity of the Nucleus Accumbens in Reward: Interneurons and Gamma Oscillations,”, Public Dissertation Defense, 2016. • Irving, J.M..Cheer, J.F., “Selective activation of cholinergic interneurons enhances accumbal phasic dopamine release: setting the tone for reward processing.”, Department of Anatomy & Neurobiology, Second-Monday Program, University of Maryland, Baltimore, 2012. • Irving, J.M..Cheer, J.F., “Selective activation of cholinergic interneurons enhances accumbal phasic dopamine release: setting the tone for reward processing.”, Program in Neuroscience Retreat, Notre Dame of Maryland, 2012. • Irving, J.M., Cheer, J.F., “The Role of CB1 Receptors on GABAergic Interneurons of the Nucleus Accumbens in Motivated-Behavior and Modulation of Accumbal Gamma Rhythms” University of Maryland, Baltimore, Thesis Proposal, 2014. • Irving. J.M., Cheer, J.F., “The Reinforcing Effects of Gamma-Frequency Stimulation of Accumbal Parvalbumin Interneurons and the Role of CB1 Receptors”, University of Pittsburgh, Department of Psychiatry, 2015. DATA SCIENCE PROJECTS Computer Vision Classification of American Sign Language – GitHub Link Applied tensorflow and transfer learning to classify an image as the correct letter of the ASL alphabet. • COMING SOON AI Job Application Assistant – App Link – GitHub Link Developed a Streamlit application to assist job seekers with resumes and cover letters • Developed a Streamlit application to assist job seekers by analyzing resumes and job listings using AI. • Integrated ChatGPT for tailored advice, resume improvements, and cover letter creation. • Automated job application process with AI-driven insights and recommendations. • Enhanced user experience with an interactive and user-friendly interface. • Provided actionable advice to job seekers, improving their chances of success. • Key Technologies Used: Streamlit, LangChain, OpenAI API  NLP Analysis of Amazon Reviews + AI Recommendations - GitHub Link Natural Language Processing Analysis, Modeling, and Deployment with Actionable Insights • Designed and deployed a user-centric Streamlit dashboard, integrating live sentiment predictions and interactive analysis of trends to guide strategic decision-making. • Conducted sentiment analysis on over 5 million Amazon Grocery & Gourmet Food reviews, utilizing NLP and machine learning techniques (Logistic Regression, Tf-idf vectorization) to identify key factors affecting customer satisfaction and achieve 95% accuracy in sentiment classification. • Employed Hugging Face transformers and Lang Chain/ChatGPT within the dashboard with a vectorized database used for summarization and insights, translating vast consumer feedback into actionable product enhancement strategies. • Key Technologies Used: Python, Hugging Face, OpenAI API, LangChain, spacy, scikit-learn. How to Make a Successful Movie – GitHub Link Constructing and analyzing an extensive movie database with hypothesis-testing insights + Tableau Dashboard • Integrated and normalized datasets from IMDB and TMDB API for comprehensive movie analysis. • Engineered a MySQL database on AWS RDS for robust data storage and retrieval. • Designed an interactive Tableau dashboard to communicate findings to stakeholders, enhancing decision-making processes (see GitHub link). • Applied A/B Testing to identify key factors influencing movie performance and success to provide business recommendations on what movies to create for high box office returns on factors like MPAA rating, runtime, and genre. • Key Technologies Used: Python, SQL, Tableau, TMDB API, Pandas, sqlalchemy, MySQL Workbench, statsmodels, AWS RDS How to Spot a Troll – GitHub Link Classifying Russian Troll Tweets vs Authentic Tweets • Performed EDA on 3 million tweets from accounts from the Internet Research Agency (the Russian Troll Farm) to identify an appropriate control dataset (which time period and content to extract to construct control group). •  Harvested control tweets for use in supervised learning using the TwitterAPI and TweetDeck to target the top 40 most frequent mentions, which produced 40,000 control tweets.  • Conducted natural language processing (NLP) on 80,000 tweets using nltk, Word2Vec, and Keras to tokenize, vectorize, and train word embeddings for Logistic Regression and multiple Keras Neural Networks.  • Final models achieved 90% accuracy with a dense neural network (training time: 32 sec) and 88% accuracy using Logistic Regression (training time: 0.6 sec)  • Key Technologies Used: Python, Tweepy, Neural Networks (Tensorflow & Keras),  \\nRecidivism Risk Assessment – GitHub Link Classifying which released prisoners in Iowa will return to a life of crime using Next-Gen Gradient Boosted Trees • Developed a predictive model to classify which released prisoners in Iowa are likely to return to crime using Gradient Boosted Trees. with over 70% accuracy (via scikit-learn and Catboost). • Researched Iowa\\'s state sentencing guidelines and sentencing enhancements to engineer new numerical features to capture the severity of the crimes committed and the duration of sentences. • Achieved high recall rates for predicting recidivism using XGBoost. • Identified key features influencing recidivism, such as age, release type, and offense subtype. • Provided actionable insights and recommendations to the Iowa Department of Corrections. • Implemented various machine learning models and utilized SHAP for feature importance analysis. • Key Technologies: Python, Jupyter Notebooks, XGBoost, CatBoost, SHAP, SMOTE   Forecasting Stock Market Fluctuations with Trump’s Tweets – GitHub Link Combining Natural Language Processing of Trump’s Tweets with Time Series Forecasting S&P500 Price  • Employed Natural Language Processing with nltk and word embeddings (both Word2Vec & GloVe pre-trained) to classify Trump’s tweets by S&P 500 price change (increase/decrease/no change) 60 minutes after tweeting. • Compared tweet NLP classification models using Keras neural networks (LSTM, GRU, and CNN) to predict the direction of stock market price change from NLP alone. • Used Keras neural networks for time series forecasting of S&P 500 price. • Compared multiple data sources: price alone, price + 7 market technical indicators. • Compared forecasting models: Keras LSTM vs. XGBoost Regressor. • Final model stacked NLP classification predictions with S&P 500 time series forecasting and additional tweet features (sentiment analysis with Vader, number of retweets/favorites, uppercase-to-lowercase ratio). PROFESSIONAL SKILLS Programming: Python, OOP, SQL (MySQL, SQLAlchemy), MATLAB, HTML/CSS, Git/GitHub, NexScript, MedState Notation Data Analysis: ETL (numpy, pandas), AB Testing (scipy, statsmodels), Machine Learning (scikit-learn, Catboost, XGBoost), Deep Learning (Tensorflow, Keras) Natural Language Processing: nltk, spaCy, Tensorflow, HuggingFace transformers, LLMs(OpenAI, LangChain) Visualization/Dashboarding: Plotly/Dash, Tableau, Streamlit Dashboards & Deployment, Seaborn/Matplotlib, Looker Software: Adobe Illustrator, Adobe Photoshop, GraphPad Prism, SPSS, Microsoft Office, VS Code, Jupyter Notebook/Lab, Google Suite, Plexon OfflineSorter, NeuroExplorer  LEADERSHIP & COMMUNITY INVOLVEMENT SECTION IS WORK-IN-PROGRESS • Key Club Lt. Governor \\n', 'job_listing': 'Robert Half\\nSenior Data Scientist\\n$115K/yr - $173K/yr···Mid-Senior level\\n10,001+ employees · Staffing and Recruiting\\n2 company alumni work here·3 school alumni work here\\n3 of 3 skills match your profile - you may be a good fit\\nApply SavedCalifornia, United States·4 hours ago·29 applicants\\nRemoteFull-time\\nAm I a good fit for this job? How can I best position myself fo\\nMeet the hiring team\\nKelli Griffin3rd\\nLead Talent Acquisition Partner\\nJob posterMessage\\nAbout the job\\nReady to revolutionize the future of data-driven decision-making? Join our\\npioneering Data Science team as we embark on an exciting journey to unlock\\ninsights, drive innovation, and shape the landscape of our organization\\'s success.\\nIf you\\'re passionate about leveraging cutting-edge generative AI technologies\\nand transforming raw data into actionable insight, we want you on our team!\"\\nThe Senior Data Scientist will be responsible for leading advanced data analytics\\nprojects, leveraging Azure and Microsoft data services. This role demands a deep\\nunderstanding of data science methodologies, machine learning algorithms, and\\nbig data technologies. The incumbent will work closely with cross-functional\\nteams to understand business needs and formulate and execute data science\\nsolutions that drive significant business impact.\\nKey Responsibilities:\\nData Analytics and Modeling:\\nDevelop and implement advanced predictive models and statistical\\nanalysis using a variety of machine learning algorithms.\\nSuggest algorithms or models appropriate for specific use cases and\\napplications.\\nAnalyze and extract relevant information from large amounts of historical\\nbusiness data to help automate and optimize key processes with business\\nteams.\\nApply technical solutions to business problems and questions using large\\nscale data analytics and machine learning; create highly calibrated\\nsolutions for business problems.\\nWork closely with software engineering teams to drive real-time model\\nexperiments, implementations and new feature creations.\\nContinuously evaluate and refine models based on performance metrics.\\nUtilize cloud technologies such as Azure Machine Learning, Azure\\nDatabricks, and other Microsoft data services for data processing, modelHomeMy NetworkJobsMessagingNotificationsMe\\n For BusinessLear\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 1/7\\nSee lessbuilding, and deployment.\\nLarge Language Model Fine-tuning:\\nEnhance and evolve the performance of large language models by\\nrefining their capabilities through targeted fine-tuning.\\nSteer both the research trajectory and the practical engineering efforts of\\nthe team.\\nFormulate and enact algorithms for model enhancement, tweak critical\\nhyperparameters, and heighten overall model efficiency.\\nGuarantee the integrity and relevance of datasets by conducting thorough\\npreprocessing and data analysis within the fine-tuning workflow.\\nConduct assessments on fine-tuned models, making necessary\\nmodifications to boost their effectiveness.\\nFoster a cooperative environment within the team, providing guidance to\\npeers to ensure a smooth fine-tuning operation that yields superior\\nresults.\\nStay at the forefront of advancements in large language model\\ntechnologies and applications, perpetually refining technical expertise in\\nmodel fine-tuning.\\nData Management and Strategy:\\nCollaborate with IT and data engineering teams in an enterprise setting to\\nintegrate data science solutions into the broader tech stack and data\\nstrategy.\\nBusiness Collaboration and Insights:\\nWork closely with business stakeholders to identify opportunities for\\nleveraging company data to drive business solutions.\\nTranslate complex data-driven findings into actionable business insights\\nand communicate these effectively to non-technical stakeholders.\\nResearch and Development:\\nStay abreast of industry trends and advancements in data science and\\nAzure technologies.\\nConduct research to explore new methodologies and technologies that\\ncan enhance the organization\\'s data analytics capabilities.\\nPreferred Qualifications and Skills:\\nBachelor\\'s degree in Statistics, Computer Science, Mathematics or\\nequivalent required; Master\\'s or PhD highly preferred\\n5 years of professional experience in data science, with a record in\\ndesigning and implementing large-scale data science projects.\\n5 years of industry experience in predictive modeling and large data\\nanalysis\\nKnowledge of open-source large language models and experience with\\nevaluating and recommending appropriate models for specific use cases.\\n3+ years of experience in using big data platforms and technologies such\\nas Hadoop, Azure data lake, Azure Cosmos DB, Pig, Hive, HBase, etc.\\n3+ years of hands-on experience in statistical modeling, data mining,\\nlarge data analysis and predictive modeling; text mining a major plus\\n3+ years of experience in regression, classification and clustering\\nmethods such as GLM, LR, SVM, LVQ, SOM, Neural Networks\\nExperience with two or more of the following: Python, PERL, Matlab or\\nScala\\nExpertise in various machine learning frameworks and libraries (e.g.,\\nTensorFlow, PyTorch, Scikit-learn).\\nExcellent analytical, problem-solving, and communication skills.\\nExcellent communication skills, with a proven ability to translate technical\\nfindings into business recommendations and strategies.\\nCertifications in Azure data services or advanced analytics preferred\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 2/7\\nSet alert for similar jobs\\nData Scientist, California, United StatesSet alert\\nEmployer-provided\\nPay range in California, United States\\nExact compensation may vary based on skills, experience, and location.\\nBase salary\\n$115,000/yr - $173,000/yr\\nFeatured benefits\\nMedical insurance\\nVision insurance\\nDental insurance\\n401(k)\\nTuition assistance\\nQualifications\\n3 of 3 skills match your profile - you may be a good fit\\nSkills added by the job poster\\nBig Data · Large Language Models (LLM) · Natural Language Processing (NLP)\\nAdditional skills among applicants\\nData Analysis · Data Science · Data Visualization · Machine Learning · Microsoft\\nPower BI · Python (Programming Language) · R (Programming Language) · SQL …\\nShow qualification details\\nPut your best foot forward with your application\\nHire a resume writer\\nGet a resume review\\nSee how you compare to other applicants\\nApplicants for this job\\n29Applicants\\n29Applicants in the past day\\nApplicant seniority level\\n15 Entry level applicants\\n10 Senior level applicants\\n1 Director level applicant Youʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 3/7\\nApplicant education level\\n19%have a Doctor of Philosophy (Similar to you)\\n59%have a Master\\'s Degree\\n15%have a Bachelor\\'s Degree\\n7%have other degrees\\nApplicants are in these locations\\n1-5 applicants\\nNew York City Metropolitan\\nArea\\n1-5 applicants\\nGreater Pittsburgh Region\\n1-5 applicants\\nDallas-Fort Worth Metroplex\\nSee if Robert Half is hiring people like you\\nThe latest hiring trends.\\n29,307\\nTotal employees3%\\nCompany-wide\\n2 year growth2%\\nEngineering\\n2 year growth\\nMedian employee tenure ‧6 yearsMay 2022 Nov 2022 May 2023 Nov 2023 May 202410,00020,00030,00040,000\\nRobert Half hires candidates from some of these companies and schools\\nRobert Half hired 2 people\\nfrom Coding Dojo.See all\\nRobert Half hired 3 people from\\nFlatiron School.See all\\nEngineering hires at Robert Half came\\nfrom these companies and more.Engineering hires at Robert Half came\\nfrom these schools and more.\\nReset map\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 4/7\\nMore jobsShow more Premium insightsSee more companies See more schools\\nAbout the company\\nRobert Half\\n3,147,224 followersFollow\\nStaffing and Recruiting•10,001+ employees•29,320 on LinkedIn\\nTrending employee content PreviousNext\\nShow more\\nRobert Half, the worldʼs first and largest specialized talent solutions firm,\\nconnects opportunities at great companies with highly skilled job seekers. We\\noffer contract, temporary and permanent placement solutions for roles in financ……show more\\nInterested in working with us in the future?\\nPrivately share your profile with our recruiters – youʼll be noted as\\nexpressing interest for up to a year.Learn more\\nIʼm interested\\nLead Data Scientist\\nCigniti Technologies\\nUnited States (Remote)\\nActively recruiting\\n4 weeks agoEasy ApplySenior Data Scientist\\nDTN\\nUnited States (Remote)\\nActively recruiting\\n2 weeks ago\\nData Scientist\\nQuantum World Technologies…\\nUnited States (Remote)\\nActively recruiting\\nSr. Data Scientist\\nAKASA\\nUnited States (Remote)\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 5/7\\nSee more jobs like this10 minutes agoEasy Apply 2 weeks ago\\nSenior Data Scientist\\nPhreesia\\nUnited States (Remote)\\nActively recruiting\\n3 weeks agoSr. Data Scientist\\nAppFolio\\nUnited States (Remote)\\nActively recruiting\\n1 week ago\\nSenior Data Scientist,\\nProduct\\nUniswap Labs\\nNew York, NY (Remote)\\nActively recruiting\\n1 week agoSenior Data Scientist\\nAustin Fraser\\nUnited States (Remote)\\nActively recruiting\\n6 days agoEasy Apply\\nSenior Data Scientist\\nWebflow\\nUnited States (Remote)\\n1 company alum works here\\n2 days agoSenior Data Scientist\\nXOi\\nUnited States (Remote)\\n2 weeks ago\\nLead Data Scientist\\nLittle Place Labs\\nUnited States (Remote)\\n1 month agoEasy ApplyStaff Data Scientist\\nDemandbase\\nUnited States (Remote)\\n3 school alumni work here\\n3 weeks ago\\nLearn skills to get a new job with these courses\\n135,378 viewers\\nThe New Rules of Work\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 6/7\\nAbout Accessibility Talent Solutions\\nCommunity Guidelines Careers Marketing Solutions\\nAd Choices Advertising\\nSales Solutions Mobile Small Business\\nSafety CenterQuestions?\\nVisit our Help Center.\\nManage your account and privacy\\nGo to your Settings.\\nRecommendation transparency\\nLearn more about Recommended Content.Select Language\\nLinkedIn Corporation © 2024282,784 viewers\\nShow more on LinkedIn Learning\\nDeveloping Your Professional Image in a New Job\\nLooking for talent?Post a job\\nPrivacy & Terms\\nEnglish (English)\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 7/7\\n'}, template='\\n    You are a a specialized career coach for the {sector}, focused on delivering tailored, concise job application advice and practice.\\n    You are proficient in resume analysis, cover letter guidance, and interview preparation, adapting to each user\\'s unique requirements. \\n    You maintain a professional, {model_tone} tone, ensuring advice is efficient, clear, and easily understandable, with the goal of aiding their career progression. \\n    Ask the user for their resume and job listing if not provided and they are needed to answer .\" \\n    \\n    Use the following context, if provided, to help answer the questions:\\n    \\n    -------------\\n    My Resume:\\n    {resume}\\n    \\n    -------------\\n    The job listing:\\n    {job_listing}\\n    ')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x176246980>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x176e98640>, model_name='gpt-4', temperature=0.1, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'RateResume', 'description': 'Rates the resume against the job listing and provides a justification.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'ListMatchingQualifications', 'description': 'Lists the matching qualifications between the resume and job listing.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'ListMissingQualifications', 'description': 'Lists the missing qualifications in the resume based on the job listing.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'QuestionsForAdditionalInfo', 'description': 'Lists questions to determine if there is additional information that could be added to the resume.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}]})\n",
       "| OpenAIToolsAgentOutputParser()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# from langchain.llms import OpenAI\n",
    "from langchain_openai import OpenAI,ChatOpenAI\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor, create_openai_tools_agent\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.1)\n",
    "\n",
    "tools_list =  [\n",
    "    rate_resume_tool,\n",
    "    matching_qualifications_tool,\n",
    "    missing_qualifications_tool,\n",
    "    additional_info_questions_tool\n",
    "    ]\n",
    "# Create the agent with the defined tools\n",
    "# agent = create_openai_functions_agent\n",
    "agent = create_openai_tools_agent(llm,\n",
    "                                      tools_list,\n",
    "                                    #   prompt=tools_prompt,\n",
    "                                    prompt=manual_tools_prompt)\n",
    "\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'chat_history': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], partial_variables={'sector': 'data science and analytics', 'model_tone': 'friendly and encouraging', 'resume': '[LONG MASTER RESUME]  James M. Irving, Ph.D. 8222 Spadderdock Way, Laurel, MD, 20724 | (518) 322-6750 | james.irving.phd@gmail.com |  LinkedIn: james-irving-phd | GitHub: https://github.com/jirvingphd  SUMMARY V1 Innovative and enterprising data scientist with extensive experience in applying advanced data science techniques to real-world problems. Known for excellent problem-solving skills and the ability to rapidly master and implement new technologies. Committed to leveraging data to drive innovation and support data-driven decision-making. SUMMARY V2 Neuroscientist-turned-data scientist with an insatiable curiosity and a proven track record in mastering cutting-edge technologies. Exceptional communication and interpersonal skills paired with a robust history of problem-solving and critical thinking. Proven ability to self-teach complex concepts and technologies, including in vivo electrophysiology recordings and analysis. Successfully trained generations of collaborators, technicians, research fellows, and undergraduate volunteers by customizing the training to match the specific trainee’s experience and knowledge. COMPETENCIES • Data Analysis, Statistical Modeling, Machine Learning, Data Visualization • Experimental Design, Quantitative Research Methods, Time Series Analysis, Signal Processing • Cognitive Neuroscience, Behavioral Analysis, Database Management, Pattern Recognition • Python Programming, Deep Learning, Natural Language Processing, AI/LLM Implementation • Adaptive Communication Style, Problem-Solving & Critical Thinking EXPERIENCE  Coding Dojo | Remote Curriculum Writer - Data Science March 2023 - January 2024 • Developed and delivered advanced courses in Time Series Modeling, NLP, and Model Deployment, enhancing data science skills for over 100 professionals. • Expanded a 16-week boot camp to a 24-week comprehensive training program, increasing curriculum depth by 50%, which boosted learner engagement and program satisfaction. • Implemented project management and automation tools using Monday.com, optimizing workflow efficiency and resolving operational bottlenecks. • Developed and implemented Monday.com boards, including public forms and executive-facing Gantt charts, to automate internal workflows and streamline curriculum management, resolving over 100 issues. • Integrated cutting-edge technologies like APIs, Web Scraping, and Computer Vision into the curriculum, aligning educational content with evolving industry standards and practical application needs. • Developed a workflow and process to test and identify datasets for curriculum use, including template Python notebooks for preprocessing, visualization, EDA, modeling, and interpretations. • Constructed the Dojo Environment Setup for Students, ensuring compatibility with various OS and facilitating smooth installation of necessary tools and libraries. • Created and maintained a GitHub Organization for curriculum-related activities, solutions, and packages, providing a centralized resource hub for students and instructors. • Designed an extended case study for the 6-month curriculum, applying all phases of CRISP-DM to a specially constructed subset of the Ames housing dataset, enhancing practical application and understanding of the data science lifecycle. • Achieved tight deadlines throughout the year despite unexpected demands related to getting the curriculum accredited ensuring timely delivery and high-quality content for the program.  Data Science Instructor November 2021 - March 2023 • Achieved high Net Promoter Scores (NPS) exceeding 90% through engaging and interactive live lectures, demonstrating strong communication and pedagogical skills. • Revolutionized administrative workflow by automating tasks, resulting in a 99% reduction in student onboarding time—from 5 hours to just 2 minutes—dramatically enhancing operational efficiency and productivity. \\n• Developed and delivered a highly acclaimed 4-week course with perfect feedback ratings, showcasing expertise in curriculum development and instructional delivery. • Designed and led over 16 interactive live lectures and code-along projects, enhancing student participation and creating a dynamic learning environment. Flatiron School | Remote Data Science Instructor  October 2019 - October 2021 • Mentored and supervised over 60 students, helping them transition into successful data science careers with a high post-program employment rate. • Conducted weekly 90-minute study groups, accumulating over 270 hours of recorded lessons, significantly enhancing student comprehension and engagement. • Spearheaded the development and implementation of the \"Flex\" boot camp program, refining instructional design and delivery methods to meet diverse learning needs. • Created and maintained three student-progress-tracking Looker dashboards, providing real-time insights into student performance and facilitating timely interventions. • Guided students in selecting capstone project subjects, identifying job sectors of interest, and selecting appropriate data sources. Topics included time series analysis, NLP analysis, Covid cough classification (via Computer Vision),  and customer segmentation. • Offered bonus lectures on Object-Oriented Programming, dashboarding with Plotly and Dash, and advanced visualizations with matplotlib and seaborn. • Updated the entire lecture and activity content to accommodate a new teaching model, integrating recorded lectures from a national \"Central Lecturer\" with expanded hands-on activities. University of Maryland, School of Medicine | Baltimore, MD  Laboratory Manager  July 2017 - August 2018 • Ensured full compliance with regulatory standards as the lab\\'s public representative, achieving a flawless inspection record. • Successfully represented lab and guided inspectors through 4 regulatory inspections from 2 agencies, demonstrating knowledge of and compliance with protocols and regulations. • Negotiated and finalized a $100,000 technical hardware contract with vendors, optimizing procurement processes and ensuring cost-effectiveness. • Managed and administered over 20 TBs of data storage systems, ensuring data accessibility, security, and efficient retrieval. • Overhauled mouse colony management procedures, reducing housing costs by 60%  (from approximately $3.8k/month to $1.5k/month ) through strategic resource allocation and process optimization. • Created and instituted new surgery logs to simplify record keeping while ensuring regularity compliance. • Managed lab supplies and equipment purchasing, maintaining appropriate documentation and financial records. • Consolidated and encrypted all sensitive and proprietary lab information vendor accounts, log-in information, and secure information into an encrypted data vault Postdoctoral Research Fellow  June 2015 - July 2017 • Led neuroscience research using advanced techniques such as in vivo optogenetics and electrophysiology recordings, resulting in groundbreaking insights into neural functioning. • Developed approximately 30 custom analysis scripts in Matlab, NexScript, MedPC, and Arduino, enhancing data processing capabilities and facilitating comprehensive statistical analyses. • Mentored and guided a diverse team, fostering a collaborative learning environment and achieving research excellence (1 postdoc, 2 Ph.D. students, 3 lab techs, and 3 undergraduate volunteers.) • Demonstrated self-directed learning by mastering Matlab programming and creating custom-designed analysis programs for large datasets, streamlining data interpretation and enhancing research efficiency. • Researched the role of extended amygdala stress neurons in binge drinking, using multiple genetic tools and in vivo electrophysiology recordings. • Recorded changes in the activity of amygdala neurons during binge drinking. Identified neuron populations using a combination of single-unit recordings and optogenetic stimulation using targeted viral vectors. • Founded in vivo electrophysiology recordings and in vivo deep-brain structure calcium imaging in awake and behaving mice. • Directed several research projects simultaneously and managed a staff of postdoctoral fellows, technicians and student volunteers. • Programmed custom-designed analysis programs (~30) for large datasets in 4 programming languages (see skills). • Communicated research findings to mixed audiences with varying degrees of background knowledge and experience via seminars, presentations, as well as scientific posters. •  Wrote user guides on various complicated technical procedures and techniques to train lab members and collaborators. • Trained and mentored 1 research fellow, 2 graduate students, 2 lab technicians, and 3 undergraduate volunteers on several complex technical procedures and the underlying scientific principles/theory.  Graduate Research Assistant \\nSeptember 2009 -  May 2015 • Pioneered application of optogenetics with fast-scan cyclic voltammetry to discover previously unknown modulation of dopamine release via cholinergic interneurons. • Communicated research findings to audiences with varying degrees of background knowledge and familiarity in seminars, as well as scientific posters. • Trained and mentored 4 fellows, 3 graduate students, 5 lab technicians, 6 collaborators, and 1 undergraduate volunteer on various complex procedures and techniques. • Wrote user guides on various complex technical procedures and techniques to train current and future lab members Tulane University | New Orleans, LA Research Assistant January 2009 – May 2009 • Continued master’s thesis study of the role of histone deacetylase (HDAC) inhibition in aggression under chronic stress. • Tested changes in stress hormones and protein expression in stressed rats with HDAC inhibition.  DISTINCTIONS & HONORS  Happy Camper Award, University of Maryland 2012 – 2013 • Awarded to the Ph.D. student with the most positive attitude in the face of adversity, as voted by fellow students.  Summer Research Program Award, Tulane University  May 2008 to August 2008 • Awarded for distinguished scientific research, including salary.  Tulane Distinguished Scholars, Tulane University  Fall 2004 - Fall 2007 • Awarded for outstanding academic performance.  Tulane-Newcomb College Dean’s List  Fall 2004 - Fall 2005 • Awarded for achieving a GPA greater than 3.7 EDUCATION Certificate of Completion, Data Science, Flatiron School, Online (February 2019 - August 2019) • Intensive 5-month program, approximately 50 hours per week Doctor of Philosophy, Neuroscience, University of Maryland, Baltimore, MD (August 2009 - May 2015) • Including specialized optional training: Entrepreneurship in Life Sciences course, Science Communication internship. Master of Science, Neuroscience, Tulane University, New Orleans, LA (January 2008 - December 2008) Bachelor of Science, Neuroscience (Sociology Minor), Tulane University, New Orleans, LA (August 2004 - December 2007) ADDITIONAL EXPERIENCE AND SERVICE University of Maryland | Baltimore, MD Science Communication Internship – Office of Public Affairs  June 2013 - September 2013 • Selected as one of four founding members for an internship with Office of Public Affairs at the University of Maryland School of Medicine. • Trained in many aspects of university public affairs communications, relaying complex scientific material to a lay audience for both educational and promotional purposes. • Wrote press releases on university-associated research and novel findings to disseminate to inspire media coverage. • Wrote an in-depth interview featuring a university scientist’s high-impact research developing a novel anti-depressant. • Practiced live television interviews in the university’s satellite teleconferencing suite as both interviewer and interviewee. • Weekly training classes + independent assignments – 5-10 hours/week.  Entrepreneurship in Life Sciences – Interdisciplinary Course January 2014 to June 2014 • Trained by visiting experts in aspects of developing, promoting, and acquiring venture funding for a biomedical technology company.  \\n• Wrote and presented funding proposals for venture capitalist firms for a resource-sharing/saving cloud-based software solution for universities. • Wrote a business plan, patent applications, and promotional materials. • Weekly classes + group work – 10 hours/week.  Student Training Committee Member January 2013 - June 2015 • Served graduate student community as proponent and liaison to the Ph.D. program administration. • Reformed graduate program policies and procedures for the mutual benefit of students and faculty. • Advised administration on student outreach and prospective student application/interview process.  Big Brother – Program in Neuroscience  August 2010 - December 2013 • Volunteered as “Big Brother” mentor for 3 incoming doctoral students. • Advised “little brothers” on research lab choices, handling graduate coursework, and navigating university politics. Tulane University | New Orleans, LA Green Wave Ambassador Fall 2004 – Spring 2005 • Led guided tours of the campus for prospective students and their families, providing comprehensive information about academic programs, campus facilities, and student life. • Served as a host for visiting students, organizing and facilitating events to enhance their campus experience. • Engaged with visitors to answer questions, provide insights into the student experience, and assist with logistical needs. • Represented the university positively, contributing to recruitment and outreach efforts by sharing personal experiences and highlighting unique aspects of the campus community.  Student Calling Center Representative Fall 2005 – Spring 2007 • Contacted alumni to provide updates about university events, achievements, and developments. • Engaged alumni in meaningful conversations to foster a connection between them and the university. • Solicited donations, explaining the impact of their contributions on university programs, scholarships, and facilities. • Maintained accurate records of interactions and feedback, contributing to the continuous improvement of alumni relations and fundraising strategies.  PUBLICATIONS • Aroni S, Marino RAM, Girven KS, Irving JM, Cheer JF, Sparta DR. (2021) Repeated binge ethanol drinking enhances electrical activity of central amygdala corticotropin releasing factor neurons in vivo. Neuropharmacology. • Girven, K., Irving, J., Aroni, S., Sparta, D. The Role of Interconnections between the vBNST and insula in the modulation of reward processing. Manuscript in preparation. • Cachope, R., Mateo, Y., Mathur, B.N., Irving, J., Wang, H.-L., Morales, M., Lovinger, D.M., and Cheer, J.F. (2012). Selective Activation of Cholinergic Interneurons Enhances Accumbal Phasic Dopamine Release: Setting the Tone for Reward Processing. Cell Reports 2, 33–41. • Mateo, Y., Atwood, B., Wang, H.-L., Zhang, S., Irving, J., Gildish, I., Cachope, R., Bellochio, L., Guzman, M., Morales, M., Cheer, J.F., and Lovinger, D.M. Cortical afferents expressing CB1 receptors control accumbal phasic dopamine release caused by selective activation of cholinergic interneurons. Manuscript submitted for publication. POSTER ABTRACTS • Irving, J.M., Maehler, C.J., Qadir, H., Girven, K.S., Sparta, D.R. Central Amygdala Corticotropin Releasing FactorNeurons Encode and Modulate Binge Drinking and Relapse American College of Neuropsychopharmacology Annual Meeting 2016. • Irving, J.M., Maehler, C.J., Girven, K.S., Sparta, D.R. The Role of Extended Amygdala Corticotropin Neurons in Binge Ethanol Drinking. Society for Neuroscience Annual Meeting 2016. • Irving, J.M., Maehler, C.J., Sparta, D.R. Optogenetic and Pharmacogenetic Interrogation of Central Amygdala Corticotropin Neurons on Binge Ethanol Drinking. Research Society on Alcoholism Annual Meeting 2016. • Irving, J.M., Gluskin, K.H., Cheer, J.F. Optogenetic activation of accumbal fast-spiking interneurons is reinforcing. Society for Neuroscience Annual Meeting 2014. • Kashtelyan, V., Irving, J.M., Fitoussi, A., Wang, H., Morales, M., Cheer, J.F. Conditional deletion of CB1 receptors on cholinergic terminals and its functional consequences. Society for Neuroscience Meeting Annual 2014. • Irving, J.M., Mateo, Y., Cheer, J.F. Optogenetic Stimulation of Cholinergic Interneurons in the Nucleus Accumbens Causes Dopamine Release. Society for Neuroscience Meeting 2011. \\n• Irving, J.M., Mateo, Y., Cheer, J.F. Endogenous Activity of Cholinergic Interneurons in the Nucleus Accumbens is Sufficient to Evoke Dopamine Release. Graduate Research Conference 2012.  PROFERRED COMMUNICATIONS •  Irving, J.M., Sparta, D.R. “Modulation of Binge Drinking by Central Amygdala Corticotropin-Releasing Factor Neurons.” Department of Anatomy & Neurobiology, Second-Monday Program, University of Maryland School of Medicine, 2016. • Irving, J.M., Cheer, J.F. “The Role of Local Activity of the Nucleus Accumbens in Reward: Interneurons and Gamma Oscillations,”, Public Dissertation Defense, 2016. • Irving, J.M..Cheer, J.F., “Selective activation of cholinergic interneurons enhances accumbal phasic dopamine release: setting the tone for reward processing.”, Department of Anatomy & Neurobiology, Second-Monday Program, University of Maryland, Baltimore, 2012. • Irving, J.M..Cheer, J.F., “Selective activation of cholinergic interneurons enhances accumbal phasic dopamine release: setting the tone for reward processing.”, Program in Neuroscience Retreat, Notre Dame of Maryland, 2012. • Irving, J.M., Cheer, J.F., “The Role of CB1 Receptors on GABAergic Interneurons of the Nucleus Accumbens in Motivated-Behavior and Modulation of Accumbal Gamma Rhythms” University of Maryland, Baltimore, Thesis Proposal, 2014. • Irving. J.M., Cheer, J.F., “The Reinforcing Effects of Gamma-Frequency Stimulation of Accumbal Parvalbumin Interneurons and the Role of CB1 Receptors”, University of Pittsburgh, Department of Psychiatry, 2015. DATA SCIENCE PROJECTS Computer Vision Classification of American Sign Language – GitHub Link Applied tensorflow and transfer learning to classify an image as the correct letter of the ASL alphabet. • COMING SOON AI Job Application Assistant – App Link – GitHub Link Developed a Streamlit application to assist job seekers with resumes and cover letters • Developed a Streamlit application to assist job seekers by analyzing resumes and job listings using AI. • Integrated ChatGPT for tailored advice, resume improvements, and cover letter creation. • Automated job application process with AI-driven insights and recommendations. • Enhanced user experience with an interactive and user-friendly interface. • Provided actionable advice to job seekers, improving their chances of success. • Key Technologies Used: Streamlit, LangChain, OpenAI API  NLP Analysis of Amazon Reviews + AI Recommendations - GitHub Link Natural Language Processing Analysis, Modeling, and Deployment with Actionable Insights • Designed and deployed a user-centric Streamlit dashboard, integrating live sentiment predictions and interactive analysis of trends to guide strategic decision-making. • Conducted sentiment analysis on over 5 million Amazon Grocery & Gourmet Food reviews, utilizing NLP and machine learning techniques (Logistic Regression, Tf-idf vectorization) to identify key factors affecting customer satisfaction and achieve 95% accuracy in sentiment classification. • Employed Hugging Face transformers and Lang Chain/ChatGPT within the dashboard with a vectorized database used for summarization and insights, translating vast consumer feedback into actionable product enhancement strategies. • Key Technologies Used: Python, Hugging Face, OpenAI API, LangChain, spacy, scikit-learn. How to Make a Successful Movie – GitHub Link Constructing and analyzing an extensive movie database with hypothesis-testing insights + Tableau Dashboard • Integrated and normalized datasets from IMDB and TMDB API for comprehensive movie analysis. • Engineered a MySQL database on AWS RDS for robust data storage and retrieval. • Designed an interactive Tableau dashboard to communicate findings to stakeholders, enhancing decision-making processes (see GitHub link). • Applied A/B Testing to identify key factors influencing movie performance and success to provide business recommendations on what movies to create for high box office returns on factors like MPAA rating, runtime, and genre. • Key Technologies Used: Python, SQL, Tableau, TMDB API, Pandas, sqlalchemy, MySQL Workbench, statsmodels, AWS RDS How to Spot a Troll – GitHub Link Classifying Russian Troll Tweets vs Authentic Tweets • Performed EDA on 3 million tweets from accounts from the Internet Research Agency (the Russian Troll Farm) to identify an appropriate control dataset (which time period and content to extract to construct control group). •  Harvested control tweets for use in supervised learning using the TwitterAPI and TweetDeck to target the top 40 most frequent mentions, which produced 40,000 control tweets.  • Conducted natural language processing (NLP) on 80,000 tweets using nltk, Word2Vec, and Keras to tokenize, vectorize, and train word embeddings for Logistic Regression and multiple Keras Neural Networks.  • Final models achieved 90% accuracy with a dense neural network (training time: 32 sec) and 88% accuracy using Logistic Regression (training time: 0.6 sec)  • Key Technologies Used: Python, Tweepy, Neural Networks (Tensorflow & Keras),  \\nRecidivism Risk Assessment – GitHub Link Classifying which released prisoners in Iowa will return to a life of crime using Next-Gen Gradient Boosted Trees • Developed a predictive model to classify which released prisoners in Iowa are likely to return to crime using Gradient Boosted Trees. with over 70% accuracy (via scikit-learn and Catboost). • Researched Iowa\\'s state sentencing guidelines and sentencing enhancements to engineer new numerical features to capture the severity of the crimes committed and the duration of sentences. • Achieved high recall rates for predicting recidivism using XGBoost. • Identified key features influencing recidivism, such as age, release type, and offense subtype. • Provided actionable insights and recommendations to the Iowa Department of Corrections. • Implemented various machine learning models and utilized SHAP for feature importance analysis. • Key Technologies: Python, Jupyter Notebooks, XGBoost, CatBoost, SHAP, SMOTE   Forecasting Stock Market Fluctuations with Trump’s Tweets – GitHub Link Combining Natural Language Processing of Trump’s Tweets with Time Series Forecasting S&P500 Price  • Employed Natural Language Processing with nltk and word embeddings (both Word2Vec & GloVe pre-trained) to classify Trump’s tweets by S&P 500 price change (increase/decrease/no change) 60 minutes after tweeting. • Compared tweet NLP classification models using Keras neural networks (LSTM, GRU, and CNN) to predict the direction of stock market price change from NLP alone. • Used Keras neural networks for time series forecasting of S&P 500 price. • Compared multiple data sources: price alone, price + 7 market technical indicators. • Compared forecasting models: Keras LSTM vs. XGBoost Regressor. • Final model stacked NLP classification predictions with S&P 500 time series forecasting and additional tweet features (sentiment analysis with Vader, number of retweets/favorites, uppercase-to-lowercase ratio). PROFESSIONAL SKILLS Programming: Python, OOP, SQL (MySQL, SQLAlchemy), MATLAB, HTML/CSS, Git/GitHub, NexScript, MedState Notation Data Analysis: ETL (numpy, pandas), AB Testing (scipy, statsmodels), Machine Learning (scikit-learn, Catboost, XGBoost), Deep Learning (Tensorflow, Keras) Natural Language Processing: nltk, spaCy, Tensorflow, HuggingFace transformers, LLMs(OpenAI, LangChain) Visualization/Dashboarding: Plotly/Dash, Tableau, Streamlit Dashboards & Deployment, Seaborn/Matplotlib, Looker Software: Adobe Illustrator, Adobe Photoshop, GraphPad Prism, SPSS, Microsoft Office, VS Code, Jupyter Notebook/Lab, Google Suite, Plexon OfflineSorter, NeuroExplorer  LEADERSHIP & COMMUNITY INVOLVEMENT SECTION IS WORK-IN-PROGRESS • Key Club Lt. Governor \\n', 'job_listing': 'Robert Half\\nSenior Data Scientist\\n$115K/yr - $173K/yr···Mid-Senior level\\n10,001+ employees · Staffing and Recruiting\\n2 company alumni work here·3 school alumni work here\\n3 of 3 skills match your profile - you may be a good fit\\nApply SavedCalifornia, United States·4 hours ago·29 applicants\\nRemoteFull-time\\nAm I a good fit for this job? How can I best position myself fo\\nMeet the hiring team\\nKelli Griffin3rd\\nLead Talent Acquisition Partner\\nJob posterMessage\\nAbout the job\\nReady to revolutionize the future of data-driven decision-making? Join our\\npioneering Data Science team as we embark on an exciting journey to unlock\\ninsights, drive innovation, and shape the landscape of our organization\\'s success.\\nIf you\\'re passionate about leveraging cutting-edge generative AI technologies\\nand transforming raw data into actionable insight, we want you on our team!\"\\nThe Senior Data Scientist will be responsible for leading advanced data analytics\\nprojects, leveraging Azure and Microsoft data services. This role demands a deep\\nunderstanding of data science methodologies, machine learning algorithms, and\\nbig data technologies. The incumbent will work closely with cross-functional\\nteams to understand business needs and formulate and execute data science\\nsolutions that drive significant business impact.\\nKey Responsibilities:\\nData Analytics and Modeling:\\nDevelop and implement advanced predictive models and statistical\\nanalysis using a variety of machine learning algorithms.\\nSuggest algorithms or models appropriate for specific use cases and\\napplications.\\nAnalyze and extract relevant information from large amounts of historical\\nbusiness data to help automate and optimize key processes with business\\nteams.\\nApply technical solutions to business problems and questions using large\\nscale data analytics and machine learning; create highly calibrated\\nsolutions for business problems.\\nWork closely with software engineering teams to drive real-time model\\nexperiments, implementations and new feature creations.\\nContinuously evaluate and refine models based on performance metrics.\\nUtilize cloud technologies such as Azure Machine Learning, Azure\\nDatabricks, and other Microsoft data services for data processing, modelHomeMy NetworkJobsMessagingNotificationsMe\\n For BusinessLear\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 1/7\\nSee lessbuilding, and deployment.\\nLarge Language Model Fine-tuning:\\nEnhance and evolve the performance of large language models by\\nrefining their capabilities through targeted fine-tuning.\\nSteer both the research trajectory and the practical engineering efforts of\\nthe team.\\nFormulate and enact algorithms for model enhancement, tweak critical\\nhyperparameters, and heighten overall model efficiency.\\nGuarantee the integrity and relevance of datasets by conducting thorough\\npreprocessing and data analysis within the fine-tuning workflow.\\nConduct assessments on fine-tuned models, making necessary\\nmodifications to boost their effectiveness.\\nFoster a cooperative environment within the team, providing guidance to\\npeers to ensure a smooth fine-tuning operation that yields superior\\nresults.\\nStay at the forefront of advancements in large language model\\ntechnologies and applications, perpetually refining technical expertise in\\nmodel fine-tuning.\\nData Management and Strategy:\\nCollaborate with IT and data engineering teams in an enterprise setting to\\nintegrate data science solutions into the broader tech stack and data\\nstrategy.\\nBusiness Collaboration and Insights:\\nWork closely with business stakeholders to identify opportunities for\\nleveraging company data to drive business solutions.\\nTranslate complex data-driven findings into actionable business insights\\nand communicate these effectively to non-technical stakeholders.\\nResearch and Development:\\nStay abreast of industry trends and advancements in data science and\\nAzure technologies.\\nConduct research to explore new methodologies and technologies that\\ncan enhance the organization\\'s data analytics capabilities.\\nPreferred Qualifications and Skills:\\nBachelor\\'s degree in Statistics, Computer Science, Mathematics or\\nequivalent required; Master\\'s or PhD highly preferred\\n5 years of professional experience in data science, with a record in\\ndesigning and implementing large-scale data science projects.\\n5 years of industry experience in predictive modeling and large data\\nanalysis\\nKnowledge of open-source large language models and experience with\\nevaluating and recommending appropriate models for specific use cases.\\n3+ years of experience in using big data platforms and technologies such\\nas Hadoop, Azure data lake, Azure Cosmos DB, Pig, Hive, HBase, etc.\\n3+ years of hands-on experience in statistical modeling, data mining,\\nlarge data analysis and predictive modeling; text mining a major plus\\n3+ years of experience in regression, classification and clustering\\nmethods such as GLM, LR, SVM, LVQ, SOM, Neural Networks\\nExperience with two or more of the following: Python, PERL, Matlab or\\nScala\\nExpertise in various machine learning frameworks and libraries (e.g.,\\nTensorFlow, PyTorch, Scikit-learn).\\nExcellent analytical, problem-solving, and communication skills.\\nExcellent communication skills, with a proven ability to translate technical\\nfindings into business recommendations and strategies.\\nCertifications in Azure data services or advanced analytics preferred\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 2/7\\nSet alert for similar jobs\\nData Scientist, California, United StatesSet alert\\nEmployer-provided\\nPay range in California, United States\\nExact compensation may vary based on skills, experience, and location.\\nBase salary\\n$115,000/yr - $173,000/yr\\nFeatured benefits\\nMedical insurance\\nVision insurance\\nDental insurance\\n401(k)\\nTuition assistance\\nQualifications\\n3 of 3 skills match your profile - you may be a good fit\\nSkills added by the job poster\\nBig Data · Large Language Models (LLM) · Natural Language Processing (NLP)\\nAdditional skills among applicants\\nData Analysis · Data Science · Data Visualization · Machine Learning · Microsoft\\nPower BI · Python (Programming Language) · R (Programming Language) · SQL …\\nShow qualification details\\nPut your best foot forward with your application\\nHire a resume writer\\nGet a resume review\\nSee how you compare to other applicants\\nApplicants for this job\\n29Applicants\\n29Applicants in the past day\\nApplicant seniority level\\n15 Entry level applicants\\n10 Senior level applicants\\n1 Director level applicant Youʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 3/7\\nApplicant education level\\n19%have a Doctor of Philosophy (Similar to you)\\n59%have a Master\\'s Degree\\n15%have a Bachelor\\'s Degree\\n7%have other degrees\\nApplicants are in these locations\\n1-5 applicants\\nNew York City Metropolitan\\nArea\\n1-5 applicants\\nGreater Pittsburgh Region\\n1-5 applicants\\nDallas-Fort Worth Metroplex\\nSee if Robert Half is hiring people like you\\nThe latest hiring trends.\\n29,307\\nTotal employees3%\\nCompany-wide\\n2 year growth2%\\nEngineering\\n2 year growth\\nMedian employee tenure ‧6 yearsMay 2022 Nov 2022 May 2023 Nov 2023 May 202410,00020,00030,00040,000\\nRobert Half hires candidates from some of these companies and schools\\nRobert Half hired 2 people\\nfrom Coding Dojo.See all\\nRobert Half hired 3 people from\\nFlatiron School.See all\\nEngineering hires at Robert Half came\\nfrom these companies and more.Engineering hires at Robert Half came\\nfrom these schools and more.\\nReset map\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 4/7\\nMore jobsShow more Premium insightsSee more companies See more schools\\nAbout the company\\nRobert Half\\n3,147,224 followersFollow\\nStaffing and Recruiting•10,001+ employees•29,320 on LinkedIn\\nTrending employee content PreviousNext\\nShow more\\nRobert Half, the worldʼs first and largest specialized talent solutions firm,\\nconnects opportunities at great companies with highly skilled job seekers. We\\noffer contract, temporary and permanent placement solutions for roles in financ……show more\\nInterested in working with us in the future?\\nPrivately share your profile with our recruiters – youʼll be noted as\\nexpressing interest for up to a year.Learn more\\nIʼm interested\\nLead Data Scientist\\nCigniti Technologies\\nUnited States (Remote)\\nActively recruiting\\n4 weeks agoEasy ApplySenior Data Scientist\\nDTN\\nUnited States (Remote)\\nActively recruiting\\n2 weeks ago\\nData Scientist\\nQuantum World Technologies…\\nUnited States (Remote)\\nActively recruiting\\nSr. Data Scientist\\nAKASA\\nUnited States (Remote)\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 5/7\\nSee more jobs like this10 minutes agoEasy Apply 2 weeks ago\\nSenior Data Scientist\\nPhreesia\\nUnited States (Remote)\\nActively recruiting\\n3 weeks agoSr. Data Scientist\\nAppFolio\\nUnited States (Remote)\\nActively recruiting\\n1 week ago\\nSenior Data Scientist,\\nProduct\\nUniswap Labs\\nNew York, NY (Remote)\\nActively recruiting\\n1 week agoSenior Data Scientist\\nAustin Fraser\\nUnited States (Remote)\\nActively recruiting\\n6 days agoEasy Apply\\nSenior Data Scientist\\nWebflow\\nUnited States (Remote)\\n1 company alum works here\\n2 days agoSenior Data Scientist\\nXOi\\nUnited States (Remote)\\n2 weeks ago\\nLead Data Scientist\\nLittle Place Labs\\nUnited States (Remote)\\n1 month agoEasy ApplyStaff Data Scientist\\nDemandbase\\nUnited States (Remote)\\n3 school alumni work here\\n3 weeks ago\\nLearn skills to get a new job with these courses\\n135,378 viewers\\nThe New Rules of Work\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 6/7\\nAbout Accessibility Talent Solutions\\nCommunity Guidelines Careers Marketing Solutions\\nAd Choices Advertising\\nSales Solutions Mobile Small Business\\nSafety CenterQuestions?\\nVisit our Help Center.\\nManage your account and privacy\\nGo to your Settings.\\nRecommendation transparency\\nLearn more about Recommended Content.Select Language\\nLinkedIn Corporation © 2024282,784 viewers\\nShow more on LinkedIn Learning\\nDeveloping Your Professional Image in a New Job\\nLooking for talent?Post a job\\nPrivacy & Terms\\nEnglish (English)\\nYouʼve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_ﬁMktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4… 7/7\\n'}, template='\\n    You are a a specialized career coach for the {sector}, focused on delivering tailored, concise job application advice and practice.\\n    You are proficient in resume analysis, cover letter guidance, and interview preparation, adapting to each user\\'s unique requirements. \\n    You maintain a professional, {model_tone} tone, ensuring advice is efficient, clear, and easily understandable, with the goal of aiding their career progression. \\n    Ask the user for their resume and job listing if not provided and they are needed to answer .\" \\n    \\n    Use the following context, if provided, to help answer the questions:\\n    \\n    -------------\\n    My Resume:\\n    {resume}\\n    \\n    -------------\\n    The job listing:\\n    {job_listing}\\n    ')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x176246980>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x176e98640>, model_name='gpt-4', temperature=0.1, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'RateResume', 'description': 'Rates the resume against the job listing and provides a justification.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'ListMatchingQualifications', 'description': 'Lists the matching qualifications between the resume and job listing.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'ListMissingQualifications', 'description': 'Lists the missing qualifications in the resume based on the job listing.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'QuestionsForAdditionalInfo', 'description': 'Lists questions to determine if there is additional information that could be added to the resume.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}]})\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[Tool(name='RateResume', description='Rates the resume against the job listing and provides a justification.', func=<function rate_resume_vs_job at 0x175ecf370>), Tool(name='ListMatchingQualifications', description='Lists the matching qualifications between the resume and job listing.', func=<function list_matching_qualifications at 0x175e23130>), Tool(name='ListMissingQualifications', description='Lists the missing qualifications in the resume based on the job listing.', func=<function list_missing_qualifications at 0x1762de3b0>), Tool(name='QuestionsForAdditionalInfo', description='Lists questions to determine if there is additional information that could be added to the resume.', func=<function questions_for_additional_info at 0x176c2e950>)])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools_list, verbose=True,\n",
    "                            #    memory=ConversationBufferWindowMemory(window_size=5, \n",
    "                                                                    #  return_messages=True)\n",
    "                                                                    \n",
    ")\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JMI: Different Step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `RateResume` with `Senior Data Scientist at Robert Half`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TypeError(\"rate_resume_vs_job() missing 1 required positional argument: 'job_listing'\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    response = agent_executor.invoke(input={'input':\"How goes my resume compare against this job listing?\",\n",
    "                                            'resume':long_resume,\n",
    "                                        'job_listing':job_text_senior_rh})\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    display(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END OF DAY 06/24/24 -  \n",
    "\n",
    "```\n",
    "File /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages/langchain/chains/base.py:153, in Chain.invoke(self, input, config, **kwargs)\n",
    "    150 try:\n",
    "    151     self._validate_inputs(inputs)\n",
    "    152     outputs = (\n",
    "--> 153         self._call(inputs, run_manager=run_manager)\n",
    "    154         if new_arg_supported\n",
    "    155         else self._call(inputs)\n",
    "    156     )\n",
    "    158     final_outputs: Dict[str, Any] = self.prep_outputs(\n",
    "    159         inputs, outputs, return_only_outputs\n",
    "...\n",
    "--> 588         else self.func(*args, **kwargs)\n",
    "    589     )\n",
    "    590 raise NotImplementedError(\"Tool does not support sync\")\n",
    "\n",
    "TypeError: rate_resume_vs_job() missing 1 required positional argument: 'job_listing'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06/24/24 Using Structured Output Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://stackoverflow.com/questions/76407803/define-an-output-schema-for-a-nested-json-in-langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pydantic\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List, Optional, Text, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function Field in module pydantic.fields:\n",
      "\n",
      "Field(default: 'Any' = PydanticUndefined, *, default_factory: 'typing.Callable[[], Any] | None' = PydanticUndefined, alias: 'str | None' = PydanticUndefined, alias_priority: 'int | None' = PydanticUndefined, validation_alias: 'str | AliasPath | AliasChoices | None' = PydanticUndefined, serialization_alias: 'str | None' = PydanticUndefined, title: 'str | None' = PydanticUndefined, description: 'str | None' = PydanticUndefined, examples: 'list[Any] | None' = PydanticUndefined, exclude: 'bool | None' = PydanticUndefined, discriminator: 'str | types.Discriminator | None' = PydanticUndefined, deprecated: 'Deprecated | str | bool | None' = PydanticUndefined, json_schema_extra: 'JsonDict | typing.Callable[[JsonDict], None] | None' = PydanticUndefined, frozen: 'bool | None' = PydanticUndefined, validate_default: 'bool | None' = PydanticUndefined, repr: 'bool' = PydanticUndefined, init: 'bool | None' = PydanticUndefined, init_var: 'bool | None' = PydanticUndefined, kw_only: 'bool | None' = PydanticUndefined, pattern: 'str | typing.Pattern[str] | None' = PydanticUndefined, strict: 'bool | None' = PydanticUndefined, coerce_numbers_to_str: 'bool | None' = PydanticUndefined, gt: 'float | None' = PydanticUndefined, ge: 'float | None' = PydanticUndefined, lt: 'float | None' = PydanticUndefined, le: 'float | None' = PydanticUndefined, multiple_of: 'float | None' = PydanticUndefined, allow_inf_nan: 'bool | None' = PydanticUndefined, max_digits: 'int | None' = PydanticUndefined, decimal_places: 'int | None' = PydanticUndefined, min_length: 'int | None' = PydanticUndefined, max_length: 'int | None' = PydanticUndefined, union_mode: \"Literal['smart', 'left_to_right']\" = PydanticUndefined, **extra: 'Unpack[_EmptyKwargs]') -> 'Any'\n",
      "    Usage docs: https://docs.pydantic.dev/2.7/concepts/fields\n",
      "    \n",
      "    Create a field for objects that can be configured.\n",
      "    \n",
      "    Used to provide extra information about a field, either for the model schema or complex validation. Some arguments\n",
      "    apply only to number fields (`int`, `float`, `Decimal`) and some apply only to `str`.\n",
      "    \n",
      "    Note:\n",
      "        - Any `_Unset` objects will be replaced by the corresponding value defined in the `_DefaultValues` dictionary. If a key for the `_Unset` object is not found in the `_DefaultValues` dictionary, it will default to `None`\n",
      "    \n",
      "    Args:\n",
      "        default: Default value if the field is not set.\n",
      "        default_factory: A callable to generate the default value, such as :func:`~datetime.utcnow`.\n",
      "        alias: The name to use for the attribute when validating or serializing by alias.\n",
      "            This is often used for things like converting between snake and camel case.\n",
      "        alias_priority: Priority of the alias. This affects whether an alias generator is used.\n",
      "        validation_alias: Like `alias`, but only affects validation, not serialization.\n",
      "        serialization_alias: Like `alias`, but only affects serialization, not validation.\n",
      "        title: Human-readable title.\n",
      "        description: Human-readable description.\n",
      "        examples: Example values for this field.\n",
      "        exclude: Whether to exclude the field from the model serialization.\n",
      "        discriminator: Field name or Discriminator for discriminating the type in a tagged union.\n",
      "        deprecated: A deprecation message, an instance of `warnings.deprecated` or the `typing_extensions.deprecated` backport,\n",
      "            or a boolean. If `True`, a default deprecation message will be emitted when accessing the field.\n",
      "        json_schema_extra: A dict or callable to provide extra JSON schema properties.\n",
      "        frozen: Whether the field is frozen. If true, attempts to change the value on an instance will raise an error.\n",
      "        validate_default: If `True`, apply validation to the default value every time you create an instance.\n",
      "            Otherwise, for performance reasons, the default value of the field is trusted and not validated.\n",
      "        repr: A boolean indicating whether to include the field in the `__repr__` output.\n",
      "        init: Whether the field should be included in the constructor of the dataclass.\n",
      "            (Only applies to dataclasses.)\n",
      "        init_var: Whether the field should _only_ be included in the constructor of the dataclass.\n",
      "            (Only applies to dataclasses.)\n",
      "        kw_only: Whether the field should be a keyword-only argument in the constructor of the dataclass.\n",
      "            (Only applies to dataclasses.)\n",
      "        coerce_numbers_to_str: Whether to enable coercion of any `Number` type to `str` (not applicable in `strict` mode).\n",
      "        strict: If `True`, strict validation is applied to the field.\n",
      "            See [Strict Mode](../concepts/strict_mode.md) for details.\n",
      "        gt: Greater than. If set, value must be greater than this. Only applicable to numbers.\n",
      "        ge: Greater than or equal. If set, value must be greater than or equal to this. Only applicable to numbers.\n",
      "        lt: Less than. If set, value must be less than this. Only applicable to numbers.\n",
      "        le: Less than or equal. If set, value must be less than or equal to this. Only applicable to numbers.\n",
      "        multiple_of: Value must be a multiple of this. Only applicable to numbers.\n",
      "        min_length: Minimum length for iterables.\n",
      "        max_length: Maximum length for iterables.\n",
      "        pattern: Pattern for strings (a regular expression).\n",
      "        allow_inf_nan: Allow `inf`, `-inf`, `nan`. Only applicable to numbers.\n",
      "        max_digits: Maximum number of allow digits for strings.\n",
      "        decimal_places: Maximum number of decimal places allowed for numbers.\n",
      "        union_mode: The strategy to apply when validating a union. Can be `smart` (the default), or `left_to_right`.\n",
      "            See [Union Mode](standard_library_types.md#union-mode) for details.\n",
      "        extra: (Deprecated) Extra fields that will be included in the JSON schema.\n",
      "    \n",
      "            !!! warning Deprecated\n",
      "                The `extra` kwargs is deprecated. Use `json_schema_extra` instead.\n",
      "    \n",
      "    Returns:\n",
      "        A new [`FieldInfo`][pydantic.fields.FieldInfo]. The return annotation is `Any` so `Field` can be used on\n",
      "            type-annotated fields without causing a type error.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ResumeAnalysis(BaseModel):\n",
    "#     resume_rating: Optional[float] = Field( description=\"The rating of the resume against the job listing.\")\n",
    "#     list_of_matching_qualifications: Optional[List[Dict[Text, Text]]] = Field(description=\"The list of matching qualifications between the resume and job listing.\")\n",
    "#     list_of_missing_qualifications: Optional[List[Dict[Text, Text]]] = Field(description=\"The list of missing qualifications in the resume based on the job listing.\")\n",
    "#     questions_for_additional_info: Optional[List[Text]] = Field(description=\"The list of questions to determine if there is additional information that could be added to the resume.\")\n",
    "\n",
    "# # model = ResumeAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Attempting simpler data models\n",
    "class ResumeRating(BaseModel):\n",
    "    rating: str = Field(description=\"resume rating out of 5 stars\")\n",
    "    justification: str = Field(description=\"short justification for the rating\")\n",
    "    \n",
    "class ResumeQualificationsMissing(BaseModel):\n",
    "    missing_qualifications: str = Field(description=\"The qualifications missing in the resume based on the job listing.\")\n",
    "    job_listing: str = Field(description=\"The job listing used for comparison.\")\n",
    "    resume: str = Field(description=\"The resume used for comparison.\")\n",
    "\n",
    "# class ResumeQualificationsMatching(BaseModel):\n",
    "#     qualification: str\n",
    "#     job_listing: str\n",
    "#     resume: str\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['job_listing', 'resume'], partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"rating\": {\"description\": \"resume rating out of 5 stars\", \"title\": \"Rating\", \"type\": \"string\"}, \"justification\": {\"description\": \"short justification for the rating\", \"title\": \"Justification\", \"type\": \"string\"}}, \"required\": [\"rating\", \"justification\"]}\\n```'}, template='\\n    I need you to rate this resume against the following job listing out of 5 stars. Please provide a rating and 1-2 sentence justification.\\n\\n    Resume:\\n    {resume}\\n\\n    Job Listing:\\n    {job_listing}\\n    \\n    Format Instructions:\\n    {format_instructions}\\n    ')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x304b413c0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x304b42830>, model_name='gpt-4o', temperature=0.1, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "| JsonOutputParser(pydantic_object=<class '__main__.ResumeRating'>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Attempting simpler data models\n",
    "class ResumeRating(BaseModel):\n",
    "    rating: str = Field(description=\"resume rating out of 5 stars\")\n",
    "    justification: str = Field(description=\"short justification for the rating\")\n",
    "    \n",
    "def rate_resume_vs_job(resume: str, job_listing: str, temperature=0.1, model_type='gpt-4o',\n",
    "                       return_llm = False) -> str:\n",
    "    prompt = \"\"\"\n",
    "    I need you to rate this resume against the following job listing out of 5 stars. Please provide a rating and 1-2 sentence justification.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "    \n",
    "    Format Instructions:\n",
    "    {format_instructions}\n",
    "    \"\"\"\n",
    "    final_prompt_template = PromptTemplate.from_template(prompt)\n",
    "    # final_prompt_template = final_prompt_template.partial(resume=resume, job=job_listing)\n",
    "\n",
    "    try:\n",
    "        api_key = st.session_state.OPENAI_API_KEY\n",
    "    except:\n",
    "        api_key = os.getenv('OPENAI_API_KEY')\n",
    "        \n",
    "        \n",
    "    llm = ChatOpenAI(temperature=temperature, model=model_type, api_key=api_key)\n",
    "    parser = JsonOutputParser(pydantic_object=ResumeRating,) # PydanticOutputParser(pydantic_object=ResumeRating)#StrOutputParser(output_key=\"response\")\n",
    "    \n",
    "    # Add formatting instructions for pydantic\n",
    "    final_prompt_template = final_prompt_template.partial(format_instructions= parser.get_format_instructions())\n",
    "    \n",
    "    # Making the chain\n",
    "    llm_chain = final_prompt_template | llm | parser\n",
    "    \n",
    "    if return_llm:\n",
    "        return llm_chain\n",
    "    else:\n",
    "        response = llm_chain.invoke(dict(resume=resume, job=job_listing))\n",
    "        return response\n",
    "\n",
    "llm_chain = rate_resume_vs_job(long_resume, job_text_senior_rh, return_llm=True)\n",
    "llm_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rating': '4',\n",
       " 'justification': 'James M. Irving, Ph.D., has extensive experience in data science, machine learning, and NLP, which aligns well with the job requirements. However, the resume lacks specific mention of experience with Azure and Microsoft data services, which are critical for the role.'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.invoke(dict(resume=long_resume, job_listing=job_text_senior_rh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = PydanticOutputParser(pydantic_object=ResumeAnalysis)\n",
    "# print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Pydantic + JsonOutputParser for entire analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rating': '4',\n",
       " 'justification': 'The resume matches most of the key qualifications and experiences required for the Senior Data Scientist role at Robert Half. The candidate has extensive experience in data science, machine learning, and NLP, which aligns well with the job requirements. However, there is no explicit mention of experience with Azure and Microsoft data services, which are crucial for this role.',\n",
       " 'missing_qualifications': 'Experience with Azure Machine Learning, Azure Databricks, and other Microsoft data services; Certifications in Azure data services or advanced analytics; Specific mention of big data platforms and technologies such as Hadoop, Azure data lake, Azure Cosmos DB, Pig, Hive, HBase.',\n",
       " 'matching_qualifications': 'Ph.D. in a relevant field; Extensive experience in data science and machine learning; Experience with NLP and large language models; Proficiency in Python and other programming languages; Strong analytical, problem-solving, and communication skills; Experience in predictive modeling and large data analysis; Experience with machine learning frameworks and libraries such as TensorFlow, PyTorch, Scikit-learn.'}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ResumeAnalysis(BaseModel):\n",
    "    rating: str = Field(description=\"Rating for how well the resume matches the job listing out of 5.\")\n",
    "    justification: str = Field(description=\"short justification for the rating\")\n",
    "    missing_qualifications: str = Field(description=\"The qualifications missing in the resume based on the job listing.\")\n",
    "    matching_qualifications: str = Field(description=\"The list of matching qualifications between the resume and job listing.\")\n",
    "    # job_listing: str = Field(description=\"The job listing used for comparison.\")\n",
    "    # resume: str = Field(description=\"The resume used for comparison.\")\n",
    "\n",
    "\n",
    "## Attempting simpler data models\n",
    "class ResumeRating(BaseModel):\n",
    "    rating: str = Field(description=\"resume rating out of 5 stars\")\n",
    "    justification: str = Field(description=\"short justification for the rating\")\n",
    "    \n",
    "def analyze_resume(resume: str, job_listing: str, temperature=0.1, model_type='gpt-4o',\n",
    "                       return_llm = False) -> str:\n",
    "    prompt = \"\"\"\n",
    "    Analyze the resume against the job listing. Provide a rating out of 5 stars, a short justification, and list the matching and missing qualifications.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "    \n",
    "    Format Instructions:\n",
    "    {format_instructions}\n",
    "    \"\"\"\n",
    "    final_prompt_template = PromptTemplate.from_template(prompt)\n",
    "    # final_prompt_template = final_prompt_template.partial(resume=resume, job=job_listing)\n",
    "\n",
    "    try:\n",
    "        api_key = st.session_state.OPENAI_API_KEY\n",
    "    except:\n",
    "        api_key = os.getenv('OPENAI_API_KEY')\n",
    "        \n",
    "        \n",
    "    llm = ChatOpenAI(temperature=temperature, model=model_type, api_key=api_key)\n",
    "    parser = JsonOutputParser(pydantic_object=ResumeAnalysis,) # PydanticOutputParser(pydantic_object=ResumeRating)#StrOutputParser(output_key=\"response\")\n",
    "    \n",
    "    # Add formatting instructions for pydantic\n",
    "    final_prompt_template = final_prompt_template.partial(format_instructions= parser.get_format_instructions())\n",
    "    \n",
    "    # Making the chain\n",
    "    llm_chain = final_prompt_template | llm | parser\n",
    "    \n",
    "    if return_llm:\n",
    "        return llm_chain\n",
    "    else:\n",
    "        response = llm_chain.invoke(dict(resume=resume, job_listing=job_listing))\n",
    "        return response\n",
    "\n",
    "\n",
    "\n",
    "# llm_chain = analyze_resume(long_resume, job_text_senior_rh, return_llm=True)\n",
    "# llm_chain\n",
    "\n",
    "\n",
    "response = analyze_resume(long_resume, job_text_senior_rh, return_llm=False)\n",
    "response\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['rating', 'justification', 'missing_qualifications', 'matching_qualifications'])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "The resume matches most of the key qualifications and experiences required for the Senior Data Scientist role at Robert Half. The candidate has extensive experience in data science, machine learning, and NLP, which aligns well with the job requirements. However, there is no explicit mention of experience with Azure and Microsoft data services, which are crucial for this role.\n",
      "Experience with Azure Machine Learning, Azure Databricks, and other Microsoft data services; Certifications in Azure data services or advanced analytics; Specific mention of big data platforms and technologies such as Hadoop, Azure data lake, Azure Cosmos DB, Pig, Hive, HBase.\n"
     ]
    }
   ],
   "source": [
    "print(response['rating'])\n",
    "print(response['justification'])\n",
    "print(response['missing_qualifications'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> https://medium.com/@shubham.shardul2019/output-parsers-in-langchain-pydantic-json-parsing-31be48ce6cfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"stop here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX (Previous/unused)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Step 6: Use the Agent to Generate the Structured Response\n",
    "\n",
    "You can now use the agent to generate the structured response based on the resume and job listing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example resume and job listing\n",
    "resume = \"\"\"\n",
    "John Doe\n",
    "Data Scientist with 5 years of experience in data analytics and machine learning.\n",
    "Skills: Python, SQL, Machine Learning, Deep Learning.\n",
    "Education: M.Sc. in Computer Science.\n",
    "\"\"\"\n",
    "job_listing = \"\"\"\n",
    "We are looking for a Data Scientist with the following qualifications:\n",
    "- 5+ years of experience in data analytics.\n",
    "- Proficient in Python and SQL.\n",
    "- Experience with Machine Learning and Deep Learning.\n",
    "- M.Sc. or higher in Computer Science or related field.\n",
    "\"\"\"\n",
    "\n",
    "# Generate the structured response\n",
    "rating = agent.run(\"RateResume\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "matching_qualifications = agent.run(\"ListMatchingQualifications\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "missing_qualifications = agent.run(\"ListMissingQualifications\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "questions = agent.run(\"QuestionsForAdditionalInfo\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "\n",
    "# Output the results\n",
    "print(\"Rating:\")\n",
    "print(rating)\n",
    "print(\"\\nMatching Qualifications:\")\n",
    "print(matching_qualifications)\n",
    "print(\"\\nMissing Qualifications:\")\n",
    "print(missing_qualifications)\n",
    "print(\"\\nQuestions for Additional Info:\")\n",
    "\n",
    "\n",
    "# resume = \"\"\"\n",
    "# John Doe\n",
    "# Data Scientist with 5 years of experience in data analytics and machine learning.\n",
    "# Skills: Python, SQL, Machine Learning, Deep Learning.\n",
    "# Education: M.Sc. in Computer Science.\n",
    "# \"\"\"\n",
    "# job_listing = \"\"\"\n",
    "# We are looking for a Data Scientist with the following qualifications:\n",
    "# - 5+ years of experience in data analytics.\n",
    "# - Proficient in Python and SQL.\n",
    "# - Experience with Machine Learning and Deep Learning.\n",
    "# - M.Sc. or higher in Computer Science or related field.\n",
    "# \"\"\"\n",
    "\n",
    "# Generate the structured response\n",
    "rating = agent.run(\"RateResume\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "matching_qualifications = agent.run(\"ListMatchingQualifications\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "missing_qualifications = agent.run(\"ListMissingQualifications\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "questions = agent.run(\"QuestionsForAdditionalInfo\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "\n",
    "# Output the results\n",
    "print(\"Rating:\")\n",
    "print(rating)\n",
    "print(\"\\nMatching Qualifications:\")\n",
    "print(matching_qualifications)\n",
    "print(\"\\nMissing Qualifications:\")\n",
    "print(missing_qualifications)\n",
    "print(\"\\nQuestions for Additional Info:\")\n",
    "resume = \"\"\"\n",
    "John Doe\n",
    "Data Scientist with 5 years of experience in data analytics and machine learning.\n",
    "Skills: Python, SQL, Machine Learning, Deep Learning.\n",
    "Education: M.Sc. in Computer Science.\n",
    "\"\"\"\n",
    "job_listing = \"\"\"\n",
    "We are looking for a Data Scientist with the following qualifications:\n",
    "- 5+ years of experience in data analytics.\n",
    "- Proficient in Python and SQL.\n",
    "- Experience with Machine Learning and Deep Learning.\n",
    "- M.Sc. or higher in Computer Science or related field.\n",
    "\"\"\"\n",
    "\n",
    "# Generate the structured response\n",
    "rating = agent.run(\"RateResume\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "matching_qualifications = agent.run(\"ListMatchingQualifications\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "missing_qualifications = agent.run(\"ListMissingQualifications\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "questions = agent.run(\"QuestionsForAdditionalInfo\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "\n",
    "# Output the results\n",
    "print(\"Rating:\")\n",
    "print(rating)\n",
    "print(\"\\nMatching Qualifications:\")\n",
    "print(matching_qualifications)\n",
    "print(\"\\nMissing Qualifications:\")\n",
    "print(missing_qualifications)\n",
    "print(\"\\nQuestions for Additional Info:\")\n",
    "print(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Full Example Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here is the complete code for setting up and using the LangChain agent:\n",
    "\n",
    "```python\n",
    "import openai\n",
    "import os\n",
    "from langchain.agents import Tool, create_openai_functions_agent\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Initialize OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'your-openai-api-key'\n",
    "\n",
    "# Function to rate the resume against the job listing\n",
    "def rate_resume_vs_job(resume: str, job_listing: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    I need you to rate this resume against the following job listing out of 5 stars. Please provide a rating and a brief justification.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"gpt-4\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=150,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Function to list matching qualifications\n",
    "def list_matching_qualifications(resume: str, job_listing: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Identify and list the matching qualifications between the following resume and job listing.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"gpt-4\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=150,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Function to list missing qualifications\n",
    "def list_missing_qualifications(resume: str, job_listing: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Identify and list the missing qualifications in the following resume based on the job listing.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"gpt-4\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=150,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Function to list questions for additional information\n",
    "def questions_for_additional_info(resume: str, job_listing: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following resume and job listing, list questions that could help determine if there is additional information that could be added to the resume.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"gpt-4\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=150,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Define the tools\n",
    "rate_resume_tool = Tool(\n",
    "    name=\"RateResume\",\n",
    "    function=rate_resume_vs_job,\n",
    "    description=\"Rates the resume against the job listing and provides a justification.\"\n",
    ")\n",
    "\n",
    "matching_qualifications_tool = Tool(\n",
    "    name=\"ListMatchingQualifications\",\n",
    "    function=list_matching_qualifications,\n",
    "    description=\"Lists the matching qualifications between the resume and job listing.\"\n",
    ")\n",
    "\n",
    "missing_qualifications_tool = Tool(\n",
    "    name=\"ListMissingQualifications\",\n",
    "    function=list_missing_qualifications,\n",
    "    description=\"Lists the missing qualifications in the resume based on the job listing.\"\n",
    ")\n",
    "\n",
    "additional_info_questions_tool = Tool(\n",
    "    name=\"QuestionsForAdditionalInfo\",\n",
    "    function=questions_for_additional_info,\n",
    "    description=\"Lists questions to determine if there is additional information that could be added to the resume.\"\n",
    ")\n",
    "\n",
    "# Initialize the language model\n",
    "llm = OpenAI(model_name=\"gpt-4\")\n",
    "\n",
    "# Create the agent with the defined tools\n",
    "\n",
    "\n",
    "agent = create_openai_functions_agent(llm, [\n",
    "    rate_resume_tool,\n",
    "    matching_qualifications_tool,\n",
    "    missing_qualifications_tool,\n",
    "    additional_info_questions_tool\n",
    "])\n",
    "\n",
    "# Example resume and job listing\n",
    "resume = \"\"\"\n",
    "John Doe\n",
    "Data Scientist with 5 years of experience in data analytics and machine learning.\n",
    "Skills: Python, SQL, Machine Learning, Deep Learning.\n",
    "Education: M.Sc. in Computer Science.\n",
    "\"\"\"\n",
    "job_listing = \"\"\"\n",
    "We are looking for a Data Scientist with the following qualifications:\n",
    "- 5+ years of experience in data analytics.\n",
    "- Proficient in Python and SQL.\n",
    "- Experience with Machine Learning and Deep Learning.\n",
    "- M.Sc. or higher in Computer Science or related field.\n",
    "\"\"\"\n",
    "\n",
    "# Generate the structured response\n",
    "rating = agent.run(\"RateResume\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "matching_qualifications = agent.run(\"ListMatchingQualifications\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "missing_qualifications = agent.run(\"ListMissingQualifications\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "questions = agent.run(\"QuestionsForAdditionalInfo\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "\n",
    "# Output the results\n",
    "print(\"Rating:\")\n",
    "print(rating)\n",
    "print(\"\\nMatching Qualifications:\")\n",
    "print(matching_qualifications)\n",
    "print(\"\\nMissing Qualifications:\")\n",
    "print(missing_qualifications)\n",
    "print(\"\\nQuestions for Additional Info:\")\n",
    "print(questions)\n",
    "```\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This lesson demonstrates how to use LangChain to create an agent that can generate a structured response for a resume evaluation task. By defining custom tools and leveraging the power of OpenAI's GPT-4 model, you can control the structure of the returned response, ensuring that each part of the response is handled separately and effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOOKMARK: ~~05/31/24~~ 06/23/24\n",
    "- ~~Pivoted to CV project for job opportunity~~\n",
    "- [ ] Save the short tailored resume (resume separate from chat gpt conversation text.)\n",
    "- [ ] Feed resume through a second check to confirm there are no new words/tech/skills added.\n",
    "- [ ] (Optional) Examin the bullets and decide if the re-wording was bad or if additional re-wording is needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolutely, James! Let's focus on highlighting the most relevant experiences and skills from your extensive resume to align with the job listing for the Senior Data Scientist position at Robert Half. Here's a condensed, targeted version of your resume:\n",
      "\n",
      "---\n",
      "\n",
      "**James M. Irving, Ph.D.**  \n",
      "8222 Spadderdock Way, Laurel, MD, 20724 | (518) 322-6750 | james.irving.phd@gmail.com  \n",
      "LinkedIn: james-irving-phd | GitHub: https://github.com/jirvingphd  \n",
      "\n",
      "---\n",
      "\n",
      "### **Summary**\n",
      "\n",
      "Innovative data scientist with a robust background in neuroscience and extensive experience in applying advanced data science techniques to real-world problems. Proven track record in machine learning, data analysis, and model deployment, with a strong ability to communicate complex findings to non-technical stakeholders. Committed to leveraging data to drive business solutions and innovation.\n",
      "\n",
      "---\n",
      "\n",
      "### **Core Competencies**\n",
      "\n",
      "- Data Analysis & Statistical Modeling\n",
      "- Machine Learning & Predictive Modeling\n",
      "- Data Visualization & Dashboarding\n",
      "- Natural Language Processing (NLP)\n",
      "- Python Programming, SQL, MATLAB\n",
      "- Cloud Technologies: Azure Machine Learning, Azure Databricks\n",
      "- Big Data Technologies: Hadoop, Azure Data Lake, Azure Cosmos DB\n",
      "\n",
      "---\n",
      "\n",
      "### **Professional Experience**\n",
      "\n",
      "**Coding Dojo | Remote**  \n",
      "*Curriculum Writer - Data Science*  \n",
      "March 2023 - January 2024  \n",
      "- Developed and delivered advanced courses in Time Series Modeling, NLP, and Model Deployment.\n",
      "- Integrated cutting-edge technologies like APIs, Web Scraping, and Computer Vision into the curriculum.\n",
      "- Created and maintained a GitHub Organization for curriculum-related activities, solutions, and packages.\n",
      "\n",
      "*Data Science Instructor*  \n",
      "November 2021 - March 2023  \n",
      "- Achieved high Net Promoter Scores (NPS) exceeding 90% through engaging and interactive live lectures.\n",
      "- Automated administrative tasks, reducing student onboarding time by 99%.\n",
      "\n",
      "**Flatiron School | Remote**  \n",
      "*Data Science Instructor*  \n",
      "October 2019 - October 2021  \n",
      "- Mentored over 60 students, helping them transition into successful data science careers.\n",
      "- Developed and implemented the \"Flex\" boot camp program, refining instructional design and delivery methods.\n",
      "- Created and maintained student-progress-tracking Looker dashboards.\n",
      "\n",
      "**University of Maryland, School of Medicine | Baltimore, MD**  \n",
      "*Postdoctoral Research Fellow*  \n",
      "June 2015 - July 2017  \n",
      "- Led neuroscience research using advanced techniques such as in vivo optogenetics and electrophysiology recordings.\n",
      "- Developed custom analysis scripts in Matlab, enhancing data processing capabilities.\n",
      "- Mentored and guided a diverse team, fostering a collaborative learning environment.\n",
      "\n",
      "---\n",
      "\n",
      "### **Education**\n",
      "\n",
      "**Certificate of Completion, Data Science**  \n",
      "Flatiron School, Online (February 2019 - August 2019)  \n",
      "\n",
      "**Doctor of Philosophy, Neuroscience**  \n",
      "University of Maryland, Baltimore, MD (August 2009 - May 2015)  \n",
      "\n",
      "**Master of Science, Neuroscience**  \n",
      "Tulane University, New Orleans, LA (January 2008 - December 2008)  \n",
      "\n",
      "**Bachelor of Science, Neuroscience (Sociology Minor)**  \n",
      "Tulane University, New Orleans, LA (August 2004 - December 2007)  \n",
      "\n",
      "---\n",
      "\n",
      "### **Selected Data Science Projects**\n",
      "\n",
      "**NLP Analysis of Amazon Reviews + AI Recommendations**  \n",
      "- Conducted sentiment analysis on over 5 million Amazon reviews, achieving 95% accuracy in sentiment classification.\n",
      "- Designed and deployed a user-centric Streamlit dashboard for live sentiment predictions and trend analysis.\n",
      "\n",
      "**Recidivism Risk Assessment**  \n",
      "- Developed a predictive model using Gradient Boosted Trees to classify which released prisoners in Iowa are likely to return to crime, achieving over 70% accuracy.\n",
      "\n",
      "**Forecasting Stock Market Fluctuations with Trump’s Tweets**  \n",
      "- Employed NLP and time series forecasting to predict S&P 500 price changes based on Trump's tweets, integrating multiple data sources and machine learning models.\n",
      "\n",
      "---\n",
      "\n",
      "### **Technical Skills**\n",
      "\n",
      "- **Programming:** Python, SQL (MySQL, SQLAlchemy), MATLAB\n",
      "- **Data Analysis:** ETL (numpy, pandas), AB Testing (scipy, statsmodels), Machine Learning (scikit-learn, Catboost, XGBoost)\n",
      "- **NLP:** nltk, spaCy, Tensorflow, HuggingFace transformers\n",
      "- **Visualization/Dashboarding:** Plotly/Dash, Tableau, Streamlit, Seaborn/Matplotlib, Looker\n",
      "- **Cloud Technologies:** Azure Machine Learning, Azure Databricks, Azure Data Lake, Azure Cosmos DB\n",
      "\n",
      "---\n",
      "\n",
      "### **Certifications**\n",
      "\n",
      "- [Include any relevant certifications, especially in Azure data services or advanced analytics, if applicable]\n",
      "\n",
      "---\n",
      "\n",
      "This version of your resume is tailored to highlight your most relevant experiences and skills for the Senior Data Scientist position at Robert Half. It focuses on your expertise in data science methodologies, machine learning, NLP, and your ability to work with cloud technologies and big data platforms, aligning with the job requirements.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(dict(input=resume_prompt, resume=long_resume, job=job_text_senior_rh))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Required citation of ONET\n",
    "```html\n",
    "<p style=\"text-align: center\"><a href=\"https://services.onetcenter.org/\" title=\"This site incorporates information from O*NET Web Services. Click to learn more.\"><img src=\"https://www.onetcenter.org/image/link/onet-in-it.svg\" style=\"width: 130px; height: 60px; border: none\" alt=\"O*NET in-it\"></a></p>\n",
    "<p>This site incorporates information from <a href=\"https://services.onetcenter.org/\">O*NET Web Services</a> by the U.S. Department of Labor, Employment and Training Administration (USDOL/ETA). O*NET&reg; is a trademark of USDOL/ETA.</p>\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGPT's Version of Agent Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/38d519b6-0803-4398-99ee-06f820153e54"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure the model correctly interprets the response format as part of the output and not additional input variables, we need to clarify the structure and constraints within the prompt. We'll use a clear delimiter to indicate that the model should generate the output in the specified JSON format.\n",
    "\n",
    "Here's how you can modify the functions and prompts to avoid confusion:\n",
    "\n",
    "### Step-by-Step Guide\n",
    "\n",
    "#### Step 1: Set Up the Environment\n",
    "\n",
    "Ensure you have the necessary packages installed:\n",
    "\n",
    "```bash\n",
    "pip install langchain openai\n",
    "```\n",
    "\n",
    "#### Step 2: Initialize the OpenAI API\n",
    "\n",
    "Set up your OpenAI API key:\n",
    "\n",
    "```python\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# Set up your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'your-openai-api-key'\n",
    "```\n",
    "\n",
    "#### Step 3: Define Functions with Clear JSON Output\n",
    "\n",
    "Modify the functions to produce JSON output with a clear indication that the format is part of the response, not additional variables.\n",
    "\n",
    "**Example Functions**:\n",
    "```python\n",
    "import json\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.parsers import OutputParser\n",
    "\n",
    "# Initialize the language model\n",
    "llm = OpenAI(model_name=\"gpt-4\")\n",
    "\n",
    "# Function to rate the resume against the job listing\n",
    "def rate_resume_vs_job(resume: str, job_listing: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Rate this resume against the following job listing out of 5 stars. Provide the rating and a brief justification in JSON format.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "\n",
    "    Response format:\n",
    "    {{\n",
    "        \"rating\": <number>,\n",
    "        \"justification\": \"<string>\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt))\n",
    "    return chain.run({})\n",
    "\n",
    "# Function to list matching qualifications\n",
    "def list_matching_qualifications(resume: str, job_listing: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Identify and list the matching qualifications between the following resume and job listing in JSON format.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "\n",
    "    Response format:\n",
    "    {{\n",
    "        \"matching_qualifications\": [\"<qualification1>\", \"<qualification2>\", ...]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt))\n",
    "    return chain.run({})\n",
    "\n",
    "# Function to list missing qualifications\n",
    "def list_missing_qualifications(resume: str, job_listing: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Identify and list the missing qualifications in the following resume based on the job listing in JSON format.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "\n",
    "    Response format:\n",
    "    {{\n",
    "        \"missing_qualifications\": [\"<qualification1>\", \"<qualification2>\", ...]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt))\n",
    "    return chain.run({})\n",
    "\n",
    "# Function to list questions for additional information\n",
    "def questions_for_additional_info(resume: str, job_listing: str, matching_qualifications: str, missing_qualifications: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following matching and missing qualifications, list questions that could help determine if there is additional information that could be added to the resume in JSON format.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "\n",
    "    Matching Qualifications:\n",
    "    {matching_qualifications}\n",
    "\n",
    "    Missing Qualifications:\n",
    "    {missing_qualifications}\n",
    "\n",
    "    Response format:\n",
    "    {{\n",
    "        \"questions\": [\"<question1>\", \"<question2>\", ...]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt))\n",
    "    return chain.run({})\n",
    "```\n",
    "\n",
    "#### Step 4: Define Tools for LangChain Agent\n",
    "\n",
    "Create tools that the LangChain agent can use to perform these tasks.\n",
    "\n",
    "```python\n",
    "from langchain.agents import Tool\n",
    "\n",
    "rate_resume_tool = Tool(\n",
    "    name=\"RateResume\",\n",
    "    function=rate_resume_vs_job,\n",
    "    description=\"Rates the resume against the job listing and provides a justification in JSON format.\"\n",
    ")\n",
    "\n",
    "matching_qualifications_tool = Tool(\n",
    "    name=\"ListMatchingQualifications\",\n",
    "    function=list_matching_qualifications,\n",
    "    description=\"Lists the matching qualifications between the resume and job listing in JSON format.\"\n",
    ")\n",
    "\n",
    "missing_qualifications_tool = Tool(\n",
    "    name=\"ListMissingQualifications\",\n",
    "    function=list_missing_qualifications,\n",
    "    description=\"Lists the missing qualifications in the resume based on the job listing in JSON format.\"\n",
    ")\n",
    "\n",
    "additional_info_questions_tool = Tool(\n",
    "    name=\"QuestionsForAdditionalInfo\",\n",
    "    function=questions_for_additional_info,\n",
    "    description=\"Lists questions to determine if there is additional information that could be added to the resume based on matching and missing qualifications in JSON format.\"\n",
    ")\n",
    "```\n",
    "\n",
    "#### Step 5: Create the Agent with JSON Output Parsing\n",
    "\n",
    "Initialize the language model and create an agent that uses the defined tools. Include the JSON output parser to handle the responses.\n",
    "\n",
    "```python\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "\n",
    "# Create a prompt template for the agent\n",
    "agent_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Given the resume and job listing, decide which task to perform:\n",
    "- RateResume: Rate the resume against the job listing and provide a justification.\n",
    "- ListMatchingQualifications: List the matching qualifications between the resume and job listing.\n",
    "- ListMissingQualifications: List the missing qualifications in the resume based on the job listing.\n",
    "- QuestionsForAdditionalInfo: List questions to determine if there is additional information that could be added to the resume based on matching and missing qualifications.\n",
    "Provide the name of the task followed by the appropriate inputs in the required format.\n",
    "\"\"\")\n",
    "\n",
    "# Create the agent with the defined tools and output parser\n",
    "agent = create_openai_functions_agent(llm, [\n",
    "    rate_resume_tool,\n",
    "    matching_qualifications_tool,\n",
    "    missing_qualifications_tool,\n",
    "    additional_info_questions_tool\n",
    "], prompt=agent_prompt, output_parser=OutputParser.from_json())\n",
    "```\n",
    "\n",
    "#### Step 6: Use the Agent to Generate the Structured Response\n",
    "\n",
    "You can now use the agent to generate the structured response based on the resume and job listing.\n",
    "\n",
    "```python\n",
    "# Example resume and job listing\n",
    "resume = \"\"\"\n",
    "John Doe\n",
    "Data Scientist with 5 years of experience in data analytics and machine learning.\n",
    "Skills: Python, SQL, Machine Learning, Deep Learning.\n",
    "Education: M.Sc. in Computer Science.\n",
    "\"\"\"\n",
    "job_listing = \"\"\"\n",
    "We are looking for a Data Scientist with the following qualifications:\n",
    "- 5+ years of experience in data analytics.\n",
    "- Proficient in Python and SQL.\n",
    "- Experience with Machine Learning and Deep Learning.\n",
    "- M.Sc. or higher in Computer Science or related field.\n",
    "\"\"\"\n",
    "\n",
    "# Generate the structured response\n",
    "rating_response = agent.run(\"RateResume\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "rating = json.loads(rating_response)\n",
    "print(\"Rating:\", rating['rating'])\n",
    "print(\"Justification:\", rating['justification'])\n",
    "\n",
    "matching_response = agent.run(\"ListMatchingQualifications\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "matching_qualifications = json.loads(matching_response)['matching_qualifications']\n",
    "print(\"\\nMatching Qualifications:\", matching_qualifications)\n",
    "\n",
    "missing_response = agent.run(\"ListMissingQualifications\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "missing_qualifications = json.loads(missing_response)['missing_qualifications']\n",
    "print(\"\\nMissing Qualifications:\", missing_qualifications)\n",
    "\n",
    "questions_response = agent.run(\"QuestionsForAdditionalInfo\", {\n",
    "    \"resume\": resume,\n",
    "    \"job_listing\": job_listing,\n",
    "    \"matching_qualifications\": matching_qualifications,\n",
    "    \"missing_qualifications\": missing_qualifications\n",
    "})\n",
    "questions = json.loads(questions_response)['questions']\n",
    "print(\"\\nQuestions for Additional Info:\", questions)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Full Example Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here is the complete code for setting up and using the LangChain agent with JSON output parsing:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Prompt must have input variable `agent_scratchpad`, but wasn't found. Found [] instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 141\u001b[0m\n\u001b[1;32m    131\u001b[0m agent_prompt \u001b[38;5;241m=\u001b[39m PromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124mGiven the resume and job listing, decide which task to perform:\u001b[39m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124m- RateResume: Rate the resume against the job listing and provide a justification.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124mProvide the name of the task followed by the appropriate inputs in the required format.\u001b[39m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# Create the agent with the defined tools and output parser\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_openai_functions_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrate_resume_tool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatching_qualifications_tool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmissing_qualifications_tool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_info_questions_tool\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent_prompt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, output_parser=JsonOutputParser())#OutputParser.from_json())\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages/langchain/agents/openai_functions_agent/base.py:304\u001b[0m, in \u001b[0;36mcreate_openai_functions_agent\u001b[0;34m(llm, tools, prompt)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create an agent that uses OpenAI function calling.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;124;03m        )\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_scratchpad\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m    302\u001b[0m     prompt\u001b[38;5;241m.\u001b[39minput_variables \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(prompt\u001b[38;5;241m.\u001b[39mpartial_variables)\n\u001b[1;32m    303\u001b[0m ):\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt must have input variable `agent_scratchpad`, but wasn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt found. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;241m.\u001b[39minput_variables\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m     )\n\u001b[1;32m    308\u001b[0m llm_with_tools \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mbind(functions\u001b[38;5;241m=\u001b[39m[convert_to_openai_function(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tools])\n\u001b[1;32m    309\u001b[0m agent \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    310\u001b[0m     RunnablePassthrough\u001b[38;5;241m.\u001b[39massign(\n\u001b[1;32m    311\u001b[0m         agent_scratchpad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: format_to_openai_function_messages(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;241m|\u001b[39m OpenAIFunctionsAgentOutputParser()\n\u001b[1;32m    318\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Prompt must have input variable `agent_scratchpad`, but wasn't found. Found [] instead."
     ]
    }
   ],
   "source": [
    "\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "from langchain.agents import Tool, create_openai_functions_agent\n",
    "# from langchain.llms import OpenAI\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "# from langchain.parsers import OutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "\n",
    "\n",
    "# Initialize OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'your-openai-api-key'\n",
    "\n",
    "# Initialize the language model\n",
    "# llm = OpenAI(model_name=\"gpt-4\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\")\n",
    "\n",
    "# Function to rate the resume against the job listing\n",
    "def rate_resume_vs_job(resume: str, job_listing: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Rate this resume against the following job listing out of 5 stars. Provide the rating and a brief justification in JSON format.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "\n",
    "    Response format:\n",
    "    {{\n",
    "        \"rating\": 5,\n",
    "        \"justification\": \"The resume perfectly matches the job requirements.\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt))\n",
    "    return chain.run({})\n",
    "\n",
    "# Function to list matching qualifications\n",
    "def list_matching_qualifications(resume: str, job_listing: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Identify and list the matching qualifications between the following resume and job listing in JSON format.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "\n",
    "    Response format:\n",
    "    {{\n",
    "        \"matching_qualifications\": [\"Python\", \"SQL\", \"Machine Learning\", \"Deep Learning\"]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt))\n",
    "    return chain.run({})\n",
    "\n",
    "# Function to list missing qualifications\n",
    "def list_missing_qualifications(resume: str, job_listing: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Identify and list the missing qualifications in\n",
    "\n",
    " the following resume based on the job listing in JSON format.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "\n",
    "    Response format:\n",
    "    {{\n",
    "        \"missing_qualifications\": [\"Experience with Big Data\"]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt))\n",
    "    return chain.run({})\n",
    "\n",
    "# Function to list questions for additional information\n",
    "def questions_for_additional_info(resume: str, job_listing: str, matching_qualifications: str, missing_qualifications: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following matching and missing qualifications, list questions that could help determine if there is additional information that could be added to the resume in JSON format.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "\n",
    "    Matching Qualifications:\n",
    "    {matching_qualifications}\n",
    "\n",
    "    Missing Qualifications:\n",
    "    {missing_qualifications}\n",
    "\n",
    "    Response format:\n",
    "    {{\n",
    "        \"questions\": [\"Do you have experience with Big Data?\", \"Have you worked on projects that involved large-scale data processing?\"]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt))\n",
    "    return chain.run({})\n",
    "\n",
    "# Define the tools\n",
    "rate_resume_tool = Tool(\n",
    "    \"RateResume\",\n",
    "    rate_resume_vs_job,\n",
    "    description=\"Rates the resume against the job listing and provides a justification in JSON format.\"\n",
    ")\n",
    "\n",
    "matching_qualifications_tool = Tool(\n",
    "    \"ListMatchingQualifications\",\n",
    "    list_matching_qualifications,\n",
    "    description=\"Lists the matching qualifications between the resume and job listing in JSON format.\"\n",
    ")\n",
    "\n",
    "missing_qualifications_tool = Tool(\n",
    "    \"ListMissingQualifications\",\n",
    "    list_missing_qualifications,\n",
    "    description=\"Lists the missing qualifications in the resume based on the job listing in JSON format.\"\n",
    ")\n",
    "\n",
    "additional_info_questions_tool = Tool(\n",
    "    \"QuestionsForAdditionalInfo\",\n",
    "    questions_for_additional_info,\n",
    "    description=\"Lists questions to determine if there is additional information that could be added to the resume based on matching and missing qualifications in JSON format.\"\n",
    ")\n",
    "\n",
    "# Create a prompt template for the agent\n",
    "agent_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Given the resume and job listing, decide which task to perform:\n",
    "- RateResume: Rate the resume against the job listing and provide a justification.\n",
    "- ListMatchingQualifications: List the matching qualifications between the resume and job listing.\n",
    "- ListMissingQualifications: List the missing qualifications in the resume based on the job listing.\n",
    "- QuestionsForAdditionalInfo: List questions to determine if there is additional information that could be added to the resume based on matching and missing qualifications.\n",
    "Provide the name of the task followed by the appropriate inputs in the required format.\n",
    "\"\"\")\n",
    "\n",
    "# Create the agent with the defined tools and output parser\n",
    "agent = create_openai_functions_agent(llm, [\n",
    "    rate_resume_tool,\n",
    "    matching_qualifications_tool,\n",
    "    missing_qualifications_tool,\n",
    "    additional_info_questions_tool\n",
    "], prompt=agent_prompt)#, output_parser=JsonOutputParser())#OutputParser.from_json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example resume and job listing\n",
    "resume = \"\"\"\n",
    "John Doe\n",
    "Data Scientist with 5 years of experience in data analytics and machine learning.\n",
    "Skills: Python, SQL, Machine Learning, Deep Learning.\n",
    "Education: M.Sc. in Computer Science.\n",
    "\"\"\"\n",
    "job_listing = \"\"\"\n",
    "We are looking for a Data Scientist with the following qualifications:\n",
    "- 5+ years of experience in data analytics.\n",
    "- Proficient in Python and SQL.\n",
    "- Experience with Machine Learning and Deep Learning.\n",
    "- M.Sc. or higher in Computer Science or related field.\n",
    "\"\"\"\n",
    "\n",
    "# Generate the structured response\n",
    "rating_response = agent.run(\"RateResume\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "rating = json.loads(rating_response)\n",
    "print(\"Rating:\", rating['rating'])\n",
    "print(\"Justification:\", rating['justification'])\n",
    "\n",
    "matching_response = agent.run(\"ListMatchingQualifications\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "matching_qualifications = json.loads(matching_response)['matching_qualifications']\n",
    "print(\"\\nMatching Qualifications:\", matching_qualifications)\n",
    "\n",
    "missing_response = agent.run(\"ListMissingQualifications\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "missing_qualifications = json.loads(missing_response)['missing_qualifications']\n",
    "print(\"\\nMissing Qualifications:\", missing_qualifications)\n",
    "\n",
    "questions_response = agent.run(\"QuestionsForAdditionalInfo\", {\n",
    "    \"resume\": resume,\n",
    "    \"job_listing\": job_listing,\n",
    "    \"matching_qualifications\": matching_qualifications,\n",
    "    \"missing_qualifications\": missing_qualifications\n",
    "})\n",
    "questions = json.loads(questions_response)['questions']\n",
    "print(\"\\nQuestions for Additional Info:\", questions)\n",
    "```\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "By clarifying the response format and using JSON parsing, you can ensure the language model generates structured outputs that are easier to handle and integrate into your application. This approach provides a robust way to manage and process complex interactions with the language model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dojo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
