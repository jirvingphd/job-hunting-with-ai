{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import app_functions as af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume_fpath = 'data/James Irving Resume 2024.pdf'\n",
    "\n",
    "# job_fpath='data/Data Scientist - Focus School Software _ Remote.pdf'\n",
    "# job_fpath_simplyhired = \"data/SimplyHired-Data Scientist - Tech Holding _ Remote.pdf\"\n",
    "# job_fpath_indeed = 'data/Indeed-Data Science-Columbia.pdf'\n",
    "# job_fpath_linkedin = 'data/LinkedIn- AI & ML Engineer _ BDO USA _ LinkedIn.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['username', 'password'])\n"
     ]
    }
   ],
   "source": [
    "# Onet web services API credentials\n",
    "import json\n",
    "login_fpath = \"/Users/codingdojo/.secret/onet.json\"\n",
    "with open(login_fpath) as f:\n",
    "    login = json.load(f)\n",
    "    print(login.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"query\": \"Data Scientist\",\n",
      "      \"results\": [\n",
      "        {\n",
      "          \"code\": \"15-2051.00\",\n",
      "          \"title\": \"Data Scientists\"\n",
      "        },\n",
      "        {\n",
      "          \"code\": \"15-1221.00\",\n",
      "          \"title\": \"Computer and Information Research Scientists\"\n",
      "        },\n",
      "        {\n",
      "          \"code\": \"19-4061.00\",\n",
      "          \"title\": \"Social Science Research Assistants\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"query\": \"Data Analyst\",\n",
      "      \"results\": [\n",
      "        {\n",
      "          \"code\": \"15-2051.00\",\n",
      "          \"title\": \"Data Scientists\"\n",
      "        },\n",
      "        {\n",
      "          \"code\": \"15-2051.01\",\n",
      "          \"title\": \"Business Intelligence Analysts\"\n",
      "        },\n",
      "        {\n",
      "          \"code\": \"13-2099.01\",\n",
      "          \"title\": \"Financial Quantitative Analysts\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"query\": \"AI Engineer\",\n",
      "      \"results\": [\n",
      "        {\n",
      "          \"code\": \"15-1221.00\",\n",
      "          \"title\": \"Computer and Information Research Scientists\"\n",
      "        },\n",
      "        {\n",
      "          \"code\": \"15-1299.05\",\n",
      "          \"title\": \"Information Security Engineers\"\n",
      "        },\n",
      "        {\n",
      "          \"code\": \"15-1252.00\",\n",
      "          \"title\": \"Software Developers\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}"
     ]
    }
   ],
   "source": [
    "## Starting code example\n",
    "# SOURCE: https://github.com/onetcenter/web-services-samples/blob/master/python-3/batch_coder.py\n",
    "#!python3\n",
    "# from OnetWebService import OnetWebService\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "# read JSON input\n",
    "# input = json.load(sys.stdin)\n",
    "config = {'max_results':3, }\n",
    "queries = ['Data Scientist','Data Analyst','AI Engineer']\n",
    "\n",
    "\n",
    "# initialize Web Services and results objects\n",
    "onet_ws = af.OnetWebService(login['username'], login['password'])#input['config']['username'], input['config']['password'])\n",
    "max_results = max(1, config['max_results'])\n",
    "output = { 'output': [] }\n",
    "\n",
    "\n",
    "# call keyword search for each input query\n",
    "for q in queries:#input['queries']:\n",
    "    res = []\n",
    "    kwresults = onet_ws.call('online/search',\n",
    "                             ('keyword', q),\n",
    "                             ('end', max_results))\n",
    "    time.sleep(.020)\n",
    "    if ('occupation' in kwresults) and (0 < len(kwresults['occupation'])):\n",
    "        for occ in kwresults['occupation']:\n",
    "            res.append({ 'code': occ['code'], 'title': occ['title'] })\n",
    "    output['output'].append({ 'query': q, 'results': res })\n",
    "\n",
    "json.dump(output, sys.stdout, indent=2, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'Data Scientist',\n",
       "  'results': [{'code': '15-2051.00', 'title': 'Data Scientists'},\n",
       "   {'code': '15-1221.00',\n",
       "    'title': 'Computer and Information Research Scientists'},\n",
       "   {'code': '19-4061.00', 'title': 'Social Science Research Assistants'},\n",
       "   {'code': '19-1029.01', 'title': 'Bioinformatics Scientists'},\n",
       "   {'code': '15-2099.01', 'title': 'Bioinformatics Technicians'}]}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import time\n",
    "# from OnetWebService import OnetWebService\n",
    "\n",
    "def onet_keyword_search(login, config, queries):\n",
    "    \"\"\"\n",
    "    Perform a keyword search using the OnetWebService.\n",
    "\n",
    "    Args:\n",
    "        login (dict): A dictionary containing the login credentials for the OnetWebService.\n",
    "                      It should have 'username' and 'password' keys.\n",
    "        config (dict): A dictionary containing configuration options for the keyword search.\n",
    "                       It should have a 'max_results' key specifying the maximum number of results to retrieve.\n",
    "        queries (list): A list of queries to perform the keyword search on.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Side Effects:\n",
    "        Prints the search results in JSON format to the standard output.\n",
    "\n",
    "    \"\"\"\n",
    "    # initialize Web Services and results objects\n",
    "    onet_ws = af.OnetWebService(login['username'], login['password'])\n",
    "    max_results = max(1, config['max_results'])\n",
    "    output = { 'output': [],\n",
    "               'config': config,\n",
    "               'queries': queries}\n",
    "\n",
    "    # call keyword search for each input query\n",
    "    for q in queries:\n",
    "        res = []\n",
    "        kwresults = onet_ws.call('online/search',\n",
    "                                 ('keyword', q),\n",
    "                                 ('end', max_results))\n",
    "        time.sleep(.020)\n",
    "        if ('occupation' in kwresults) and (0 < len(kwresults['occupation'])):\n",
    "            for occ in kwresults['occupation']:\n",
    "                res.append({ 'code': occ['code'], 'title': occ['title'] })\n",
    "        output['output'].append({ 'query': q, 'results': res })\n",
    "\n",
    "    # json.dump(output, sys.stdout, indent=2, sort_keys=True)\n",
    "    return output\n",
    "    \n",
    "\n",
    "# usage\n",
    "# login = {'username': 'your_username', 'password': 'your_password'}\n",
    "config = {'max_results':5}\n",
    "queries = ['Data Scientist']#,'AI Engineer']\n",
    "job_results = onet_keyword_search(login, config, queries)\n",
    "job_results['output']#['results']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which Services to Use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- List of full services in API: https://services.onetcenter.org/reference/#full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Have ChatGPT use the resume or job listing to extract the job title.\n",
    "2. Call Onet services to get list of top X related results. \n",
    "    - Results include name and job code.\n",
    "3. Use job code to look up overview. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing Job Occupation Report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def onet_occupation_report(login,  job_code):\n",
    "    \"\"\"\n",
    "    Perform a keyword search using the OnetWebService.\n",
    "\n",
    "    Args:\n",
    "        login (dict): A dictionary containing the login credentials for the OnetWebService.\n",
    "                      It should have 'username' and 'password' keys.\n",
    "        config (dict): A dictionary containing configuration options for the keyword search.\n",
    "                       It should have a 'max_results' key specifying the maximum number of results to retrieve.\n",
    "        queries (list): A list of queries to perform the keyword search on.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Side Effects:\n",
    "        Prints the search results in JSON format to the standard output.\n",
    "\n",
    "    \"\"\"\n",
    "    # queries = [job_code]\n",
    "    # initialize Web Services and results objects\n",
    "    onet_ws = af.OnetWebService(login['username'], login['password'])\n",
    "    # max_results = #max(1, config['max_results'])\n",
    "    # output = { 'output': [],\n",
    "    #         #    'config': dict(max_results=max_results),\n",
    "    #            'query': job_code\n",
    "    #            }\n",
    "\n",
    "    # call keyword search for each input query\n",
    "    # for q in queries:\n",
    "        # res = []\n",
    "        # kwresults = onet_ws.call('online/occupations',\n",
    "        #                          ('keyword', q),\n",
    "        #                          ('end', max_results))\n",
    "    report = onet_ws.occupation_report(job_code)\n",
    "    # output['output'] = report\n",
    "        # if ('occupation' in kwresults) and (0 < len(kwresults['occupation'])):\n",
    "        #     for occ in kwresults['occupation']:\n",
    "        #         res.append({ 'code': occ['code'], 'title': occ['title'] })\n",
    "        # output['output'].append({ 'query': q, 'results': res })\n",
    "\n",
    "    # json.dump(output, sys.stdout, indent=2, sort_keys=True)\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://services.onetcenter.org/ws/online/occupations/15-2051.00/'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occupation_base_url = \"https://services.onetcenter.org/ws/online/occupations/{job_code}/\"\n",
    "occupation_base_url.format(job_code=\"15-2051.00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': '15-2051.00', 'title': 'Data Scientists'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_code_results = job_results['output'][0]['results']#[0]['code']\n",
    "test_result = job_code_results[0]\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': '15-2051.00',\n",
       " 'title': 'Data Scientists',\n",
       " 'tags': {'bright_outlook': True, 'green': False},\n",
       " 'description': 'Develop and implement a set of techniques or analytics applications to transform raw data into meaningful information using data-oriented programming languages and visualization software. Apply data mining, data modeling, natural language processing, and machine learning to extract and analyze information from large structured and unstructured datasets. Visualize, interpret, and report data findings. May create dynamic data reports.',\n",
       " 'also_see': {'occupation': [{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.01/',\n",
       "    'code': '15-2051.01',\n",
       "    'title': 'Business Intelligence Analysts',\n",
       "    'tags': {'bright_outlook': True, 'green': False}},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.02/',\n",
       "    'code': '15-2051.02',\n",
       "    'title': 'Clinical Data Managers',\n",
       "    'tags': {'bright_outlook': True, 'green': False}}]},\n",
       " 'updated': {'partial': True,\n",
       "  'year': 2024,\n",
       "  'resource_updated': [{'title': 'Abilities'},\n",
       "   {'title': 'Alternate Titles', 'source': 'Multiple sources', 'year': 2023},\n",
       "   {'title': 'Detailed Work Activities', 'source': 'Analyst', 'year': 2020},\n",
       "   {'title': 'Education'},\n",
       "   {'title': 'Interests', 'source': 'Machine Learning', 'year': 2023},\n",
       "   {'title': 'Job Zone', 'source': 'Analyst - Preliminary', 'year': 2021},\n",
       "   {'title': 'Knowledge'},\n",
       "   {'title': 'Sample of Reported Titles'},\n",
       "   {'title': 'Skills'},\n",
       "   {'title': 'Tasks', 'source': 'Analyst', 'year': 2020},\n",
       "   {'title': 'Technology Skills & Tools', 'source': 'Analyst', 'year': 2024},\n",
       "   {'title': 'Work Activities'},\n",
       "   {'title': 'Work Context'},\n",
       "   {'title': 'Work Needs'},\n",
       "   {'title': 'Work Styles'},\n",
       "   {'title': 'Work Values'}]},\n",
       " 'bright_outlook': {'description': 'This occupation is expected to grow rapidly.',\n",
       "  'category': ['Grow Rapidly']},\n",
       " 'summary_resources': {'resource': [{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/tasks',\n",
       "    'title': 'Tasks'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/technology_skills',\n",
       "    'title': 'Technology Skills'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/tools_technology',\n",
       "    'title': 'Tools &amp; Technology'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/detailed_work_activities',\n",
       "    'title': 'Detailed Work Activities'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/job_zone',\n",
       "    'title': 'Job Zone'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/interests',\n",
       "    'title': 'Interests'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/related_occupations',\n",
       "    'title': 'Related Occupations'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/additional_information',\n",
       "    'title': 'Sources of Additional Information'}]},\n",
       " 'details_resources': {'resource': [{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/tasks',\n",
       "    'title': 'Tasks'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/technology_skills',\n",
       "    'title': 'Technology Skills'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/tools_technology',\n",
       "    'title': 'Tools &amp; Technology'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/detailed_work_activities',\n",
       "    'title': 'Detailed Work Activities'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/job_zone',\n",
       "    'title': 'Job Zone'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/interests',\n",
       "    'title': 'Interests'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/related_occupations',\n",
       "    'title': 'Related Occupations'},\n",
       "   {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/additional_information',\n",
       "    'title': 'Sources of Additional Information'}]},\n",
       " 'custom_resources': {'resource': [{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/custom/work_activities_outline',\n",
       "    'title': 'Work Activities Outline'}]}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = onet_occupation_report(login, job_code=test_result['code'])\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['code', 'title', 'tags', 'description', 'also_see', 'updated', 'bright_outlook', 'summary_resources', 'details_resources', 'custom_resources'])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing report results\n",
    "# report = results_report['output']\n",
    "report.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "      <th>description</th>\n",
       "      <th>also_see</th>\n",
       "      <th>updated</th>\n",
       "      <th>bright_outlook</th>\n",
       "      <th>summary_resources</th>\n",
       "      <th>details_resources</th>\n",
       "      <th>custom_resources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bright_outlook</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>True</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>green</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>False</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td></td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>[{'href': 'https://services.onetcenter.org/ws/...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td></td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td></td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td></td>\n",
       "      <td>2024</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resource_updated</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td></td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td></td>\n",
       "      <td>[{'title': 'Abilities'}, {'title': 'Alternate ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td></td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>This occupation is expected to grow rapidly.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td></td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[Grow Rapidly]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resource</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td></td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'href': 'https://services.onetcenter.org/ws/...</td>\n",
       "      <td>[{'href': 'https://services.onetcenter.org/ws/...</td>\n",
       "      <td>[{'href': 'https://services.onetcenter.org/ws/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        code            title   tags  \\\n",
       "bright_outlook    15-2051.00  Data Scientists   True   \n",
       "green             15-2051.00  Data Scientists  False   \n",
       "occupation        15-2051.00  Data Scientists          \n",
       "partial           15-2051.00  Data Scientists          \n",
       "year              15-2051.00  Data Scientists          \n",
       "resource_updated  15-2051.00  Data Scientists          \n",
       "description       15-2051.00  Data Scientists          \n",
       "category          15-2051.00  Data Scientists          \n",
       "resource          15-2051.00  Data Scientists          \n",
       "\n",
       "                                                        description  \\\n",
       "bright_outlook    Develop and implement a set of techniques or a...   \n",
       "green             Develop and implement a set of techniques or a...   \n",
       "occupation        Develop and implement a set of techniques or a...   \n",
       "partial           Develop and implement a set of techniques or a...   \n",
       "year              Develop and implement a set of techniques or a...   \n",
       "resource_updated  Develop and implement a set of techniques or a...   \n",
       "description       Develop and implement a set of techniques or a...   \n",
       "category          Develop and implement a set of techniques or a...   \n",
       "resource          Develop and implement a set of techniques or a...   \n",
       "\n",
       "                                                           also_see  \\\n",
       "bright_outlook                                                        \n",
       "green                                                                 \n",
       "occupation        [{'href': 'https://services.onetcenter.org/ws/...   \n",
       "partial                                                               \n",
       "year                                                                  \n",
       "resource_updated                                                      \n",
       "description                                                           \n",
       "category                                                              \n",
       "resource                                                              \n",
       "\n",
       "                                                            updated  \\\n",
       "bright_outlook                                                        \n",
       "green                                                                 \n",
       "occupation                                                            \n",
       "partial                                                        True   \n",
       "year                                                           2024   \n",
       "resource_updated  [{'title': 'Abilities'}, {'title': 'Alternate ...   \n",
       "description                                                           \n",
       "category                                                              \n",
       "resource                                                              \n",
       "\n",
       "                                                bright_outlook  \\\n",
       "bright_outlook                                                   \n",
       "green                                                            \n",
       "occupation                                                       \n",
       "partial                                                          \n",
       "year                                                             \n",
       "resource_updated                                                 \n",
       "description       This occupation is expected to grow rapidly.   \n",
       "category                                        [Grow Rapidly]   \n",
       "resource                                                         \n",
       "\n",
       "                                                  summary_resources  \\\n",
       "bright_outlook                                                        \n",
       "green                                                                 \n",
       "occupation                                                            \n",
       "partial                                                               \n",
       "year                                                                  \n",
       "resource_updated                                                      \n",
       "description                                                           \n",
       "category                                                              \n",
       "resource          [{'href': 'https://services.onetcenter.org/ws/...   \n",
       "\n",
       "                                                  details_resources  \\\n",
       "bright_outlook                                                        \n",
       "green                                                                 \n",
       "occupation                                                            \n",
       "partial                                                               \n",
       "year                                                                  \n",
       "resource_updated                                                      \n",
       "description                                                           \n",
       "category                                                              \n",
       "resource          [{'href': 'https://services.onetcenter.org/ws/...   \n",
       "\n",
       "                                                   custom_resources  \n",
       "bright_outlook                                                       \n",
       "green                                                                \n",
       "occupation                                                           \n",
       "partial                                                              \n",
       "year                                                                 \n",
       "resource_updated                                                     \n",
       "description                                                          \n",
       "category                                                             \n",
       "resource          [{'href': 'https://services.onetcenter.org/ws/...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Checking report as a dataframe\n",
    "report_df = pd.DataFrame(report).fillna('')\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code:\n",
      "    15-2051.00\n",
      "title:\n",
      "    Data Scientists\n",
      "tags:\n",
      "    {'bright_outlook': True, 'green': False}\n",
      "description:\n",
      "    Develop and implement a set of techniques or analytics applications to transform raw data into meaningful information using data-oriented programming languages and visualization software. Apply data mining, data modeling, natural language processing, and machine learning to extract and analyze information from large structured and unstructured datasets. Visualize, interpret, and report data findings. May create dynamic data reports.\n",
      "also_see:\n",
      "    {'occupation': [{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.01/', 'code': '15-2051.01', 'title': 'Business Intelligence Analysts', 'tags': {'bright_outlook': True, 'green': False}}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.02/', 'code': '15-2051.02', 'title': 'Clinical Data Managers', 'tags': {'bright_outlook': True, 'green': False}}]}\n",
      "updated:\n",
      "    {'partial': True, 'year': 2024, 'resource_updated': [{'title': 'Abilities'}, {'title': 'Alternate Titles', 'source': 'Multiple sources', 'year': 2023}, {'title': 'Detailed Work Activities', 'source': 'Analyst', 'year': 2020}, {'title': 'Education'}, {'title': 'Interests', 'source': 'Machine Learning', 'year': 2023}, {'title': 'Job Zone', 'source': 'Analyst - Preliminary', 'year': 2021}, {'title': 'Knowledge'}, {'title': 'Sample of Reported Titles'}, {'title': 'Skills'}, {'title': 'Tasks', 'source': 'Analyst', 'year': 2020}, {'title': 'Technology Skills & Tools', 'source': 'Analyst', 'year': 2024}, {'title': 'Work Activities'}, {'title': 'Work Context'}, {'title': 'Work Needs'}, {'title': 'Work Styles'}, {'title': 'Work Values'}]}\n",
      "bright_outlook:\n",
      "    {'description': 'This occupation is expected to grow rapidly.', 'category': ['Grow Rapidly']}\n",
      "summary_resources:\n",
      "    {'resource': [{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/tasks', 'title': 'Tasks'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/technology_skills', 'title': 'Technology Skills'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/tools_technology', 'title': 'Tools &amp; Technology'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/detailed_work_activities', 'title': 'Detailed Work Activities'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/job_zone', 'title': 'Job Zone'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/interests', 'title': 'Interests'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/related_occupations', 'title': 'Related Occupations'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/additional_information', 'title': 'Sources of Additional Information'}]}\n",
      "details_resources:\n",
      "    {'resource': [{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/tasks', 'title': 'Tasks'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/technology_skills', 'title': 'Technology Skills'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/tools_technology', 'title': 'Tools &amp; Technology'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/detailed_work_activities', 'title': 'Detailed Work Activities'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/job_zone', 'title': 'Job Zone'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/interests', 'title': 'Interests'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/related_occupations', 'title': 'Related Occupations'}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/additional_information', 'title': 'Sources of Additional Information'}]}\n",
      "custom_resources:\n",
      "    {'resource': [{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/custom/work_activities_outline', 'title': 'Work Activities Outline'}]}\n"
     ]
    }
   ],
   "source": [
    "# Printing report\n",
    "for k,v in report.items():\n",
    "    print(f\"{k}:\\n    {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta_keys=['code', 'title', 'description']\n",
      "list_keys=[]\n",
      "dict_keys=['tags', 'also_see', 'updated', 'bright_outlook', 'summary_resources', 'details_resources', 'custom_resources']\n"
     ]
    }
   ],
   "source": [
    "# Separating the keys by type\n",
    "meta_keys = [k for k,v in report.items() if isinstance(v, str)]\n",
    "list_keys = [k for k,v in report.items() if isinstance(v, list)]\n",
    "dict_keys = [k for k,v in report.items() if isinstance(v, dict)]\n",
    "\n",
    "print(f\"{meta_keys=}\\n{list_keys=}\\n{dict_keys=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags:\n",
      "    dict_keys(['bright_outlook', 'green'])\n",
      "also_see:\n",
      "    dict_keys(['occupation'])\n",
      "updated:\n",
      "    dict_keys(['partial', 'year', 'resource_updated'])\n",
      "bright_outlook:\n",
      "    dict_keys(['description', 'category'])\n",
      "summary_resources:\n",
      "    dict_keys(['resource'])\n",
      "details_resources:\n",
      "    dict_keys(['resource'])\n",
      "custom_resources:\n",
      "    dict_keys(['resource'])\n"
     ]
    }
   ],
   "source": [
    "for k in dict_keys:\n",
    "    print(f\"{k}:\\n    {report[k].keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dont use type to separate, separate by resources ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['summary_resources', 'details_resources', 'custom_resources']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resource_keys = [k for k in report if 'resource' in k.lower()]\n",
    "resource_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/tasks',\n",
       "  'title': 'Tasks'},\n",
       " {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/technology_skills',\n",
       "  'title': 'Technology Skills'},\n",
       " {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/tools_technology',\n",
       "  'title': 'Tools &amp; Technology'},\n",
       " {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/detailed_work_activities',\n",
       "  'title': 'Detailed Work Activities'},\n",
       " {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/job_zone',\n",
       "  'title': 'Job Zone'},\n",
       " {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/interests',\n",
       "  'title': 'Interests'},\n",
       " {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/related_occupations',\n",
       "  'title': 'Related Occupations'},\n",
       " {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/additional_information',\n",
       "  'title': 'Sources of Additional Information'}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report[resource_keys[0]]['resource']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/tasks', 'title': 'Tasks'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/technology_skills', 'title': 'Technology Skills'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/tools_technology', 'title': 'Tools &amp; Technology'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/detailed_work_activities', 'title': 'Detailed Work Activities'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/job_zone', 'title': 'Job Zone'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/interests', 'title': 'Interests'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/related_occupations', 'title': 'Related Occupations'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/summary/additional_information', 'title': 'Sources of Additional Information'}\n",
      "\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/tasks', 'title': 'Tasks'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/technology_skills', 'title': 'Technology Skills'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/tools_technology', 'title': 'Tools &amp; Technology'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/detailed_work_activities', 'title': 'Detailed Work Activities'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/job_zone', 'title': 'Job Zone'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/interests', 'title': 'Interests'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/related_occupations', 'title': 'Related Occupations'}\n",
      "{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.00/details/additional_information', 'title': 'Sources of Additional Information'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_resources = report['summary_resources']['resource']\n",
    "detail_resources = report['details_resources']['resource']\n",
    "\n",
    "[print(k) for k in summary_resources]\n",
    "print()\n",
    "[print(k) for k in detail_resources]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>href</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tasks</th>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology Skills</th>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tools &amp;amp; Technology</th>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Detailed Work Activities</th>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Zone</th>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interests</th>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Related Occupations</th>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sources of Additional Information</th>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                href\n",
       "title                                                                               \n",
       "Tasks                              https://services.onetcenter.org/ws/online/occu...\n",
       "Technology Skills                  https://services.onetcenter.org/ws/online/occu...\n",
       "Tools &amp; Technology             https://services.onetcenter.org/ws/online/occu...\n",
       "Detailed Work Activities           https://services.onetcenter.org/ws/online/occu...\n",
       "Job Zone                           https://services.onetcenter.org/ws/online/occu...\n",
       "Interests                          https://services.onetcenter.org/ws/online/occu...\n",
       "Related Occupations                https://services.onetcenter.org/ws/online/occu...\n",
       "Sources of Additional Information  https://services.onetcenter.org/ws/online/occu..."
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "resources_df = pd.DataFrame(detail_resources)\n",
    "resources_df = resources_df.set_index(\"title\")\n",
    "resources_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing/Controlling Report DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>bright_outlook</th>\n",
       "      <th>green</th>\n",
       "      <th>resource type</th>\n",
       "      <th>resource title</th>\n",
       "      <th>href</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Tasks</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Technology Skills</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Tools &amp;amp; Technology</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Detailed Work Activities</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Job Zone</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Interests</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Related Occupations</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Sources of Additional Information</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Tasks</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Technology Skills</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Tools &amp;amp; Technology</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Detailed Work Activities</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Job Zone</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Interests</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Related Occupations</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Sources of Additional Information</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>custom_resources</td>\n",
       "      <td>Work Activities Outline</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          code            title  \\\n",
       "0   15-2051.00  Data Scientists   \n",
       "1   15-2051.00  Data Scientists   \n",
       "2   15-2051.00  Data Scientists   \n",
       "3   15-2051.00  Data Scientists   \n",
       "4   15-2051.00  Data Scientists   \n",
       "5   15-2051.00  Data Scientists   \n",
       "6   15-2051.00  Data Scientists   \n",
       "7   15-2051.00  Data Scientists   \n",
       "8   15-2051.00  Data Scientists   \n",
       "9   15-2051.00  Data Scientists   \n",
       "10  15-2051.00  Data Scientists   \n",
       "11  15-2051.00  Data Scientists   \n",
       "12  15-2051.00  Data Scientists   \n",
       "13  15-2051.00  Data Scientists   \n",
       "14  15-2051.00  Data Scientists   \n",
       "15  15-2051.00  Data Scientists   \n",
       "16  15-2051.00  Data Scientists   \n",
       "\n",
       "                                          description  bright_outlook  green  \\\n",
       "0   Develop and implement a set of techniques or a...            True  False   \n",
       "1   Develop and implement a set of techniques or a...            True  False   \n",
       "2   Develop and implement a set of techniques or a...            True  False   \n",
       "3   Develop and implement a set of techniques or a...            True  False   \n",
       "4   Develop and implement a set of techniques or a...            True  False   \n",
       "5   Develop and implement a set of techniques or a...            True  False   \n",
       "6   Develop and implement a set of techniques or a...            True  False   \n",
       "7   Develop and implement a set of techniques or a...            True  False   \n",
       "8   Develop and implement a set of techniques or a...            True  False   \n",
       "9   Develop and implement a set of techniques or a...            True  False   \n",
       "10  Develop and implement a set of techniques or a...            True  False   \n",
       "11  Develop and implement a set of techniques or a...            True  False   \n",
       "12  Develop and implement a set of techniques or a...            True  False   \n",
       "13  Develop and implement a set of techniques or a...            True  False   \n",
       "14  Develop and implement a set of techniques or a...            True  False   \n",
       "15  Develop and implement a set of techniques or a...            True  False   \n",
       "16  Develop and implement a set of techniques or a...            True  False   \n",
       "\n",
       "        resource type                     resource title  \\\n",
       "0   summary_resources                              Tasks   \n",
       "1   summary_resources                  Technology Skills   \n",
       "2   summary_resources             Tools &amp; Technology   \n",
       "3   summary_resources           Detailed Work Activities   \n",
       "4   summary_resources                           Job Zone   \n",
       "5   summary_resources                          Interests   \n",
       "6   summary_resources                Related Occupations   \n",
       "7   summary_resources  Sources of Additional Information   \n",
       "8   details_resources                              Tasks   \n",
       "9   details_resources                  Technology Skills   \n",
       "10  details_resources             Tools &amp; Technology   \n",
       "11  details_resources           Detailed Work Activities   \n",
       "12  details_resources                           Job Zone   \n",
       "13  details_resources                          Interests   \n",
       "14  details_resources                Related Occupations   \n",
       "15  details_resources  Sources of Additional Information   \n",
       "16   custom_resources            Work Activities Outline   \n",
       "\n",
       "                                                 href  \n",
       "0   https://services.onetcenter.org/ws/online/occu...  \n",
       "1   https://services.onetcenter.org/ws/online/occu...  \n",
       "2   https://services.onetcenter.org/ws/online/occu...  \n",
       "3   https://services.onetcenter.org/ws/online/occu...  \n",
       "4   https://services.onetcenter.org/ws/online/occu...  \n",
       "5   https://services.onetcenter.org/ws/online/occu...  \n",
       "6   https://services.onetcenter.org/ws/online/occu...  \n",
       "7   https://services.onetcenter.org/ws/online/occu...  \n",
       "8   https://services.onetcenter.org/ws/online/occu...  \n",
       "9   https://services.onetcenter.org/ws/online/occu...  \n",
       "10  https://services.onetcenter.org/ws/online/occu...  \n",
       "11  https://services.onetcenter.org/ws/online/occu...  \n",
       "12  https://services.onetcenter.org/ws/online/occu...  \n",
       "13  https://services.onetcenter.org/ws/online/occu...  \n",
       "14  https://services.onetcenter.org/ws/online/occu...  \n",
       "15  https://services.onetcenter.org/ws/online/occu...  \n",
       "16  https://services.onetcenter.org/ws/online/occu...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with columns for resources\n",
    "report_prep = [('resource type','resource title','href')]\n",
    "\n",
    "for k in  resource_keys:\n",
    "    \n",
    "    resources = report[k]['resource']\n",
    "    \n",
    "    for r in resources:\n",
    "        report_prep.append([k, r['title'], r['href']])\n",
    "        \n",
    "    # temp_df = pd.DataFrame(report[k]['resource'])\n",
    "    # temp_df.insert(0,'resource type',k)\n",
    "    # report_prep.append(temp_df)#.fillna('')\n",
    "\n",
    "# report_df = pd.DataFrame(report_prep).fillna('')\n",
    "# report_df\n",
    "\n",
    "\n",
    "# resources_df = pd.concat(report_prep)\n",
    "# resources_df = resources_df.set_index(['resource type','title'])\n",
    "# resources_df\n",
    "\n",
    "# Make into a DataFrame\n",
    "resources_df = pd.DataFrame(report_prep[1:], columns=report_prep[0])\n",
    "resources_cols = resources_df.columns\n",
    "\n",
    "\n",
    "# Insert the meta keys as columns\n",
    "info_cols = []\n",
    "for k in meta_keys:\n",
    "    #report_prep.append([k, report[k]])\n",
    "    resources_df[k] = report[k]\n",
    "    info_cols.append(k)\n",
    "    \n",
    "    \n",
    "for k in report['tags']:\n",
    "    resources_df[k] = report['tags'][k]\n",
    "    info_cols.append(k)\n",
    "\n",
    "    \n",
    "    \n",
    "resources_df = resources_df[[*info_cols, *resources_df.drop(columns=info_cols).columns]]\n",
    "resources_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tags', 'also_see', 'updated', 'bright_outlook']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_keys =  [k for k in report.keys() if k not in resource_keys and k not in meta_keys]\n",
    "remaining_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags:\n",
      "    {'bright_outlook': True, 'green': False}\n",
      "also_see:\n",
      "    {'occupation': [{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.01/', 'code': '15-2051.01', 'title': 'Business Intelligence Analysts', 'tags': {'bright_outlook': True, 'green': False}}, {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.02/', 'code': '15-2051.02', 'title': 'Clinical Data Managers', 'tags': {'bright_outlook': True, 'green': False}}]}\n",
      "updated:\n",
      "    {'partial': True, 'year': 2024, 'resource_updated': [{'title': 'Abilities'}, {'title': 'Alternate Titles', 'source': 'Multiple sources', 'year': 2023}, {'title': 'Detailed Work Activities', 'source': 'Analyst', 'year': 2020}, {'title': 'Education'}, {'title': 'Interests', 'source': 'Machine Learning', 'year': 2023}, {'title': 'Job Zone', 'source': 'Analyst - Preliminary', 'year': 2021}, {'title': 'Knowledge'}, {'title': 'Sample of Reported Titles'}, {'title': 'Skills'}, {'title': 'Tasks', 'source': 'Analyst', 'year': 2020}, {'title': 'Technology Skills & Tools', 'source': 'Analyst', 'year': 2024}, {'title': 'Work Activities'}, {'title': 'Work Context'}, {'title': 'Work Needs'}, {'title': 'Work Styles'}, {'title': 'Work Values'}]}\n",
      "bright_outlook:\n",
      "    {'description': 'This occupation is expected to grow rapidly.', 'category': ['Grow Rapidly']}\n"
     ]
    }
   ],
   "source": [
    "for k in remaining_keys:\n",
    "    print(f\"{k}:\\n    {report[k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'occupation': [{'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.01/',\n",
       "   'code': '15-2051.01',\n",
       "   'title': 'Business Intelligence Analysts',\n",
       "   'tags': {'bright_outlook': True, 'green': False}},\n",
       "  {'href': 'https://services.onetcenter.org/ws/online/occupations/15-2051.02/',\n",
       "   'code': '15-2051.02',\n",
       "   'title': 'Clinical Data Managers',\n",
       "   'tags': {'bright_outlook': True, 'green': False}}]}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report['also_see']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rf/vw4r41jd7vd95x1w0dth7v9h0000gp/T/ipykernel_4702/4012382594.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  also_see_df[info_cols] = resources_df[info_cols].iloc[0]\n",
      "/var/folders/rf/vw4r41jd7vd95x1w0dth7v9h0000gp/T/ipykernel_4702/4012382594.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  also_see_df[info_cols] = resources_df[info_cols].iloc[0]\n",
      "/var/folders/rf/vw4r41jd7vd95x1w0dth7v9h0000gp/T/ipykernel_4702/4012382594.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  also_see_df[info_cols] = resources_df[info_cols].iloc[0]\n",
      "/var/folders/rf/vw4r41jd7vd95x1w0dth7v9h0000gp/T/ipykernel_4702/4012382594.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  also_see_df[info_cols] = resources_df[info_cols].iloc[0]\n",
      "/var/folders/rf/vw4r41jd7vd95x1w0dth7v9h0000gp/T/ipykernel_4702/4012382594.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  also_see_df[info_cols] = resources_df[info_cols].iloc[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>href</th>\n",
       "      <th>also_see_code</th>\n",
       "      <th>resource title</th>\n",
       "      <th>tags</th>\n",
       "      <th>resource type</th>\n",
       "      <th>code</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>bright_outlook</th>\n",
       "      <th>green</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>15-2051.01</td>\n",
       "      <td>Business Intelligence Analysts</td>\n",
       "      <td>{'bright_outlook': True, 'green': False}</td>\n",
       "      <td>also see</td>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>15-2051.02</td>\n",
       "      <td>Clinical Data Managers</td>\n",
       "      <td>{'bright_outlook': True, 'green': False}</td>\n",
       "      <td>also see</td>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                href also_see_code  \\\n",
       "0  https://services.onetcenter.org/ws/online/occu...    15-2051.01   \n",
       "1  https://services.onetcenter.org/ws/online/occu...    15-2051.02   \n",
       "\n",
       "                   resource title                                      tags  \\\n",
       "0  Business Intelligence Analysts  {'bright_outlook': True, 'green': False}   \n",
       "1          Clinical Data Managers  {'bright_outlook': True, 'green': False}   \n",
       "\n",
       "  resource type        code            title  \\\n",
       "0      also see  15-2051.00  Data Scientists   \n",
       "1      also see  15-2051.00  Data Scientists   \n",
       "\n",
       "                                         description  bright_outlook  green  \n",
       "0  Develop and implement a set of techniques or a...            True  False  \n",
       "1  Develop and implement a set of techniques or a...            True  False  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "also_see_df = pd.DataFrame(report['also_see']['occupation'])\n",
    "also_see_df = also_see_df.rename({'code':'also_see_code','title':'resource title'}, axis=1)\n",
    "also_see_df['resource type'] = 'also see'\n",
    "also_see_df[info_cols] = resources_df[info_cols].iloc[0]\n",
    "also_see_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resources_df[info_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>bright_outlook</th>\n",
       "      <th>green</th>\n",
       "      <th>resource type</th>\n",
       "      <th>resource title</th>\n",
       "      <th>href</th>\n",
       "      <th>also_see_code</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Tasks</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Technology Skills</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Tools &amp;amp; Technology</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Detailed Work Activities</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Job Zone</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Interests</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Related Occupations</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Sources of Additional Information</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Tasks</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Technology Skills</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Tools &amp;amp; Technology</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Detailed Work Activities</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Job Zone</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Interests</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Related Occupations</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Sources of Additional Information</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>custom_resources</td>\n",
       "      <td>Work Activities Outline</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>also see</td>\n",
       "      <td>Business Intelligence Analysts</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>15-2051.01</td>\n",
       "      <td>{'bright_outlook': True, 'green': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>also see</td>\n",
       "      <td>Clinical Data Managers</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "      <td>15-2051.02</td>\n",
       "      <td>{'bright_outlook': True, 'green': False}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          code            title  \\\n",
       "0   15-2051.00  Data Scientists   \n",
       "1   15-2051.00  Data Scientists   \n",
       "2   15-2051.00  Data Scientists   \n",
       "3   15-2051.00  Data Scientists   \n",
       "4   15-2051.00  Data Scientists   \n",
       "5   15-2051.00  Data Scientists   \n",
       "6   15-2051.00  Data Scientists   \n",
       "7   15-2051.00  Data Scientists   \n",
       "8   15-2051.00  Data Scientists   \n",
       "9   15-2051.00  Data Scientists   \n",
       "10  15-2051.00  Data Scientists   \n",
       "11  15-2051.00  Data Scientists   \n",
       "12  15-2051.00  Data Scientists   \n",
       "13  15-2051.00  Data Scientists   \n",
       "14  15-2051.00  Data Scientists   \n",
       "15  15-2051.00  Data Scientists   \n",
       "16  15-2051.00  Data Scientists   \n",
       "0   15-2051.00  Data Scientists   \n",
       "1   15-2051.00  Data Scientists   \n",
       "\n",
       "                                          description  bright_outlook  green  \\\n",
       "0   Develop and implement a set of techniques or a...            True  False   \n",
       "1   Develop and implement a set of techniques or a...            True  False   \n",
       "2   Develop and implement a set of techniques or a...            True  False   \n",
       "3   Develop and implement a set of techniques or a...            True  False   \n",
       "4   Develop and implement a set of techniques or a...            True  False   \n",
       "5   Develop and implement a set of techniques or a...            True  False   \n",
       "6   Develop and implement a set of techniques or a...            True  False   \n",
       "7   Develop and implement a set of techniques or a...            True  False   \n",
       "8   Develop and implement a set of techniques or a...            True  False   \n",
       "9   Develop and implement a set of techniques or a...            True  False   \n",
       "10  Develop and implement a set of techniques or a...            True  False   \n",
       "11  Develop and implement a set of techniques or a...            True  False   \n",
       "12  Develop and implement a set of techniques or a...            True  False   \n",
       "13  Develop and implement a set of techniques or a...            True  False   \n",
       "14  Develop and implement a set of techniques or a...            True  False   \n",
       "15  Develop and implement a set of techniques or a...            True  False   \n",
       "16  Develop and implement a set of techniques or a...            True  False   \n",
       "0   Develop and implement a set of techniques or a...            True  False   \n",
       "1   Develop and implement a set of techniques or a...            True  False   \n",
       "\n",
       "        resource type                     resource title  \\\n",
       "0   summary_resources                              Tasks   \n",
       "1   summary_resources                  Technology Skills   \n",
       "2   summary_resources             Tools &amp; Technology   \n",
       "3   summary_resources           Detailed Work Activities   \n",
       "4   summary_resources                           Job Zone   \n",
       "5   summary_resources                          Interests   \n",
       "6   summary_resources                Related Occupations   \n",
       "7   summary_resources  Sources of Additional Information   \n",
       "8   details_resources                              Tasks   \n",
       "9   details_resources                  Technology Skills   \n",
       "10  details_resources             Tools &amp; Technology   \n",
       "11  details_resources           Detailed Work Activities   \n",
       "12  details_resources                           Job Zone   \n",
       "13  details_resources                          Interests   \n",
       "14  details_resources                Related Occupations   \n",
       "15  details_resources  Sources of Additional Information   \n",
       "16   custom_resources            Work Activities Outline   \n",
       "0            also see     Business Intelligence Analysts   \n",
       "1            also see             Clinical Data Managers   \n",
       "\n",
       "                                                 href also_see_code  \\\n",
       "0   https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "1   https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "2   https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "3   https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "4   https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "5   https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "6   https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "7   https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "8   https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "9   https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "10  https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "11  https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "12  https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "13  https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "14  https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "15  https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "16  https://services.onetcenter.org/ws/online/occu...           NaN   \n",
       "0   https://services.onetcenter.org/ws/online/occu...    15-2051.01   \n",
       "1   https://services.onetcenter.org/ws/online/occu...    15-2051.02   \n",
       "\n",
       "                                        tags  \n",
       "0                                        NaN  \n",
       "1                                        NaN  \n",
       "2                                        NaN  \n",
       "3                                        NaN  \n",
       "4                                        NaN  \n",
       "5                                        NaN  \n",
       "6                                        NaN  \n",
       "7                                        NaN  \n",
       "8                                        NaN  \n",
       "9                                        NaN  \n",
       "10                                       NaN  \n",
       "11                                       NaN  \n",
       "12                                       NaN  \n",
       "13                                       NaN  \n",
       "14                                       NaN  \n",
       "15                                       NaN  \n",
       "16                                       NaN  \n",
       "0   {'bright_outlook': True, 'green': False}  \n",
       "1   {'bright_outlook': True, 'green': False}  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_df = pd.concat([resources_df, also_see_df],axis=0)\n",
    "# report_df[info_cols] = \n",
    "# report_df = pd.concat([resources_df[info_cols],report_df ],axis=1, ignore_index=True)\n",
    "report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOOKMARK: LUNCH.  (06/16/24)\n",
    "> note: was all of the report df stuff even necessary? Take a step back and ask yourself how you plan to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also_see_df['resource type'] = 'also_see'\n",
    "# also_see_df['resource title'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>bright_outlook</th>\n",
       "      <th>green</th>\n",
       "      <th>resource type</th>\n",
       "      <th>resource title</th>\n",
       "      <th>href</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Tasks</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Technology Skills</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Tools &amp;amp; Technology</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Detailed Work Activities</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Job Zone</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Interests</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Related Occupations</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>summary_resources</td>\n",
       "      <td>Sources of Additional Information</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Tasks</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Technology Skills</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Tools &amp;amp; Technology</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Detailed Work Activities</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Job Zone</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Interests</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Related Occupations</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>details_resources</td>\n",
       "      <td>Sources of Additional Information</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15-2051.00</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>Develop and implement a set of techniques or a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>custom_resources</td>\n",
       "      <td>Work Activities Outline</td>\n",
       "      <td>https://services.onetcenter.org/ws/online/occu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          code            title  \\\n",
       "0   15-2051.00  Data Scientists   \n",
       "1   15-2051.00  Data Scientists   \n",
       "2   15-2051.00  Data Scientists   \n",
       "3   15-2051.00  Data Scientists   \n",
       "4   15-2051.00  Data Scientists   \n",
       "5   15-2051.00  Data Scientists   \n",
       "6   15-2051.00  Data Scientists   \n",
       "7   15-2051.00  Data Scientists   \n",
       "8   15-2051.00  Data Scientists   \n",
       "9   15-2051.00  Data Scientists   \n",
       "10  15-2051.00  Data Scientists   \n",
       "11  15-2051.00  Data Scientists   \n",
       "12  15-2051.00  Data Scientists   \n",
       "13  15-2051.00  Data Scientists   \n",
       "14  15-2051.00  Data Scientists   \n",
       "15  15-2051.00  Data Scientists   \n",
       "16  15-2051.00  Data Scientists   \n",
       "\n",
       "                                          description  bright_outlook  green  \\\n",
       "0   Develop and implement a set of techniques or a...            True  False   \n",
       "1   Develop and implement a set of techniques or a...            True  False   \n",
       "2   Develop and implement a set of techniques or a...            True  False   \n",
       "3   Develop and implement a set of techniques or a...            True  False   \n",
       "4   Develop and implement a set of techniques or a...            True  False   \n",
       "5   Develop and implement a set of techniques or a...            True  False   \n",
       "6   Develop and implement a set of techniques or a...            True  False   \n",
       "7   Develop and implement a set of techniques or a...            True  False   \n",
       "8   Develop and implement a set of techniques or a...            True  False   \n",
       "9   Develop and implement a set of techniques or a...            True  False   \n",
       "10  Develop and implement a set of techniques or a...            True  False   \n",
       "11  Develop and implement a set of techniques or a...            True  False   \n",
       "12  Develop and implement a set of techniques or a...            True  False   \n",
       "13  Develop and implement a set of techniques or a...            True  False   \n",
       "14  Develop and implement a set of techniques or a...            True  False   \n",
       "15  Develop and implement a set of techniques or a...            True  False   \n",
       "16  Develop and implement a set of techniques or a...            True  False   \n",
       "\n",
       "        resource type                     resource title  \\\n",
       "0   summary_resources                              Tasks   \n",
       "1   summary_resources                  Technology Skills   \n",
       "2   summary_resources             Tools &amp; Technology   \n",
       "3   summary_resources           Detailed Work Activities   \n",
       "4   summary_resources                           Job Zone   \n",
       "5   summary_resources                          Interests   \n",
       "6   summary_resources                Related Occupations   \n",
       "7   summary_resources  Sources of Additional Information   \n",
       "8   details_resources                              Tasks   \n",
       "9   details_resources                  Technology Skills   \n",
       "10  details_resources             Tools &amp; Technology   \n",
       "11  details_resources           Detailed Work Activities   \n",
       "12  details_resources                           Job Zone   \n",
       "13  details_resources                          Interests   \n",
       "14  details_resources                Related Occupations   \n",
       "15  details_resources  Sources of Additional Information   \n",
       "16   custom_resources            Work Activities Outline   \n",
       "\n",
       "                                                 href  \n",
       "0   https://services.onetcenter.org/ws/online/occu...  \n",
       "1   https://services.onetcenter.org/ws/online/occu...  \n",
       "2   https://services.onetcenter.org/ws/online/occu...  \n",
       "3   https://services.onetcenter.org/ws/online/occu...  \n",
       "4   https://services.onetcenter.org/ws/online/occu...  \n",
       "5   https://services.onetcenter.org/ws/online/occu...  \n",
       "6   https://services.onetcenter.org/ws/online/occu...  \n",
       "7   https://services.onetcenter.org/ws/online/occu...  \n",
       "8   https://services.onetcenter.org/ws/online/occu...  \n",
       "9   https://services.onetcenter.org/ws/online/occu...  \n",
       "10  https://services.onetcenter.org/ws/online/occu...  \n",
       "11  https://services.onetcenter.org/ws/online/occu...  \n",
       "12  https://services.onetcenter.org/ws/online/occu...  \n",
       "13  https://services.onetcenter.org/ws/online/occu...  \n",
       "14  https://services.onetcenter.org/ws/online/occu...  \n",
       "15  https://services.onetcenter.org/ws/online/occu...  \n",
       "16  https://services.onetcenter.org/ws/online/occu...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resources_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the results with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_results = onet_ws.generic_request(full_path=resources_df.loc['Tasks','href'])\n",
    "# task_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(task_results))\n",
    "# task_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(results['task'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Here for LLM code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "import PyPDF2\n",
    "from io import StringIO\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.prompts import  MessagesPlaceholder, PromptTemplate, ChatPromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "# from langchain.memory import ConversationBufferWindowMemory\n",
    "import os, json\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "import streamlit as st\n",
    "ai_avatar  = \"\"\n",
    "user_avatar = \"\"\n",
    "model_type = 'gpt-4o'\n",
    "model_tone='friendly and encouraging'\n",
    "\n",
    "\n",
    "def get_system_prompt_str(with_context=True, with_onet=False):\n",
    "    \"\"\"Helper function for get_prompt_template. New v2.0\"\"\"\n",
    "    system_prompt = (\" You are a a specialized career coach for the {sector}, focused on delivering tailored, concise job application advice and practice. \" \n",
    "    \" You are proficient in resume analysis, cover letter guidance, and interview preparation, adapting to each user's unique requirements. \"\n",
    "    \" You maintain a professional, {model_tone} tone, ensuring advice is efficient, clear, and easily understandable, \"\n",
    "    \" with the goal of aiding their career progression. Ask the user for their resume and job listing if not provided and they are needed to asnwer .\")\n",
    "    context = \"\\nUse the following context, if provided, to help answer the questions:\\n\\nHere is my resume:\\n-------------\\n {resume}\\n\\n Here is the job listing:\\n-------------\\n{job}\\n\\n \"    \n",
    "\n",
    "    if with_context:        \n",
    "        if with_onet:\n",
    "            context += \"\\nHere is the Onet occupation report:\\n-------------\\n{onet_report}\\n\\n\"\n",
    "        return system_prompt + context\n",
    "    else:\n",
    "        return system_prompt\n",
    "\n",
    "\n",
    "def get_llm_no_memory(model_type='gpt-4o', temperature=0.1, #\n",
    "            system_prompt_template_func= get_system_prompt_str,#verbose=False,\n",
    "            system_prompt_template_func_kws = dict(with_context=True, with_onet=False),\n",
    "            model_tone='friendly and encouraging',\n",
    "             verbose=True, sector=\"data science and analytics\",\n",
    "             partial_prompt_kws= {}):#, resume='', job=''):\n",
    "    \"\"\"Version 2.0\"\"\"\n",
    "    # ## get prompt string\n",
    "    system_prompt = system_prompt_template_func(**system_prompt_template_func_kws)\n",
    "    \n",
    "    # final_promp_str = system_prompt + \"\"\"\n",
    "    #     Current conversation:\n",
    "    #     {history}\n",
    "    #     Human: {input}\n",
    "    #     AI:\"\"\"\n",
    "        \n",
    "    # final_prompt_template = ChatPromptTemplate.from_template(final_promp_str)\n",
    "    final_prompt_template = ChatPromptTemplate.from_messages([\n",
    "        ('system',system_prompt),\n",
    "         MessagesPlaceholder(variable_name='history', optional=True),\n",
    "         ('human', '{input}'),\n",
    "    ])\n",
    "    \n",
    "    final_prompt_template = final_prompt_template.partial(sector=sector,\n",
    "                                                          model_tone=model_tone,\n",
    "                                                          **partial_prompt_kws)#, resume=resume, job=job)\n",
    "\n",
    "    try:\n",
    "        api_key = st.session_state.OPENAI_API_KEY\n",
    "    except:\n",
    "        api_key = os.getenv('OPENAI_API_KEY')\n",
    "    llm = ChatOpenAI(temperature=temperature, model=model_type, api_key=api_key)\n",
    "    \n",
    "    llm_chain = final_prompt_template | llm | StrOutputParser(output_key=\"response\")\n",
    "    # llm_chain = ConversationChain(prompt=final_prompt_template, \n",
    "    #                               llm=llm, \n",
    "    #                               memory=None, \n",
    "    #                               verbose=verbose, \n",
    "    #                             #   input_key=\"input\",\n",
    "    #                               output_key=\"response\")#,#callbacks=callbacks)\n",
    "    \n",
    "    return llm_chain\n",
    "            \n",
    "            \n",
    "\n",
    "def stream_response(llm_no_mem, input, resume='', job='', \n",
    "                    model_tone='friendly and encouraging',\n",
    "                    model_type='gpt-4o',\n",
    "                    history=[],\n",
    "                    system_prompt_template_func= get_system_prompt_str,\n",
    "                    system_prompt_template_func_kws= dict(with_context=True, with_onet=False),\n",
    "                    partial_prompt_kws = {},\n",
    "                    prompt_kws={}):\n",
    "    \"\"\"Stream response from ChatGPT. Version 2.0.\"\"\"\n",
    "    if llm_no_mem is None:\n",
    "        llm_no_mem = get_llm_no_memory(model_type=model_type,\n",
    "                                       model_tone=model_tone,\n",
    "                                       sector=\"data science and analytics\", \n",
    "                                       partial_prompt_kws=partial_prompt_kws,\n",
    "                                        system_prompt_template_func=system_prompt_template_func,\n",
    "                                        system_prompt_template_func_kws=system_prompt_template_func_kws,\n",
    "                                       )\n",
    "\n",
    "    ## Add input to history\n",
    "    history.append(HumanMessage(content=input))\n",
    "\n",
    "    return llm_no_mem.stream({'input':input,\n",
    "                   'resume':resume,\n",
    "                   'job':job,\n",
    "                   'history':history,\n",
    "                   **prompt_kws})\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `stream_response` updated with flexible args for partial prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_fpath = \"../data/James Irving Resume 2024.pdf\"\n",
    "job_fpath='../data/bah-473.pdf'\n",
    "\n",
    "resume_text = af.read_pdf(resume_fpath)\n",
    "job_text = af.read_pdf(job_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NameError(\"name 'results_report' is not defined\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    chat_history = []\n",
    "    user_text = \"What can you tell me about this profession from the ONET report?\"\n",
    "\n",
    "    chat_history.append(HumanMessage(content=user_text))\n",
    "\n",
    "    response= \"\"\n",
    "    for chunk in  stream_response(llm_no_mem=None, input=user_text, \n",
    "                            resume=resume_text, job=job_text, model_tone=model_tone,\n",
    "                            partial_prompt_kws=dict(report=results_report['output']),\n",
    "                            history=chat_history):\n",
    "        response+=chunk\n",
    "    print(response)\n",
    "        # response += s\n",
    "        # print(s)\n",
    "except Exception as e:\n",
    "    display(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_report['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Resume Creation/Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pypi.org/project/python-docx/\n",
    "# !pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robert Half\n",
      "Senior Data Scientist\n",
      "$115K/yr - $173K/yrMid-Senior level\n",
      "10,001+ employees  Staffing and Recruiting\n",
      "2 company alumni work here3 school alumni work here\n",
      "3 of 3 skills match your profile - you may be a good fit\n",
      "Apply SavedCalifornia, United States4 hours ago29 applicants\n",
      "RemoteFull-time\n",
      "Am I a good fit for this job? How can I best position myself fo\n",
      "Meet the hiring team\n",
      "Kelli Griffin3rd\n",
      "Lead Talent Acquisition Partner\n",
      "Job posterMessage\n",
      "About the job\n",
      "Ready to revolutionize the future of data-driven decision-making? Join our\n",
      "pioneering Data Science team as we embark on an exciting journey to unlock\n",
      "insights, drive innovation, and shape the landscape of our organization's success.\n",
      "If you're passionate about leveraging cutting-edge generative AI technologies\n",
      "and transforming raw data into actionable insight, we want you on our team!\"\n",
      "The Senior Data Scientist will be responsible for leading advanced data analytics\n",
      "projects, leveraging Azure and Microsoft data services. Th\n"
     ]
    }
   ],
   "source": [
    "job_fpath_senior_rh = '../data/Senior Data Scientist _ Robert Half _ LinkedIn copy.pdf'\n",
    "job_text_senior_rh = af.read_pdf(job_fpath_senior_rh)\n",
    "print(job_text_senior_rh[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LONG MASTER RESUME]  James M. Irving, Ph.D. 8222 Spadderdock Way, Laurel, MD, 20724 | (518) 322-6750 | james.irving.phd@gmail.com |  LinkedIn: james-irving-phd | GitHub: https://github.com/jirvingphd  SUMMARY V1 Innovative and enterprising data scientist with extensive experience in applying advanced data science techniques to real-world problems. Known for excellent problem-solving skills and the ability to rapidly master and implement new technologies. Committed to leveraging data to drive innovation and support data-driven decision-making. SUMMARY V2 Neuroscientist-turned-data scientist with an insatiable curiosity and a proven track record in mastering cutting-edge technologies. Exceptional communication and interpersonal skills paired with a robust history of problem-solving and critical thinking. Proven ability to self-teach complex concepts and technologies, including in vivo electrophysiology recordings and analysis. Successfully trained generations of collaborators, technicia\n"
     ]
    }
   ],
   "source": [
    "long_resume_fpath = \"../data/James Irving LONG MASTER Resume 2024.pdf\"\n",
    "long_resume = af.read_pdf(long_resume_fpath)\n",
    "print(long_resume[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input', 'job', 'resume'], input_types={'history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'history': [], 'sector': 'data science and analytics', 'model_tone': 'friendly and encouraging'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['job', 'model_tone', 'resume', 'sector'], template=\" You are a a specialized career coach for the {sector}, focused on delivering tailored, concise job application advice and practice.  You are proficient in resume analysis, cover letter guidance, and interview preparation, adapting to each user's unique requirements.  You maintain a professional, {model_tone} tone, ensuring advice is efficient, clear, and easily understandable,  with the goal of aiding their career progression. Ask the user for their resume and job listing if not provided and they are needed to asnwer .\\nUse the following context, if provided, to help answer the questions:\\n\\nHere is my resume:\\n-------------\\n {resume}\\n\\n Here is the job listing:\\n-------------\\n{job}\\n\\n \")), MessagesPlaceholder(variable_name='history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x175abb250>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x175b576d0>, model_name='gpt-4o', temperature=0.1, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = get_llm_no_memory(model_type='gpt-4o', temperature=0.1)\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Help me take my longer cv (that has more bullet points per item than I want to keep)  to craft a tailor-made 2-page resume for the job listing by cherry-picking the most relevant/best items.  Do not make anything up or mention skills or accomplishments that I do not have. '"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_prompt = ( \" Help me take my longer cv (that has more bullet points per item than I want to keep) \"\n",
    "                  \" to craft a tailor-made 2-page resume for the job listing by cherry-picking the most relevant/best items. \" \n",
    "                  \" Do not make anything up or mention skills or accomplishments that I do not have. \"\n",
    "                  )\n",
    "resume_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using OpenAI Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve a more controlled and structured response from the LLM, you can define a detailed prompt and use LangChain to orchestrate the interactions. Heres how you can do it step by step:\n",
    "\n",
    "### Step-by-Step Guide\n",
    "\n",
    "#### Step 1: Set Up the Environment\n",
    "\n",
    "Ensure you have the necessary packages installed:\n",
    "\n",
    "```bash\n",
    "pip install langchain openai\n",
    "```\n",
    "\n",
    "#### Step 2: Initialize the OpenAI API\n",
    "\n",
    "Set up your OpenAI API key:\n",
    "\n",
    "```python\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# Set up your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'your-openai-api-key'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Step 3: Define Functions for Structured Response\n",
    "\n",
    "Create functions to handle each part of the structured response you need.\n",
    "\n",
    "**Example Functions**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def get_llm(model_type='gpt-4o', temperature=0.1, #\n",
    "#             prompt_template = None,\n",
    "#             # system_prompt_template_func= get_system_prompt_str,#verbose=False,\n",
    "#             # system_prompt_template_func_kws = dict(with_context=True, with_onet=False),\n",
    "#             # model_tone='friendly and encouraging',\n",
    "#              verbose=True, \n",
    "#             #  sector=\"data science and analytics\",\n",
    "#             #  partial_prompt_kws= {}):#, resume='', job=''\n",
    "#             ):\n",
    "#     \"\"\"Version 2.0\"\"\"\n",
    "#     # ## get prompt string\n",
    "#     if prompt_template is None:\n",
    "        \n",
    "#     system_prompt = system_prompt_template_func(**system_prompt_template_func_kws)\n",
    "    \n",
    "#     # final_promp_str = system_prompt + \"\"\"\n",
    "#     #     Current conversation:\n",
    "#     #     {history}\n",
    "#     #     Human: {input}\n",
    "#     #     AI:\"\"\"\n",
    "        \n",
    "#     # final_prompt_template = ChatPromptTemplate.from_template(final_promp_str)\n",
    "#     final_prompt_template = ChatPromptTemplate.from_messages([\n",
    "#         ('system',system_prompt),\n",
    "#          MessagesPlaceholder(variable_name='history', optional=True),\n",
    "#          ('human', '{input}'),\n",
    "#     ])\n",
    "    \n",
    "#     final_prompt_template = final_prompt_template.partial(sector=sector,\n",
    "#                                                           model_tone=model_tone,\n",
    "#                                                           **partial_prompt_kws)#, resume=resume, job=job)\n",
    "\n",
    "#     try:\n",
    "#         api_key = st.session_state.OPENAI_API_KEY\n",
    "#     except:\n",
    "#         api_key = os.getenv('OPENAI_API_KEY')\n",
    "#     llm = ChatOpenAI(temperature=temperature, model=model_type, api_key=api_key)\n",
    "    \n",
    "#     llm_chain = final_prompt_template | llm | StrOutputParser(output_key=\"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_resume_vs_job(resume: str, job_listing: str, temperature=0.1, model_type='gpt-4o') -> str:\n",
    "    prompt = f\"\"\"\n",
    "    I need you to rate this resume against the following job listing out of 5 stars. Please provide a rating and 1-2 sentence justification.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "    \"\"\"\n",
    "    #     Response format:\n",
    "    # {{\n",
    "    #     \"rating\": <number>,\n",
    "    #     \"justification\": \"<string>\"\n",
    "    # }}\n",
    "\n",
    "    final_prompt_template = PromptTemplate.from_template(prompt)\n",
    "    # final_prompt_template = final_prompt_template.partial(resume=resume, job=job_listing)\n",
    "        \n",
    "    # final_prompt_template = final_prompt_template.partial(sector=sector,\n",
    "    #                                                       model_tone=model_tone,\n",
    "    #                                                       **partial_prompt_kws)#, resume=resume, job=job)\n",
    "    try:\n",
    "        api_key = st.session_state.OPENAI_API_KEY\n",
    "    except:\n",
    "        api_key = os.getenv('OPENAI_API_KEY')\n",
    "    llm = ChatOpenAI(temperature=temperature, model=model_type, api_key=api_key)\n",
    "    \n",
    "    llm_chain = final_prompt_template | llm | StrOutputParser(output_key=\"response\")\n",
    "    response = llm_chain.invoke(dict(resume=resume, job=job_listing))\n",
    "    return response\n",
    "    # response = openai.Completion.create(\n",
    "    #     engine=\"gpt-4\",\n",
    "    #     prompt=prompt,\n",
    "    #     max_tokens=150,\n",
    "    #     n=1,\n",
    "    #     stop=None,\n",
    "    #     temperature=0.7,\n",
    "    # )\n",
    "    # return response.choices[0].text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 06/23/24 Notes: Can't get job_listing passed to tools\n",
    "- [ ] Try swapping StrOutputParser for Json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Robert Half\\nSenior Data Scientist\\n$115K/yr - $173K/yrMid-Senior level\\n10,001+ employees  Staffing and Recruiting\\n2 company alumni work here3 school alumni work here\\n3 of 3 skills match your profile - you may be a good fit\\nApply SavedCalifornia, United States4 hours ago29 applicants\\nRemoteFull-time\\nAm I a good fit for this job? How can I best position myself fo\\nMeet the hiring team\\nKelli Griffin3rd\\nLead Talent Acquisition Partner\\nJob posterMessage\\nAbout the job\\nReady to revolutionize the future of data-driven decision-making? Join our\\npioneering Data Science team as we embark on an exciting journey to unlock\\ninsights, drive innovation, and shape the landscape of our organization\\'s success.\\nIf you\\'re passionate about leveraging cutting-edge generative AI technologies\\nand transforming raw data into actionable insight, we want you on our team!\"\\nThe Senior Data Scientist will be responsible for leading advanced data analytics\\nprojects, leveraging Azure and Microsoft data services. This role demands a deep\\nunderstanding of data science methodologies, machine learning algorithms, and\\nbig data technologies. The incumbent will work closely with cross-functional\\nteams to understand business needs and formulate and execute data science\\nsolutions that drive significant business impact.\\nKey Responsibilities:\\nData Analytics and Modeling:\\nDevelop and implement advanced predictive models and statistical\\nanalysis using a variety of machine learning algorithms.\\nSuggest algorithms or models appropriate for specific use cases and\\napplications.\\nAnalyze and extract relevant information from large amounts of historical\\nbusiness data to help automate and optimize key processes with business\\nteams.\\nApply technical solutions to business problems and questions using large\\nscale data analytics and machine learning; create highly calibrated\\nsolutions for business problems.\\nWork closely with software engineering teams to drive real-time model\\nexperiments, implementations and new feature creations.\\nContinuously evaluate and refine models based on performance metrics.\\nUtilize cloud technologies such as Azure Machine Learning, Azure\\nDatabricks, and other Microsoft data services for data processing, modelHomeMy NetworkJobsMessagingNotificationsMe\\n For BusinessLear\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 1/7\\nSee lessbuilding, and deployment.\\nLarge Language Model Fine-tuning:\\nEnhance and evolve the performance of large language models by\\nrefining their capabilities through targeted fine-tuning.\\nSteer both the research trajectory and the practical engineering efforts of\\nthe team.\\nFormulate and enact algorithms for model enhancement, tweak critical\\nhyperparameters, and heighten overall model efficiency.\\nGuarantee the integrity and relevance of datasets by conducting thorough\\npreprocessing and data analysis within the fine-tuning workflow.\\nConduct assessments on fine-tuned models, making necessary\\nmodifications to boost their effectiveness.\\nFoster a cooperative environment within the team, providing guidance to\\npeers to ensure a smooth fine-tuning operation that yields superior\\nresults.\\nStay at the forefront of advancements in large language model\\ntechnologies and applications, perpetually refining technical expertise in\\nmodel fine-tuning.\\nData Management and Strategy:\\nCollaborate with IT and data engineering teams in an enterprise setting to\\nintegrate data science solutions into the broader tech stack and data\\nstrategy.\\nBusiness Collaboration and Insights:\\nWork closely with business stakeholders to identify opportunities for\\nleveraging company data to drive business solutions.\\nTranslate complex data-driven findings into actionable business insights\\nand communicate these effectively to non-technical stakeholders.\\nResearch and Development:\\nStay abreast of industry trends and advancements in data science and\\nAzure technologies.\\nConduct research to explore new methodologies and technologies that\\ncan enhance the organization\\'s data analytics capabilities.\\nPreferred Qualifications and Skills:\\nBachelor\\'s degree in Statistics, Computer Science, Mathematics or\\nequivalent required; Master\\'s or PhD highly preferred\\n5 years of professional experience in data science, with a record in\\ndesigning and implementing large-scale data science projects.\\n5 years of industry experience in predictive modeling and large data\\nanalysis\\nKnowledge of open-source large language models and experience with\\nevaluating and recommending appropriate models for specific use cases.\\n3+ years of experience in using big data platforms and technologies such\\nas Hadoop, Azure data lake, Azure Cosmos DB, Pig, Hive, HBase, etc.\\n3+ years of hands-on experience in statistical modeling, data mining,\\nlarge data analysis and predictive modeling; text mining a major plus\\n3+ years of experience in regression, classification and clustering\\nmethods such as GLM, LR, SVM, LVQ, SOM, Neural Networks\\nExperience with two or more of the following: Python, PERL, Matlab or\\nScala\\nExpertise in various machine learning frameworks and libraries (e.g.,\\nTensorFlow, PyTorch, Scikit-learn).\\nExcellent analytical, problem-solving, and communication skills.\\nExcellent communication skills, with a proven ability to translate technical\\nfindings into business recommendations and strategies.\\nCertifications in Azure data services or advanced analytics preferred\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 2/7\\nSet alert for similar jobs\\nData Scientist, California, United StatesSet alert\\nEmployer-provided\\nPay range in California, United States\\nExact compensation may vary based on skills, experience, and location.\\nBase salary\\n$115,000/yr - $173,000/yr\\nFeatured benefits\\nMedical insurance\\nVision insurance\\nDental insurance\\n401(k)\\nTuition assistance\\nQualifications\\n3 of 3 skills match your profile - you may be a good fit\\nSkills added by the job poster\\nBig Data  Large Language Models (LLM)  Natural Language Processing (NLP)\\nAdditional skills among applicants\\nData Analysis  Data Science  Data Visualization  Machine Learning  Microsoft\\nPower BI  Python (Programming Language)  R (Programming Language)  SQL \\nShow qualification details\\nPut your best foot forward with your application\\nHire a resume writer\\nGet a resume review\\nSee how you compare to other applicants\\nApplicants for this job\\n29Applicants\\n29Applicants in the past day\\nApplicant seniority level\\n15 Entry level applicants\\n10 Senior level applicants\\n1 Director level applicant Youve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 3/7\\nApplicant education level\\n19%have a Doctor of Philosophy (Similar to you)\\n59%have a Master\\'s Degree\\n15%have a Bachelor\\'s Degree\\n7%have other degrees\\nApplicants are in these locations\\n1-5 applicants\\nNew York City Metropolitan\\nArea\\n1-5 applicants\\nGreater Pittsburgh Region\\n1-5 applicants\\nDallas-Fort Worth Metroplex\\nSee if Robert Half is hiring people like you\\nThe latest hiring trends.\\n29,307\\nTotal employees3%\\nCompany-wide\\n2 year growth2%\\nEngineering\\n2 year growth\\nMedian employee tenure 6 yearsMay 2022 Nov 2022 May 2023 Nov 2023 May 202410,00020,00030,00040,000\\nRobert Half hires candidates from some of these companies and schools\\nRobert Half hired 2 people\\nfrom Coding Dojo.See all\\nRobert Half hired 3 people from\\nFlatiron School.See all\\nEngineering hires at Robert Half came\\nfrom these companies and more.Engineering hires at Robert Half came\\nfrom these schools and more.\\nReset map\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 4/7\\nMore jobsShow more Premium insightsSee more companies See more schools\\nAbout the company\\nRobert Half\\n3,147,224 followersFollow\\nStaffing and Recruiting10,001+ employees29,320 on LinkedIn\\nTrending employee content PreviousNext\\nShow more\\nRobert Half, the worlds first and largest specialized talent solutions firm,\\nconnects opportunities at great companies with highly skilled job seekers. We\\noffer contract, temporary and permanent placement solutions for roles in financshow more\\nInterested in working with us in the future?\\nPrivately share your profile with our recruiters  youll be noted as\\nexpressing interest for up to a year.Learn more\\nIm interested\\nLead Data Scientist\\nCigniti Technologies\\nUnited States (Remote)\\nActively recruiting\\n4 weeks agoEasy ApplySenior Data Scientist\\nDTN\\nUnited States (Remote)\\nActively recruiting\\n2 weeks ago\\nData Scientist\\nQuantum World Technologies\\nUnited States (Remote)\\nActively recruiting\\nSr. Data Scientist\\nAKASA\\nUnited States (Remote)\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 5/7\\nSee more jobs like this10 minutes agoEasy Apply 2 weeks ago\\nSenior Data Scientist\\nPhreesia\\nUnited States (Remote)\\nActively recruiting\\n3 weeks agoSr. Data Scientist\\nAppFolio\\nUnited States (Remote)\\nActively recruiting\\n1 week ago\\nSenior Data Scientist,\\nProduct\\nUniswap Labs\\nNew York, NY (Remote)\\nActively recruiting\\n1 week agoSenior Data Scientist\\nAustin Fraser\\nUnited States (Remote)\\nActively recruiting\\n6 days agoEasy Apply\\nSenior Data Scientist\\nWebflow\\nUnited States (Remote)\\n1 company alum works here\\n2 days agoSenior Data Scientist\\nXOi\\nUnited States (Remote)\\n2 weeks ago\\nLead Data Scientist\\nLittle Place Labs\\nUnited States (Remote)\\n1 month agoEasy ApplyStaff Data Scientist\\nDemandbase\\nUnited States (Remote)\\n3 school alumni work here\\n3 weeks ago\\nLearn skills to get a new job with these courses\\n135,378 viewers\\nThe New Rules of Work\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 6/7\\nAbout Accessibility Talent Solutions\\nCommunity Guidelines Careers Marketing Solutions\\nAd Choices Advertising\\nSales Solutions Mobile Small Business\\nSafety CenterQuestions?\\nVisit our Help Center.\\nManage your account and privacy\\nGo to your Settings.\\nRecommendation transparency\\nLearn more about Recommended Content.Select Language\\nLinkedIn Corporation  2024282,784 viewers\\nShow more on LinkedIn Learning\\nDeveloping Your Professional Image in a New Job\\nLooking for talent?Post a job\\nPrivacy & Terms\\nEnglish (English)\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 7/7\\n'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_text_senior_rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Rating: 4.5 out of 5 stars\n",
      "\n",
      "### Justification:\n",
      "James M. Irving, Ph.D., has a robust and comprehensive resume that aligns well with the job listing for a Senior Data Scientist at Robert Half. His extensive experience in data science, machine learning, and NLP, coupled with his strong academic background, makes him a strong candidate for this role. \n",
      "\n",
      "**Strengths:**\n",
      "1. **Relevant Experience:** James has significant experience in data science, including predictive modeling, statistical analysis, and machine learning, which are key responsibilities for the role.\n",
      "2. **Technical Skills:** He possesses expertise in Python, TensorFlow, Keras, and other relevant technologies, which aligns well with the job requirements.\n",
      "3. **Project Management:** His experience in developing and delivering data science curricula and managing large-scale projects demonstrates his ability to lead and execute complex tasks.\n",
      "4. **Communication Skills:** His ability to translate technical findings into actionable business insights and his experience in teaching and mentoring highlight his strong communication skills.\n",
      "\n",
      "**Areas for Improvement:**\n",
      "1. **Specific Technologies:** While James has a broad range of technical skills, the job listing specifically mentions Azure Machine Learning, Azure Databricks, and other Microsoft data services. Explicit experience with these technologies is not highlighted in his resume.\n",
      "2. **Big Data Platforms:** The job listing requires experience with big data platforms such as Hadoop, Azure data lake, and others. While James has extensive data science experience, explicit mention of these platforms would strengthen his application.\n",
      "\n",
      "Overall, James's resume is highly impressive and closely matches the job requirements, with minor gaps in specific technologies and platforms mentioned in the job listing.\n"
     ]
    }
   ],
   "source": [
    "compare_response = rate_resume_vs_job(long_resume, job_text_senior_rh)\n",
    "print(compare_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def list_matching_qualifications(resume: str, job_listing: str, \n",
    "                                 temperature=0.1, model_type='gpt-4o',\n",
    "                                 ) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Identify and list the most important matching qualifications between the following resume and job listing. \n",
    "    Mention the qualification first,what the job listing desires, then how the resume meets it. Be concise and to the point. Do not mention the gaps or missing qualifications.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "    \"\"\"\n",
    "    final_prompt_template = PromptTemplate.from_template(prompt)\n",
    "        \n",
    "    # final_prompt_template = final_prompt_template.partial(sector=sector,\n",
    "    #                                                       model_tone=model_tone,\n",
    "    #                                                       **partial_prompt_kws)#, resume=resume, job=job)\n",
    "    try:\n",
    "        api_key = st.session_state.OPENAI_API_KEY\n",
    "    except:\n",
    "        api_key = os.getenv('OPENAI_API_KEY')\n",
    "    llm = ChatOpenAI(temperature=temperature, model=model_type, api_key=api_key,\n",
    "                    #  max_tokens=max_tokens\n",
    "                     )\n",
    "    \n",
    "    llm_chain = final_prompt_template | llm | StrOutputParser(output_key=\"response\")\n",
    "    response = llm_chain.invoke(dict(resume=resume, job=job_listing))\n",
    "    return response\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Matching Qualifications\n",
      "\n",
      "1. **Advanced Data Analytics and Predictive Modeling**\n",
      "   - **Job Listing:** Develop and implement advanced predictive models and statistical analysis using a variety of machine learning algorithms.\n",
      "   - **Resume:** Extensive experience in data analysis, statistical modeling, machine learning, and predictive modeling, including projects like \"Recidivism Risk Assessment\" and \"Forecasting Stock Market Fluctuations with Trumps Tweets.\"\n",
      "\n",
      "2. **Machine Learning Algorithms**\n",
      "   - **Job Listing:** Expertise in various machine learning frameworks and libraries (e.g., TensorFlow, PyTorch, Scikit-learn).\n",
      "   - **Resume:** Proficient in machine learning frameworks and libraries such as TensorFlow, Keras, and scikit-learn, demonstrated through multiple data science projects.\n",
      "\n",
      "3. **Large Language Models (LLM) and Natural Language Processing (NLP)**\n",
      "   - **Job Listing:** Knowledge of open-source large language models and experience with evaluating and recommending appropriate models for specific use cases.\n",
      "   - **Resume:** Experience with NLP and LLMs, including projects like \"NLP Analysis of Amazon Reviews + AI Recommendations\" and \"How to Spot a Troll.\"\n",
      "\n",
      "4. **Big Data Technologies**\n",
      "   - **Job Listing:** Experience in using big data platforms and technologies such as Hadoop, Azure data lake, Azure Cosmos DB.\n",
      "   - **Resume:** Experience with big data analysis and platforms, including managing over 20 TBs of data storage systems and using cloud technologies like AWS RDS for data storage and retrieval.\n",
      "\n",
      "5. **Programming Skills**\n",
      "   - **Job Listing:** Experience with Python, Matlab, and other programming languages.\n",
      "   - **Resume:** Proficient in Python, MATLAB, and other programming languages, with extensive experience in developing custom analysis scripts and data science projects.\n",
      "\n",
      "6. **Communication Skills**\n",
      "   - **Job Listing:** Excellent communication skills, with a proven ability to translate technical findings into business recommendations and strategies.\n",
      "   - **Resume:** Demonstrated strong communication skills through teaching roles, mentoring, and presenting research findings to mixed audiences.\n",
      "\n",
      "7. **Educational Background**\n",
      "   - **Job Listing:** Bachelor's degree in Statistics, Computer Science, Mathematics or equivalent required; Master's or PhD highly preferred.\n",
      "   - **Resume:** Holds a Ph.D. in Neuroscience, a Master's in Neuroscience, and a Certificate of Completion in Data Science.\n",
      "\n",
      "8. **Experience in Data Science Projects**\n",
      "   - **Job Listing:** 5 years of professional experience in data science, with a record in designing and implementing large-scale data science projects.\n",
      "   - **Resume:** Over 5 years of experience in data science roles, including developing and delivering data science curricula and leading data science projects.\n",
      "\n",
      "9. **Cloud Technologies**\n",
      "   - **Job Listing:** Utilize cloud technologies such as Azure Machine Learning, Azure Databricks, and other Microsoft data services for data processing, model building, and deployment.\n",
      "   - **Resume:** Experience with cloud technologies, including AWS RDS for data storage and retrieval, and integrating cutting-edge technologies into educational content.\n",
      "\n",
      "10. **Research and Development**\n",
      "    - **Job Listing:** Conduct research to explore new methodologies and technologies that can enhance the organization's data analytics capabilities.\n",
      "    - **Resume:** Extensive research experience in neuroscience and data science, with a history of developing new methodologies and technologies.\n"
     ]
    }
   ],
   "source": [
    "response_matching = list_matching_qualifications(long_resume, job_text_senior_rh)\n",
    "print(response_matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Azure and Microsoft Data Services Expertise**\n",
      "   - **Job Listing:** Requires experience with Azure Machine Learning, Azure Databricks, and other Microsoft data services.\n",
      "   - **Resume:** No mention of experience with Azure or Microsoft data services.\n",
      "\n",
      "2. **Big Data Platforms and Technologies**\n",
      "   - **Job Listing:** Requires 3+ years of experience with big data platforms such as Hadoop, Azure Data Lake, Azure Cosmos DB, Pig, Hive, HBase.\n",
      "   - **Resume:** No mention of experience with these specific big data platforms and technologies.\n",
      "\n",
      "3. **Large Language Model Fine-tuning**\n",
      "   - **Job Listing:** Requires experience in fine-tuning large language models and staying updated with advancements in LLM technologies.\n",
      "   - **Resume:** No specific mention of fine-tuning large language models, although there is experience with NLP and AI/LLM implementation.\n",
      "\n",
      "4. **Statistical Modeling and Predictive Modeling**\n",
      "   - **Job Listing:** Requires 3+ years of hands-on experience in statistical modeling, data mining, large data analysis, and predictive modeling.\n",
      "   - **Resume:** While there is experience in machine learning and data analysis, there is no explicit mention of 3+ years of hands-on experience in statistical modeling and predictive modeling.\n",
      "\n",
      "5. **Experience with Specific Machine Learning Methods**\n",
      "   - **Job Listing:** Requires experience with regression, classification, and clustering methods such as GLM, LR, SVM, LVQ, SOM, Neural Networks.\n",
      "   - **Resume:** General experience with machine learning is mentioned, but specific experience with GLM, LR, SVM, LVQ, SOM is not detailed.\n",
      "\n",
      "6. **Certifications in Azure Data Services or Advanced Analytics**\n",
      "   - **Job Listing:** Preferred certifications in Azure data services or advanced analytics.\n",
      "   - **Resume:** No mention of certifications in Azure data services or advanced analytics.\n",
      "\n",
      "7. **Business Collaboration and Insights**\n",
      "   - **Job Listing:** Requires translating complex data-driven findings into actionable business insights and communicating these effectively to non-technical stakeholders.\n",
      "   - **Resume:** While there is mention of communication skills and translating technical findings, there is no specific mention of experience in translating data-driven findings into actionable business insights for non-technical stakeholders.\n",
      "\n",
      "8. **Research and Development in Data Science and Azure Technologies**\n",
      "   - **Job Listing:** Requires staying abreast of industry trends and advancements in data science and Azure technologies.\n",
      "   - **Resume:** No specific mention of staying updated with advancements in Azure technologies, although there is a general mention of staying updated with industry trends.\n",
      "\n",
      "9. **Experience with Specific Programming Languages**\n",
      "   - **Job Listing:** Requires experience with Python, PERL, Matlab, or Scala.\n",
      "   - **Resume:** Experience with Python and Matlab is mentioned, but no mention of PERL or Scala.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def list_missing_qualifications(resume: str, job_listing: str, \n",
    "                                 temperature=0.1, model_type='gpt-4o',\n",
    "                                 ) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Identify and list the most important missing qualifications between the following resume and job listing. \n",
    "    Mention the qualification first, what the job listing desires, then how the resume does not meet it. Be concise and to the point. \n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "    \"\"\"\n",
    "    final_prompt_template = PromptTemplate.from_template(prompt)\n",
    "        \n",
    "    # final_prompt_template = final_prompt_template.partial(sector=sector,\n",
    "    #                                                       model_tone=model_tone,\n",
    "    #                                                       **partial_prompt_kws)#, resume=resume, job=job)\n",
    "    try:\n",
    "        api_key = st.session_state.OPENAI_API_KEY\n",
    "    except:\n",
    "        api_key = os.getenv('OPENAI_API_KEY')\n",
    "    llm = ChatOpenAI(temperature=temperature, model=model_type, api_key=api_key,\n",
    "                    #  max_tokens=max_tokens\n",
    "                     )\n",
    "    \n",
    "    llm_chain = final_prompt_template | llm | StrOutputParser(output_key=\"response\")\n",
    "    response = llm_chain.invoke(dict(resume=resume, job=job_listing))\n",
    "    return response\n",
    "\n",
    "\n",
    "\n",
    "missing_response = list_missing_qualifications(long_resume, job_text_senior_rh)\n",
    "print(missing_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine if there is additional information that could be added to the resume, you can ask the following questions:\n",
      "\n",
      "### Azure and Microsoft Data Services Expertise\n",
      "1. **Azure Experience:** Have you had any experience working with Azure Machine Learning, Azure Databricks, or other Microsoft data services that might not be listed on your resume?\n",
      "2. **Certifications:** Do you hold any certifications in Azure data services or advanced analytics that are not mentioned on your resume?\n",
      "\n",
      "### Big Data Platforms and Technologies\n",
      "3. **Specific Big Data Platforms:** Have you worked with big data platforms such as Hadoop, Azure Data Lake, Azure Cosmos DB, Pig, Hive, or HBase? If so, can you provide details on your experience with these technologies?\n",
      "\n",
      "### Large Language Model Fine-tuning\n",
      "4. **LLM Fine-tuning:** Have you had any experience in fine-tuning large language models? Can you provide examples of projects where you have done this?\n",
      "\n",
      "### Statistical Modeling and Predictive Modeling\n",
      "5. **Hands-on Experience:** Can you provide more details on your hands-on experience with statistical modeling and predictive modeling? Specifically, do you have 3+ years of experience in these areas?\n",
      "\n",
      "### Experience with Specific Machine Learning Methods\n",
      "6. **Specific Methods:** Have you worked with specific machine learning methods such as GLM, LR, SVM, LVQ, SOM, or Neural Networks? If so, can you provide examples of projects where you used these methods?\n",
      "\n",
      "### Business Collaboration and Insights\n",
      "7. **Business Insights:** Can you provide examples of how you have translated complex data-driven findings into actionable business insights for non-technical stakeholders?\n",
      "\n",
      "### Research and Development in Data Science and Azure Technologies\n",
      "8. **Staying Updated:** How do you stay updated with advancements in data science and Azure technologies? Can you provide examples of recent trends or advancements you have incorporated into your work?\n",
      "\n",
      "### Experience with Specific Programming Languages\n",
      "9. **Additional Languages:** Do you have experience with programming languages such as PERL or Scala that are not mentioned on your resume?\n",
      "\n",
      "### General Questions\n",
      "10. **Additional Projects:** Are there any additional projects or experiences that you have worked on which might be relevant to this job but are not listed on your resume?\n",
      "11. **Professional Development:** Have you participated in any professional development activities, workshops, or courses that are relevant to the qualifications listed in the job description?\n",
      "\n",
      "These questions can help uncover any additional relevant experience or skills that the candidate may have but did not include in their resume.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# def questions_for_additional_info(resume: str, job_listing: str,\n",
    "                                       \n",
    "def questions_for_additional_info(matching_qualifications: str, missing_qualifications: str,\n",
    "                                  temperature=0.1, model_type='gpt-4o') -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following matching and missing qualifications, list questions that could help determine if there is additional information that could be added to the resume.\n",
    "\n",
    "    Matching Qualifications:\n",
    "    {matching_qualifications}\n",
    "\n",
    "    Missing Qualifications:\n",
    "    {missing_qualifications}\n",
    "    \"\"\"\n",
    "    final_prompt_template = PromptTemplate.from_template(prompt)\n",
    "        \n",
    "    # final_prompt_template = final_prompt_template.partial(sector=sector,\n",
    "    #                                                       model_tone=model_tone,\n",
    "    #                                                       **partial_prompt_kws)#, resume=resume, job=job)\n",
    "    try:\n",
    "        api_key = st.session_state.OPENAI_API_KEY\n",
    "    except:\n",
    "        api_key = os.getenv('OPENAI_API_KEY')\n",
    "    llm = ChatOpenAI(temperature=temperature, model=model_type, api_key=api_key,\n",
    "                    #  max_tokens=max_tokens\n",
    "                     )\n",
    "    \n",
    "    llm_chain = final_prompt_template | llm | StrOutputParser(output_key=\"response\")\n",
    "    response = llm_chain.invoke(dict(matching_qualifications=matching_qualifications, missing_qualifications=missing_qualifications))\n",
    "    return response\n",
    "\n",
    "response_questions  = questions_for_additional_info(matching_qualifications=response_matching, missing_qualifications=missing_response)\n",
    "print(response_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Step 4: Define Tools for LangChain Agent\n",
    "\n",
    "Create tools that the LangChain agent can use to perform these tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.agents import Tool\n",
    "\n",
    "rate_resume_tool = Tool(\"RateResume\",\n",
    "                        rate_resume_vs_job,\n",
    "                        description=\"Rates the resume against the job listing and provides a justification.\"\n",
    ")\n",
    " \n",
    "matching_qualifications_tool = Tool(\"ListMatchingQualifications\",\n",
    "                                    list_matching_qualifications,\n",
    "                                    description=\"Lists the matching qualifications between the resume and job listing.\",\n",
    "                                    resume = long_resume,\n",
    "                                    job_listing = job_text_senior_rh\n",
    ")\n",
    "\n",
    "missing_qualifications_tool = Tool(\"ListMissingQualifications\",\n",
    "                                   list_missing_qualifications,\n",
    "                                   description=\"Lists the missing qualifications in the resume based on the job listing.\",\n",
    "                                   resume = long_resume,\n",
    "                                   job_listing = job_text_senior_rh\n",
    ")\n",
    "\n",
    "additional_info_questions_tool = Tool(\"QuestionsForAdditionalInfo\",\n",
    "                                      questions_for_additional_info,\n",
    "                                      description=\"Lists questions to determine if there is additional information that could be added to the resume.\",\n",
    "                                        matching_qualifications = response_matching,\n",
    "                                        missing_qualifications = missing_response\n",
    "                                      \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Step 5: Initialize the Language Model and Create the Agent\n",
    "\n",
    "Initialize the language model and create an agent that uses the defined tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['agent_scratchpad', 'input'] input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]} metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-tools-agent', 'lc_hub_commit_hash': 'c18672812789a3b9697656dd539edf0120285dcae36396d0b548ae42a4ed66f5'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')]\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "# Get the prompt to use - you can modify this!\n",
    "tools_prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "print(tools_prompt)\n",
    "# tools_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.prompts.chat.ChatPromptTemplate"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tools_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Config',\n",
       " 'InputType',\n",
       " 'OutputType',\n",
       " 'abatch',\n",
       " 'abatch_as_completed',\n",
       " 'aformat',\n",
       " 'aformat_messages',\n",
       " 'aformat_prompt',\n",
       " 'ainvoke',\n",
       " 'append',\n",
       " 'assign',\n",
       " 'astream',\n",
       " 'astream_events',\n",
       " 'astream_log',\n",
       " 'atransform',\n",
       " 'batch',\n",
       " 'batch_as_completed',\n",
       " 'bind',\n",
       " 'config_schema',\n",
       " 'config_specs',\n",
       " 'configurable_alternatives',\n",
       " 'configurable_fields',\n",
       " 'construct',\n",
       " 'copy',\n",
       " 'dict',\n",
       " 'extend',\n",
       " 'format',\n",
       " 'format_messages',\n",
       " 'format_prompt',\n",
       " 'from_messages',\n",
       " 'from_orm',\n",
       " 'from_role_strings',\n",
       " 'from_strings',\n",
       " 'from_template',\n",
       " 'get_graph',\n",
       " 'get_input_schema',\n",
       " 'get_lc_namespace',\n",
       " 'get_name',\n",
       " 'get_output_schema',\n",
       " 'get_prompts',\n",
       " 'input_schema',\n",
       " 'input_types',\n",
       " 'input_variables',\n",
       " 'invoke',\n",
       " 'is_lc_serializable',\n",
       " 'json',\n",
       " 'lc_attributes',\n",
       " 'lc_id',\n",
       " 'lc_secrets',\n",
       " 'map',\n",
       " 'messages',\n",
       " 'metadata',\n",
       " 'name',\n",
       " 'output_parser',\n",
       " 'output_schema',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'partial',\n",
       " 'partial_variables',\n",
       " 'pick',\n",
       " 'pipe',\n",
       " 'pretty_print',\n",
       " 'pretty_repr',\n",
       " 'save',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'stream',\n",
       " 'tags',\n",
       " 'to_json',\n",
       " 'to_json_not_implemented',\n",
       " 'transform',\n",
       " 'update_forward_refs',\n",
       " 'validate',\n",
       " 'validate_input_variables',\n",
       " 'validate_template',\n",
       " 'validate_variable_names',\n",
       " 'with_config',\n",
       " 'with_fallbacks',\n",
       " 'with_listeners',\n",
       " 'with_retry',\n",
       " 'with_types']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: not x.startswith('_'),dir(tools_prompt), ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Must replace system message with custom prompt\n",
    "tools_prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_prompt_formatted( sector=\"data science and analytics\",\n",
    "                          model_tone='friendly and encouraging',\n",
    "                          resume='', job_listing='',\n",
    "                          return_formatted=True):\n",
    "    \"\"\"Helper function for get_prompt_template. New v2.0\"\"\"\n",
    "    system_prompt_template = \"\"\"\n",
    "    You are a a specialized career coach for the {sector}, focused on delivering tailored, concise job application advice and practice.\n",
    "    You are proficient in resume analysis, cover letter guidance, and interview preparation, adapting to each user's unique requirements. \n",
    "    You maintain a professional, {model_tone} tone, ensuring advice is efficient, clear, and easily understandable, with the goal of aiding their career progression. \n",
    "    Ask the user for their resume and job listing if not provided and they are needed to answer .\" \n",
    "    \n",
    "    Use the following context, if provided, to help answer the questions:\n",
    "    \n",
    "    -------------\n",
    "    My Resume:\n",
    "    {resume}\n",
    "    \n",
    "    -------------\n",
    "    The job listing:\n",
    "    {job_listing}\n",
    "    \"\"\"  \n",
    "    system_prompt =  PromptTemplate.from_template(system_prompt_template)\n",
    "    \n",
    "    if return_formatted:\n",
    "        print(\"- Returning formatted system prompt\")\n",
    "        return system_prompt.partial(sector=sector, model_tone=model_tone, resume=resume, job_listing=job_listing)\n",
    "    else:\n",
    "        print(\"- Returning unformatted system prompt\")\n",
    "        return system_prompt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Returning formatted system prompt\n",
      "\n",
      "    You are a a specialized career coach for the {sector}, focused on delivering tailored, concise job application advice and practice.\n",
      "    You are proficient in resume analysis, cover letter guidance, and interview preparation, adapting to each user's unique requirements. \n",
      "    You maintain a professional, {model_tone} tone, ensuring advice is efficient, clear, and easily understandable, with the goal of aiding their career progression. \n",
      "    Ask the user for their resume and job listing if not provided and they are needed to answer .\" \n",
      "    \n",
      "    Use the following context, if provided, to help answer the questions:\n",
      "    \n",
      "    -------------\n",
      "    My Resume:\n",
      "    {resume}\n",
      "    \n",
      "    -------------\n",
      "    The job listing:\n",
      "    {job_listing}\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=[], partial_variables={'sector': 'data science and analytics', 'model_tone': 'friendly and encouraging', 'resume': '[LONG MASTER RESUME]  James M. Irving, Ph.D. 8222 Spadderdock Way, Laurel, MD, 20724 | (518) 322-6750 | james.irving.phd@gmail.com |  LinkedIn: james-irving-phd | GitHub: https://github.com/jirvingphd  SUMMARY V1 Innovative and enterprising data scientist with extensive experience in applying advanced data science techniques to real-world problems. Known for excellent problem-solving skills and the ability to rapidly master and implement new technologies. Committed to leveraging data to drive innovation and support data-driven decision-making. SUMMARY V2 Neuroscientist-turned-data scientist with an insatiable curiosity and a proven track record in mastering cutting-edge technologies. Exceptional communication and interpersonal skills paired with a robust history of problem-solving and critical thinking. Proven ability to self-teach complex concepts and technologies, including in vivo electrophysiology recordings and analysis. Successfully trained generations of collaborators, technicians, research fellows, and undergraduate volunteers by customizing the training to match the specific trainees experience and knowledge. COMPETENCIES  Data Analysis, Statistical Modeling, Machine Learning, Data Visualization  Experimental Design, Quantitative Research Methods, Time Series Analysis, Signal Processing  Cognitive Neuroscience, Behavioral Analysis, Database Management, Pattern Recognition  Python Programming, Deep Learning, Natural Language Processing, AI/LLM Implementation  Adaptive Communication Style, Problem-Solving & Critical Thinking EXPERIENCE  Coding Dojo | Remote Curriculum Writer - Data Science March 2023 - January 2024  Developed and delivered advanced courses in Time Series Modeling, NLP, and Model Deployment, enhancing data science skills for over 100 professionals.  Expanded a 16-week boot camp to a 24-week comprehensive training program, increasing curriculum depth by 50%, which boosted learner engagement and program satisfaction.  Implemented project management and automation tools using Monday.com, optimizing workflow efficiency and resolving operational bottlenecks.  Developed and implemented Monday.com boards, including public forms and executive-facing Gantt charts, to automate internal workflows and streamline curriculum management, resolving over 100 issues.  Integrated cutting-edge technologies like APIs, Web Scraping, and Computer Vision into the curriculum, aligning educational content with evolving industry standards and practical application needs.  Developed a workflow and process to test and identify datasets for curriculum use, including template Python notebooks for preprocessing, visualization, EDA, modeling, and interpretations.  Constructed the Dojo Environment Setup for Students, ensuring compatibility with various OS and facilitating smooth installation of necessary tools and libraries.  Created and maintained a GitHub Organization for curriculum-related activities, solutions, and packages, providing a centralized resource hub for students and instructors.  Designed an extended case study for the 6-month curriculum, applying all phases of CRISP-DM to a specially constructed subset of the Ames housing dataset, enhancing practical application and understanding of the data science lifecycle.  Achieved tight deadlines throughout the year despite unexpected demands related to getting the curriculum accredited ensuring timely delivery and high-quality content for the program.  Data Science Instructor November 2021 - March 2023  Achieved high Net Promoter Scores (NPS) exceeding 90% through engaging and interactive live lectures, demonstrating strong communication and pedagogical skills.  Revolutionized administrative workflow by automating tasks, resulting in a 99% reduction in student onboarding timefrom 5 hours to just 2 minutesdramatically enhancing operational efficiency and productivity. \\n Developed and delivered a highly acclaimed 4-week course with perfect feedback ratings, showcasing expertise in curriculum development and instructional delivery.  Designed and led over 16 interactive live lectures and code-along projects, enhancing student participation and creating a dynamic learning environment. Flatiron School | Remote Data Science Instructor  October 2019 - October 2021  Mentored and supervised over 60 students, helping them transition into successful data science careers with a high post-program employment rate.  Conducted weekly 90-minute study groups, accumulating over 270 hours of recorded lessons, significantly enhancing student comprehension and engagement.  Spearheaded the development and implementation of the \"Flex\" boot camp program, refining instructional design and delivery methods to meet diverse learning needs.  Created and maintained three student-progress-tracking Looker dashboards, providing real-time insights into student performance and facilitating timely interventions.  Guided students in selecting capstone project subjects, identifying job sectors of interest, and selecting appropriate data sources. Topics included time series analysis, NLP analysis, Covid cough classification (via Computer Vision),  and customer segmentation.  Offered bonus lectures on Object-Oriented Programming, dashboarding with Plotly and Dash, and advanced visualizations with matplotlib and seaborn.  Updated the entire lecture and activity content to accommodate a new teaching model, integrating recorded lectures from a national \"Central Lecturer\" with expanded hands-on activities. University of Maryland, School of Medicine | Baltimore, MD  Laboratory Manager  July 2017 - August 2018  Ensured full compliance with regulatory standards as the lab\\'s public representative, achieving a flawless inspection record.  Successfully represented lab and guided inspectors through 4 regulatory inspections from 2 agencies, demonstrating knowledge of and compliance with protocols and regulations.  Negotiated and finalized a $100,000 technical hardware contract with vendors, optimizing procurement processes and ensuring cost-effectiveness.  Managed and administered over 20 TBs of data storage systems, ensuring data accessibility, security, and efficient retrieval.  Overhauled mouse colony management procedures, reducing housing costs by 60%  (from approximately $3.8k/month to $1.5k/month ) through strategic resource allocation and process optimization.  Created and instituted new surgery logs to simplify record keeping while ensuring regularity compliance.  Managed lab supplies and equipment purchasing, maintaining appropriate documentation and financial records.  Consolidated and encrypted all sensitive and proprietary lab information vendor accounts, log-in information, and secure information into an encrypted data vault Postdoctoral Research Fellow  June 2015 - July 2017  Led neuroscience research using advanced techniques such as in vivo optogenetics and electrophysiology recordings, resulting in groundbreaking insights into neural functioning.  Developed approximately 30 custom analysis scripts in Matlab, NexScript, MedPC, and Arduino, enhancing data processing capabilities and facilitating comprehensive statistical analyses.  Mentored and guided a diverse team, fostering a collaborative learning environment and achieving research excellence (1 postdoc, 2 Ph.D. students, 3 lab techs, and 3 undergraduate volunteers.)  Demonstrated self-directed learning by mastering Matlab programming and creating custom-designed analysis programs for large datasets, streamlining data interpretation and enhancing research efficiency.  Researched the role of extended amygdala stress neurons in binge drinking, using multiple genetic tools and in vivo electrophysiology recordings.  Recorded changes in the activity of amygdala neurons during binge drinking. Identified neuron populations using a combination of single-unit recordings and optogenetic stimulation using targeted viral vectors.  Founded in vivo electrophysiology recordings and in vivo deep-brain structure calcium imaging in awake and behaving mice.  Directed several research projects simultaneously and managed a staff of postdoctoral fellows, technicians and student volunteers.  Programmed custom-designed analysis programs (~30) for large datasets in 4 programming languages (see skills).  Communicated research findings to mixed audiences with varying degrees of background knowledge and experience via seminars, presentations, as well as scientific posters.   Wrote user guides on various complicated technical procedures and techniques to train lab members and collaborators.  Trained and mentored 1 research fellow, 2 graduate students, 2 lab technicians, and 3 undergraduate volunteers on several complex technical procedures and the underlying scientific principles/theory.  Graduate Research Assistant \\nSeptember 2009 -  May 2015  Pioneered application of optogenetics with fast-scan cyclic voltammetry to discover previously unknown modulation of dopamine release via cholinergic interneurons.  Communicated research findings to audiences with varying degrees of background knowledge and familiarity in seminars, as well as scientific posters.  Trained and mentored 4 fellows, 3 graduate students, 5 lab technicians, 6 collaborators, and 1 undergraduate volunteer on various complex procedures and techniques.  Wrote user guides on various complex technical procedures and techniques to train current and future lab members Tulane University | New Orleans, LA Research Assistant January 2009  May 2009  Continued masters thesis study of the role of histone deacetylase (HDAC) inhibition in aggression under chronic stress.  Tested changes in stress hormones and protein expression in stressed rats with HDAC inhibition.  DISTINCTIONS & HONORS  Happy Camper Award, University of Maryland 2012  2013  Awarded to the Ph.D. student with the most positive attitude in the face of adversity, as voted by fellow students.  Summer Research Program Award, Tulane University  May 2008 to August 2008  Awarded for distinguished scientific research, including salary.  Tulane Distinguished Scholars, Tulane University  Fall 2004 - Fall 2007  Awarded for outstanding academic performance.  Tulane-Newcomb College Deans List  Fall 2004 - Fall 2005  Awarded for achieving a GPA greater than 3.7 EDUCATION Certificate of Completion, Data Science, Flatiron School, Online (February 2019 - August 2019)  Intensive 5-month program, approximately 50 hours per week Doctor of Philosophy, Neuroscience, University of Maryland, Baltimore, MD (August 2009 - May 2015)  Including specialized optional training: Entrepreneurship in Life Sciences course, Science Communication internship. Master of Science, Neuroscience, Tulane University, New Orleans, LA (January 2008 - December 2008) Bachelor of Science, Neuroscience (Sociology Minor), Tulane University, New Orleans, LA (August 2004 - December 2007) ADDITIONAL EXPERIENCE AND SERVICE University of Maryland | Baltimore, MD Science Communication Internship  Office of Public Affairs  June 2013 - September 2013  Selected as one of four founding members for an internship with Office of Public Affairs at the University of Maryland School of Medicine.  Trained in many aspects of university public affairs communications, relaying complex scientific material to a lay audience for both educational and promotional purposes.  Wrote press releases on university-associated research and novel findings to disseminate to inspire media coverage.  Wrote an in-depth interview featuring a university scientists high-impact research developing a novel anti-depressant.  Practiced live television interviews in the universitys satellite teleconferencing suite as both interviewer and interviewee.  Weekly training classes + independent assignments  5-10 hours/week.  Entrepreneurship in Life Sciences  Interdisciplinary Course January 2014 to June 2014  Trained by visiting experts in aspects of developing, promoting, and acquiring venture funding for a biomedical technology company.  \\n Wrote and presented funding proposals for venture capitalist firms for a resource-sharing/saving cloud-based software solution for universities.  Wrote a business plan, patent applications, and promotional materials.  Weekly classes + group work  10 hours/week.  Student Training Committee Member January 2013 - June 2015  Served graduate student community as proponent and liaison to the Ph.D. program administration.  Reformed graduate program policies and procedures for the mutual benefit of students and faculty.  Advised administration on student outreach and prospective student application/interview process.  Big Brother  Program in Neuroscience  August 2010 - December 2013  Volunteered as Big Brother mentor for 3 incoming doctoral students.  Advised little brothers on research lab choices, handling graduate coursework, and navigating university politics. Tulane University | New Orleans, LA Green Wave Ambassador Fall 2004  Spring 2005  Led guided tours of the campus for prospective students and their families, providing comprehensive information about academic programs, campus facilities, and student life.  Served as a host for visiting students, organizing and facilitating events to enhance their campus experience.  Engaged with visitors to answer questions, provide insights into the student experience, and assist with logistical needs.  Represented the university positively, contributing to recruitment and outreach efforts by sharing personal experiences and highlighting unique aspects of the campus community.  Student Calling Center Representative Fall 2005  Spring 2007  Contacted alumni to provide updates about university events, achievements, and developments.  Engaged alumni in meaningful conversations to foster a connection between them and the university.  Solicited donations, explaining the impact of their contributions on university programs, scholarships, and facilities.  Maintained accurate records of interactions and feedback, contributing to the continuous improvement of alumni relations and fundraising strategies.  PUBLICATIONS  Aroni S, Marino RAM, Girven KS, Irving JM, Cheer JF, Sparta DR. (2021) Repeated binge ethanol drinking enhances electrical activity of central amygdala corticotropin releasing factor neurons in vivo. Neuropharmacology.  Girven, K., Irving, J., Aroni, S., Sparta, D. The Role of Interconnections between the vBNST and insula in the modulation of reward processing. Manuscript in preparation.  Cachope, R., Mateo, Y., Mathur, B.N., Irving, J., Wang, H.-L., Morales, M., Lovinger, D.M., and Cheer, J.F. (2012). Selective Activation of Cholinergic Interneurons Enhances Accumbal Phasic Dopamine Release: Setting the Tone for Reward Processing. Cell Reports 2, 3341.  Mateo, Y., Atwood, B., Wang, H.-L., Zhang, S., Irving, J., Gildish, I., Cachope, R., Bellochio, L., Guzman, M., Morales, M., Cheer, J.F., and Lovinger, D.M. Cortical afferents expressing CB1 receptors control accumbal phasic dopamine release caused by selective activation of cholinergic interneurons. Manuscript submitted for publication. POSTER ABTRACTS  Irving, J.M., Maehler, C.J., Qadir, H., Girven, K.S., Sparta, D.R. Central Amygdala Corticotropin Releasing FactorNeurons Encode and Modulate Binge Drinking and Relapse American College of Neuropsychopharmacology Annual Meeting 2016.  Irving, J.M., Maehler, C.J., Girven, K.S., Sparta, D.R. The Role of Extended Amygdala Corticotropin Neurons in Binge Ethanol Drinking. Society for Neuroscience Annual Meeting 2016.  Irving, J.M., Maehler, C.J., Sparta, D.R. Optogenetic and Pharmacogenetic Interrogation of Central Amygdala Corticotropin Neurons on Binge Ethanol Drinking. Research Society on Alcoholism Annual Meeting 2016.  Irving, J.M., Gluskin, K.H., Cheer, J.F. Optogenetic activation of accumbal fast-spiking interneurons is reinforcing. Society for Neuroscience Annual Meeting 2014.  Kashtelyan, V., Irving, J.M., Fitoussi, A., Wang, H., Morales, M., Cheer, J.F. Conditional deletion of CB1 receptors on cholinergic terminals and its functional consequences. Society for Neuroscience Meeting Annual 2014.  Irving, J.M., Mateo, Y., Cheer, J.F. Optogenetic Stimulation of Cholinergic Interneurons in the Nucleus Accumbens Causes Dopamine Release. Society for Neuroscience Meeting 2011. \\n Irving, J.M., Mateo, Y., Cheer, J.F. Endogenous Activity of Cholinergic Interneurons in the Nucleus Accumbens is Sufficient to Evoke Dopamine Release. Graduate Research Conference 2012.  PROFERRED COMMUNICATIONS   Irving, J.M., Sparta, D.R. Modulation of Binge Drinking by Central Amygdala Corticotropin-Releasing Factor Neurons. Department of Anatomy & Neurobiology, Second-Monday Program, University of Maryland School of Medicine, 2016.  Irving, J.M., Cheer, J.F. The Role of Local Activity of the Nucleus Accumbens in Reward: Interneurons and Gamma Oscillations,, Public Dissertation Defense, 2016.  Irving, J.M..Cheer, J.F., Selective activation of cholinergic interneurons enhances accumbal phasic dopamine release: setting the tone for reward processing., Department of Anatomy & Neurobiology, Second-Monday Program, University of Maryland, Baltimore, 2012.  Irving, J.M..Cheer, J.F., Selective activation of cholinergic interneurons enhances accumbal phasic dopamine release: setting the tone for reward processing., Program in Neuroscience Retreat, Notre Dame of Maryland, 2012.  Irving, J.M., Cheer, J.F., The Role of CB1 Receptors on GABAergic Interneurons of the Nucleus Accumbens in Motivated-Behavior and Modulation of Accumbal Gamma Rhythms University of Maryland, Baltimore, Thesis Proposal, 2014.  Irving. J.M., Cheer, J.F., The Reinforcing Effects of Gamma-Frequency Stimulation of Accumbal Parvalbumin Interneurons and the Role of CB1 Receptors, University of Pittsburgh, Department of Psychiatry, 2015. DATA SCIENCE PROJECTS Computer Vision Classification of American Sign Language  GitHub Link Applied tensorflow and transfer learning to classify an image as the correct letter of the ASL alphabet.  COMING SOON AI Job Application Assistant  App Link  GitHub Link Developed a Streamlit application to assist job seekers with resumes and cover letters  Developed a Streamlit application to assist job seekers by analyzing resumes and job listings using AI.  Integrated ChatGPT for tailored advice, resume improvements, and cover letter creation.  Automated job application process with AI-driven insights and recommendations.  Enhanced user experience with an interactive and user-friendly interface.  Provided actionable advice to job seekers, improving their chances of success.  Key Technologies Used: Streamlit, LangChain, OpenAI API  NLP Analysis of Amazon Reviews + AI Recommendations - GitHub Link Natural Language Processing Analysis, Modeling, and Deployment with Actionable Insights  Designed and deployed a user-centric Streamlit dashboard, integrating live sentiment predictions and interactive analysis of trends to guide strategic decision-making.  Conducted sentiment analysis on over 5 million Amazon Grocery & Gourmet Food reviews, utilizing NLP and machine learning techniques (Logistic Regression, Tf-idf vectorization) to identify key factors affecting customer satisfaction and achieve 95% accuracy in sentiment classification.  Employed Hugging Face transformers and Lang Chain/ChatGPT within the dashboard with a vectorized database used for summarization and insights, translating vast consumer feedback into actionable product enhancement strategies.  Key Technologies Used: Python, Hugging Face, OpenAI API, LangChain, spacy, scikit-learn. How to Make a Successful Movie  GitHub Link Constructing and analyzing an extensive movie database with hypothesis-testing insights + Tableau Dashboard  Integrated and normalized datasets from IMDB and TMDB API for comprehensive movie analysis.  Engineered a MySQL database on AWS RDS for robust data storage and retrieval.  Designed an interactive Tableau dashboard to communicate findings to stakeholders, enhancing decision-making processes (see GitHub link).  Applied A/B Testing to identify key factors influencing movie performance and success to provide business recommendations on what movies to create for high box office returns on factors like MPAA rating, runtime, and genre.  Key Technologies Used: Python, SQL, Tableau, TMDB API, Pandas, sqlalchemy, MySQL Workbench, statsmodels, AWS RDS How to Spot a Troll  GitHub Link Classifying Russian Troll Tweets vs Authentic Tweets  Performed EDA on 3 million tweets from accounts from the Internet Research Agency (the Russian Troll Farm) to identify an appropriate control dataset (which time period and content to extract to construct control group).   Harvested control tweets for use in supervised learning using the TwitterAPI and TweetDeck to target the top 40 most frequent mentions, which produced 40,000 control tweets.   Conducted natural language processing (NLP) on 80,000 tweets using nltk, Word2Vec, and Keras to tokenize, vectorize, and train word embeddings for Logistic Regression and multiple Keras Neural Networks.   Final models achieved 90% accuracy with a dense neural network (training time: 32 sec) and 88% accuracy using Logistic Regression (training time: 0.6 sec)   Key Technologies Used: Python, Tweepy, Neural Networks (Tensorflow & Keras),  \\nRecidivism Risk Assessment  GitHub Link Classifying which released prisoners in Iowa will return to a life of crime using Next-Gen Gradient Boosted Trees  Developed a predictive model to classify which released prisoners in Iowa are likely to return to crime using Gradient Boosted Trees. with over 70% accuracy (via scikit-learn and Catboost).  Researched Iowa\\'s state sentencing guidelines and sentencing enhancements to engineer new numerical features to capture the severity of the crimes committed and the duration of sentences.  Achieved high recall rates for predicting recidivism using XGBoost.  Identified key features influencing recidivism, such as age, release type, and offense subtype.  Provided actionable insights and recommendations to the Iowa Department of Corrections.  Implemented various machine learning models and utilized SHAP for feature importance analysis.  Key Technologies: Python, Jupyter Notebooks, XGBoost, CatBoost, SHAP, SMOTE   Forecasting Stock Market Fluctuations with Trumps Tweets  GitHub Link Combining Natural Language Processing of Trumps Tweets with Time Series Forecasting S&P500 Price   Employed Natural Language Processing with nltk and word embeddings (both Word2Vec & GloVe pre-trained) to classify Trumps tweets by S&P 500 price change (increase/decrease/no change) 60 minutes after tweeting.  Compared tweet NLP classification models using Keras neural networks (LSTM, GRU, and CNN) to predict the direction of stock market price change from NLP alone.  Used Keras neural networks for time series forecasting of S&P 500 price.  Compared multiple data sources: price alone, price + 7 market technical indicators.  Compared forecasting models: Keras LSTM vs. XGBoost Regressor.  Final model stacked NLP classification predictions with S&P 500 time series forecasting and additional tweet features (sentiment analysis with Vader, number of retweets/favorites, uppercase-to-lowercase ratio). PROFESSIONAL SKILLS Programming: Python, OOP, SQL (MySQL, SQLAlchemy), MATLAB, HTML/CSS, Git/GitHub, NexScript, MedState Notation Data Analysis: ETL (numpy, pandas), AB Testing (scipy, statsmodels), Machine Learning (scikit-learn, Catboost, XGBoost), Deep Learning (Tensorflow, Keras) Natural Language Processing: nltk, spaCy, Tensorflow, HuggingFace transformers, LLMs(OpenAI, LangChain) Visualization/Dashboarding: Plotly/Dash, Tableau, Streamlit Dashboards & Deployment, Seaborn/Matplotlib, Looker Software: Adobe Illustrator, Adobe Photoshop, GraphPad Prism, SPSS, Microsoft Office, VS Code, Jupyter Notebook/Lab, Google Suite, Plexon OfflineSorter, NeuroExplorer  LEADERSHIP & COMMUNITY INVOLVEMENT SECTION IS WORK-IN-PROGRESS  Key Club Lt. Governor \\n', 'job_listing': 'Robert Half\\nSenior Data Scientist\\n$115K/yr - $173K/yrMid-Senior level\\n10,001+ employees  Staffing and Recruiting\\n2 company alumni work here3 school alumni work here\\n3 of 3 skills match your profile - you may be a good fit\\nApply SavedCalifornia, United States4 hours ago29 applicants\\nRemoteFull-time\\nAm I a good fit for this job? How can I best position myself fo\\nMeet the hiring team\\nKelli Griffin3rd\\nLead Talent Acquisition Partner\\nJob posterMessage\\nAbout the job\\nReady to revolutionize the future of data-driven decision-making? Join our\\npioneering Data Science team as we embark on an exciting journey to unlock\\ninsights, drive innovation, and shape the landscape of our organization\\'s success.\\nIf you\\'re passionate about leveraging cutting-edge generative AI technologies\\nand transforming raw data into actionable insight, we want you on our team!\"\\nThe Senior Data Scientist will be responsible for leading advanced data analytics\\nprojects, leveraging Azure and Microsoft data services. This role demands a deep\\nunderstanding of data science methodologies, machine learning algorithms, and\\nbig data technologies. The incumbent will work closely with cross-functional\\nteams to understand business needs and formulate and execute data science\\nsolutions that drive significant business impact.\\nKey Responsibilities:\\nData Analytics and Modeling:\\nDevelop and implement advanced predictive models and statistical\\nanalysis using a variety of machine learning algorithms.\\nSuggest algorithms or models appropriate for specific use cases and\\napplications.\\nAnalyze and extract relevant information from large amounts of historical\\nbusiness data to help automate and optimize key processes with business\\nteams.\\nApply technical solutions to business problems and questions using large\\nscale data analytics and machine learning; create highly calibrated\\nsolutions for business problems.\\nWork closely with software engineering teams to drive real-time model\\nexperiments, implementations and new feature creations.\\nContinuously evaluate and refine models based on performance metrics.\\nUtilize cloud technologies such as Azure Machine Learning, Azure\\nDatabricks, and other Microsoft data services for data processing, modelHomeMy NetworkJobsMessagingNotificationsMe\\n For BusinessLear\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 1/7\\nSee lessbuilding, and deployment.\\nLarge Language Model Fine-tuning:\\nEnhance and evolve the performance of large language models by\\nrefining their capabilities through targeted fine-tuning.\\nSteer both the research trajectory and the practical engineering efforts of\\nthe team.\\nFormulate and enact algorithms for model enhancement, tweak critical\\nhyperparameters, and heighten overall model efficiency.\\nGuarantee the integrity and relevance of datasets by conducting thorough\\npreprocessing and data analysis within the fine-tuning workflow.\\nConduct assessments on fine-tuned models, making necessary\\nmodifications to boost their effectiveness.\\nFoster a cooperative environment within the team, providing guidance to\\npeers to ensure a smooth fine-tuning operation that yields superior\\nresults.\\nStay at the forefront of advancements in large language model\\ntechnologies and applications, perpetually refining technical expertise in\\nmodel fine-tuning.\\nData Management and Strategy:\\nCollaborate with IT and data engineering teams in an enterprise setting to\\nintegrate data science solutions into the broader tech stack and data\\nstrategy.\\nBusiness Collaboration and Insights:\\nWork closely with business stakeholders to identify opportunities for\\nleveraging company data to drive business solutions.\\nTranslate complex data-driven findings into actionable business insights\\nand communicate these effectively to non-technical stakeholders.\\nResearch and Development:\\nStay abreast of industry trends and advancements in data science and\\nAzure technologies.\\nConduct research to explore new methodologies and technologies that\\ncan enhance the organization\\'s data analytics capabilities.\\nPreferred Qualifications and Skills:\\nBachelor\\'s degree in Statistics, Computer Science, Mathematics or\\nequivalent required; Master\\'s or PhD highly preferred\\n5 years of professional experience in data science, with a record in\\ndesigning and implementing large-scale data science projects.\\n5 years of industry experience in predictive modeling and large data\\nanalysis\\nKnowledge of open-source large language models and experience with\\nevaluating and recommending appropriate models for specific use cases.\\n3+ years of experience in using big data platforms and technologies such\\nas Hadoop, Azure data lake, Azure Cosmos DB, Pig, Hive, HBase, etc.\\n3+ years of hands-on experience in statistical modeling, data mining,\\nlarge data analysis and predictive modeling; text mining a major plus\\n3+ years of experience in regression, classification and clustering\\nmethods such as GLM, LR, SVM, LVQ, SOM, Neural Networks\\nExperience with two or more of the following: Python, PERL, Matlab or\\nScala\\nExpertise in various machine learning frameworks and libraries (e.g.,\\nTensorFlow, PyTorch, Scikit-learn).\\nExcellent analytical, problem-solving, and communication skills.\\nExcellent communication skills, with a proven ability to translate technical\\nfindings into business recommendations and strategies.\\nCertifications in Azure data services or advanced analytics preferred\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 2/7\\nSet alert for similar jobs\\nData Scientist, California, United StatesSet alert\\nEmployer-provided\\nPay range in California, United States\\nExact compensation may vary based on skills, experience, and location.\\nBase salary\\n$115,000/yr - $173,000/yr\\nFeatured benefits\\nMedical insurance\\nVision insurance\\nDental insurance\\n401(k)\\nTuition assistance\\nQualifications\\n3 of 3 skills match your profile - you may be a good fit\\nSkills added by the job poster\\nBig Data  Large Language Models (LLM)  Natural Language Processing (NLP)\\nAdditional skills among applicants\\nData Analysis  Data Science  Data Visualization  Machine Learning  Microsoft\\nPower BI  Python (Programming Language)  R (Programming Language)  SQL \\nShow qualification details\\nPut your best foot forward with your application\\nHire a resume writer\\nGet a resume review\\nSee how you compare to other applicants\\nApplicants for this job\\n29Applicants\\n29Applicants in the past day\\nApplicant seniority level\\n15 Entry level applicants\\n10 Senior level applicants\\n1 Director level applicant Youve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 3/7\\nApplicant education level\\n19%have a Doctor of Philosophy (Similar to you)\\n59%have a Master\\'s Degree\\n15%have a Bachelor\\'s Degree\\n7%have other degrees\\nApplicants are in these locations\\n1-5 applicants\\nNew York City Metropolitan\\nArea\\n1-5 applicants\\nGreater Pittsburgh Region\\n1-5 applicants\\nDallas-Fort Worth Metroplex\\nSee if Robert Half is hiring people like you\\nThe latest hiring trends.\\n29,307\\nTotal employees3%\\nCompany-wide\\n2 year growth2%\\nEngineering\\n2 year growth\\nMedian employee tenure 6 yearsMay 2022 Nov 2022 May 2023 Nov 2023 May 202410,00020,00030,00040,000\\nRobert Half hires candidates from some of these companies and schools\\nRobert Half hired 2 people\\nfrom Coding Dojo.See all\\nRobert Half hired 3 people from\\nFlatiron School.See all\\nEngineering hires at Robert Half came\\nfrom these companies and more.Engineering hires at Robert Half came\\nfrom these schools and more.\\nReset map\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 4/7\\nMore jobsShow more Premium insightsSee more companies See more schools\\nAbout the company\\nRobert Half\\n3,147,224 followersFollow\\nStaffing and Recruiting10,001+ employees29,320 on LinkedIn\\nTrending employee content PreviousNext\\nShow more\\nRobert Half, the worlds first and largest specialized talent solutions firm,\\nconnects opportunities at great companies with highly skilled job seekers. We\\noffer contract, temporary and permanent placement solutions for roles in financshow more\\nInterested in working with us in the future?\\nPrivately share your profile with our recruiters  youll be noted as\\nexpressing interest for up to a year.Learn more\\nIm interested\\nLead Data Scientist\\nCigniti Technologies\\nUnited States (Remote)\\nActively recruiting\\n4 weeks agoEasy ApplySenior Data Scientist\\nDTN\\nUnited States (Remote)\\nActively recruiting\\n2 weeks ago\\nData Scientist\\nQuantum World Technologies\\nUnited States (Remote)\\nActively recruiting\\nSr. Data Scientist\\nAKASA\\nUnited States (Remote)\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 5/7\\nSee more jobs like this10 minutes agoEasy Apply 2 weeks ago\\nSenior Data Scientist\\nPhreesia\\nUnited States (Remote)\\nActively recruiting\\n3 weeks agoSr. Data Scientist\\nAppFolio\\nUnited States (Remote)\\nActively recruiting\\n1 week ago\\nSenior Data Scientist,\\nProduct\\nUniswap Labs\\nNew York, NY (Remote)\\nActively recruiting\\n1 week agoSenior Data Scientist\\nAustin Fraser\\nUnited States (Remote)\\nActively recruiting\\n6 days agoEasy Apply\\nSenior Data Scientist\\nWebflow\\nUnited States (Remote)\\n1 company alum works here\\n2 days agoSenior Data Scientist\\nXOi\\nUnited States (Remote)\\n2 weeks ago\\nLead Data Scientist\\nLittle Place Labs\\nUnited States (Remote)\\n1 month agoEasy ApplyStaff Data Scientist\\nDemandbase\\nUnited States (Remote)\\n3 school alumni work here\\n3 weeks ago\\nLearn skills to get a new job with these courses\\n135,378 viewers\\nThe New Rules of Work\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 6/7\\nAbout Accessibility Talent Solutions\\nCommunity Guidelines Careers Marketing Solutions\\nAd Choices Advertising\\nSales Solutions Mobile Small Business\\nSafety CenterQuestions?\\nVisit our Help Center.\\nManage your account and privacy\\nGo to your Settings.\\nRecommendation transparency\\nLearn more about Recommended Content.Select Language\\nLinkedIn Corporation  2024282,784 viewers\\nShow more on LinkedIn Learning\\nDeveloping Your Professional Image in a New Job\\nLooking for talent?Post a job\\nPrivacy & Terms\\nEnglish (English)\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 7/7\\n'}, template='\\n    You are a a specialized career coach for the {sector}, focused on delivering tailored, concise job application advice and practice.\\n    You are proficient in resume analysis, cover letter guidance, and interview preparation, adapting to each user\\'s unique requirements. \\n    You maintain a professional, {model_tone} tone, ensuring advice is efficient, clear, and easily understandable, with the goal of aiding their career progression. \\n    Ask the user for their resume and job listing if not provided and they are needed to answer .\" \\n    \\n    Use the following context, if provided, to help answer the questions:\\n    \\n    -------------\\n    My Resume:\\n    {resume}\\n    \\n    -------------\\n    The job listing:\\n    {job_listing}\\n    ')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the new sytem prompt to use for the tools agent\n",
    "system_prompt = get_system_prompt_formatted(sector=\"data science and analytics\",\n",
    "                            model_tone='friendly and encouraging',\n",
    "                            resume=long_resume, job_listing=job_text_senior_rh,\n",
    "                            return_formatted=True)\n",
    "print(system_prompt.template)\n",
    "system_prompt\n",
    "# print(system_prompt.for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=\" You are a a specialized career coach for the {sector}, focused on delivering tailored, concise job application advice and practice.  You are proficient in resume analysis, cover letter guidance, and interview preparation, adapting to each user's unique requirements.  You maintain a professional, {model_tone} tone, ensuring advice is efficient, clear, and easily understandable,  with the goal of aiding their career progression. Ask the user for their resume and job listing if not provided and they are needed to asnwer .\\nUse the following context, if provided, to help answer the questions:\\n\\nHere is my resume:\\n-------------\\n {resume}\\n\\n Here is the job listing:\\n-------------\\n{job}\\n\\n \"),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools_prompt.messages[0].prompt = get_system_prompt_str(with_context=True, with_onet=False)\n",
    "tools_prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Returning formatted system prompt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'chat_history': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], partial_variables={'sector': 'data science and analytics', 'model_tone': 'friendly and encouraging', 'resume': '[LONG MASTER RESUME]  James M. Irving, Ph.D. 8222 Spadderdock Way, Laurel, MD, 20724 | (518) 322-6750 | james.irving.phd@gmail.com |  LinkedIn: james-irving-phd | GitHub: https://github.com/jirvingphd  SUMMARY V1 Innovative and enterprising data scientist with extensive experience in applying advanced data science techniques to real-world problems. Known for excellent problem-solving skills and the ability to rapidly master and implement new technologies. Committed to leveraging data to drive innovation and support data-driven decision-making. SUMMARY V2 Neuroscientist-turned-data scientist with an insatiable curiosity and a proven track record in mastering cutting-edge technologies. Exceptional communication and interpersonal skills paired with a robust history of problem-solving and critical thinking. Proven ability to self-teach complex concepts and technologies, including in vivo electrophysiology recordings and analysis. Successfully trained generations of collaborators, technicians, research fellows, and undergraduate volunteers by customizing the training to match the specific trainees experience and knowledge. COMPETENCIES  Data Analysis, Statistical Modeling, Machine Learning, Data Visualization  Experimental Design, Quantitative Research Methods, Time Series Analysis, Signal Processing  Cognitive Neuroscience, Behavioral Analysis, Database Management, Pattern Recognition  Python Programming, Deep Learning, Natural Language Processing, AI/LLM Implementation  Adaptive Communication Style, Problem-Solving & Critical Thinking EXPERIENCE  Coding Dojo | Remote Curriculum Writer - Data Science March 2023 - January 2024  Developed and delivered advanced courses in Time Series Modeling, NLP, and Model Deployment, enhancing data science skills for over 100 professionals.  Expanded a 16-week boot camp to a 24-week comprehensive training program, increasing curriculum depth by 50%, which boosted learner engagement and program satisfaction.  Implemented project management and automation tools using Monday.com, optimizing workflow efficiency and resolving operational bottlenecks.  Developed and implemented Monday.com boards, including public forms and executive-facing Gantt charts, to automate internal workflows and streamline curriculum management, resolving over 100 issues.  Integrated cutting-edge technologies like APIs, Web Scraping, and Computer Vision into the curriculum, aligning educational content with evolving industry standards and practical application needs.  Developed a workflow and process to test and identify datasets for curriculum use, including template Python notebooks for preprocessing, visualization, EDA, modeling, and interpretations.  Constructed the Dojo Environment Setup for Students, ensuring compatibility with various OS and facilitating smooth installation of necessary tools and libraries.  Created and maintained a GitHub Organization for curriculum-related activities, solutions, and packages, providing a centralized resource hub for students and instructors.  Designed an extended case study for the 6-month curriculum, applying all phases of CRISP-DM to a specially constructed subset of the Ames housing dataset, enhancing practical application and understanding of the data science lifecycle.  Achieved tight deadlines throughout the year despite unexpected demands related to getting the curriculum accredited ensuring timely delivery and high-quality content for the program.  Data Science Instructor November 2021 - March 2023  Achieved high Net Promoter Scores (NPS) exceeding 90% through engaging and interactive live lectures, demonstrating strong communication and pedagogical skills.  Revolutionized administrative workflow by automating tasks, resulting in a 99% reduction in student onboarding timefrom 5 hours to just 2 minutesdramatically enhancing operational efficiency and productivity. \\n Developed and delivered a highly acclaimed 4-week course with perfect feedback ratings, showcasing expertise in curriculum development and instructional delivery.  Designed and led over 16 interactive live lectures and code-along projects, enhancing student participation and creating a dynamic learning environment. Flatiron School | Remote Data Science Instructor  October 2019 - October 2021  Mentored and supervised over 60 students, helping them transition into successful data science careers with a high post-program employment rate.  Conducted weekly 90-minute study groups, accumulating over 270 hours of recorded lessons, significantly enhancing student comprehension and engagement.  Spearheaded the development and implementation of the \"Flex\" boot camp program, refining instructional design and delivery methods to meet diverse learning needs.  Created and maintained three student-progress-tracking Looker dashboards, providing real-time insights into student performance and facilitating timely interventions.  Guided students in selecting capstone project subjects, identifying job sectors of interest, and selecting appropriate data sources. Topics included time series analysis, NLP analysis, Covid cough classification (via Computer Vision),  and customer segmentation.  Offered bonus lectures on Object-Oriented Programming, dashboarding with Plotly and Dash, and advanced visualizations with matplotlib and seaborn.  Updated the entire lecture and activity content to accommodate a new teaching model, integrating recorded lectures from a national \"Central Lecturer\" with expanded hands-on activities. University of Maryland, School of Medicine | Baltimore, MD  Laboratory Manager  July 2017 - August 2018  Ensured full compliance with regulatory standards as the lab\\'s public representative, achieving a flawless inspection record.  Successfully represented lab and guided inspectors through 4 regulatory inspections from 2 agencies, demonstrating knowledge of and compliance with protocols and regulations.  Negotiated and finalized a $100,000 technical hardware contract with vendors, optimizing procurement processes and ensuring cost-effectiveness.  Managed and administered over 20 TBs of data storage systems, ensuring data accessibility, security, and efficient retrieval.  Overhauled mouse colony management procedures, reducing housing costs by 60%  (from approximately $3.8k/month to $1.5k/month ) through strategic resource allocation and process optimization.  Created and instituted new surgery logs to simplify record keeping while ensuring regularity compliance.  Managed lab supplies and equipment purchasing, maintaining appropriate documentation and financial records.  Consolidated and encrypted all sensitive and proprietary lab information vendor accounts, log-in information, and secure information into an encrypted data vault Postdoctoral Research Fellow  June 2015 - July 2017  Led neuroscience research using advanced techniques such as in vivo optogenetics and electrophysiology recordings, resulting in groundbreaking insights into neural functioning.  Developed approximately 30 custom analysis scripts in Matlab, NexScript, MedPC, and Arduino, enhancing data processing capabilities and facilitating comprehensive statistical analyses.  Mentored and guided a diverse team, fostering a collaborative learning environment and achieving research excellence (1 postdoc, 2 Ph.D. students, 3 lab techs, and 3 undergraduate volunteers.)  Demonstrated self-directed learning by mastering Matlab programming and creating custom-designed analysis programs for large datasets, streamlining data interpretation and enhancing research efficiency.  Researched the role of extended amygdala stress neurons in binge drinking, using multiple genetic tools and in vivo electrophysiology recordings.  Recorded changes in the activity of amygdala neurons during binge drinking. Identified neuron populations using a combination of single-unit recordings and optogenetic stimulation using targeted viral vectors.  Founded in vivo electrophysiology recordings and in vivo deep-brain structure calcium imaging in awake and behaving mice.  Directed several research projects simultaneously and managed a staff of postdoctoral fellows, technicians and student volunteers.  Programmed custom-designed analysis programs (~30) for large datasets in 4 programming languages (see skills).  Communicated research findings to mixed audiences with varying degrees of background knowledge and experience via seminars, presentations, as well as scientific posters.   Wrote user guides on various complicated technical procedures and techniques to train lab members and collaborators.  Trained and mentored 1 research fellow, 2 graduate students, 2 lab technicians, and 3 undergraduate volunteers on several complex technical procedures and the underlying scientific principles/theory.  Graduate Research Assistant \\nSeptember 2009 -  May 2015  Pioneered application of optogenetics with fast-scan cyclic voltammetry to discover previously unknown modulation of dopamine release via cholinergic interneurons.  Communicated research findings to audiences with varying degrees of background knowledge and familiarity in seminars, as well as scientific posters.  Trained and mentored 4 fellows, 3 graduate students, 5 lab technicians, 6 collaborators, and 1 undergraduate volunteer on various complex procedures and techniques.  Wrote user guides on various complex technical procedures and techniques to train current and future lab members Tulane University | New Orleans, LA Research Assistant January 2009  May 2009  Continued masters thesis study of the role of histone deacetylase (HDAC) inhibition in aggression under chronic stress.  Tested changes in stress hormones and protein expression in stressed rats with HDAC inhibition.  DISTINCTIONS & HONORS  Happy Camper Award, University of Maryland 2012  2013  Awarded to the Ph.D. student with the most positive attitude in the face of adversity, as voted by fellow students.  Summer Research Program Award, Tulane University  May 2008 to August 2008  Awarded for distinguished scientific research, including salary.  Tulane Distinguished Scholars, Tulane University  Fall 2004 - Fall 2007  Awarded for outstanding academic performance.  Tulane-Newcomb College Deans List  Fall 2004 - Fall 2005  Awarded for achieving a GPA greater than 3.7 EDUCATION Certificate of Completion, Data Science, Flatiron School, Online (February 2019 - August 2019)  Intensive 5-month program, approximately 50 hours per week Doctor of Philosophy, Neuroscience, University of Maryland, Baltimore, MD (August 2009 - May 2015)  Including specialized optional training: Entrepreneurship in Life Sciences course, Science Communication internship. Master of Science, Neuroscience, Tulane University, New Orleans, LA (January 2008 - December 2008) Bachelor of Science, Neuroscience (Sociology Minor), Tulane University, New Orleans, LA (August 2004 - December 2007) ADDITIONAL EXPERIENCE AND SERVICE University of Maryland | Baltimore, MD Science Communication Internship  Office of Public Affairs  June 2013 - September 2013  Selected as one of four founding members for an internship with Office of Public Affairs at the University of Maryland School of Medicine.  Trained in many aspects of university public affairs communications, relaying complex scientific material to a lay audience for both educational and promotional purposes.  Wrote press releases on university-associated research and novel findings to disseminate to inspire media coverage.  Wrote an in-depth interview featuring a university scientists high-impact research developing a novel anti-depressant.  Practiced live television interviews in the universitys satellite teleconferencing suite as both interviewer and interviewee.  Weekly training classes + independent assignments  5-10 hours/week.  Entrepreneurship in Life Sciences  Interdisciplinary Course January 2014 to June 2014  Trained by visiting experts in aspects of developing, promoting, and acquiring venture funding for a biomedical technology company.  \\n Wrote and presented funding proposals for venture capitalist firms for a resource-sharing/saving cloud-based software solution for universities.  Wrote a business plan, patent applications, and promotional materials.  Weekly classes + group work  10 hours/week.  Student Training Committee Member January 2013 - June 2015  Served graduate student community as proponent and liaison to the Ph.D. program administration.  Reformed graduate program policies and procedures for the mutual benefit of students and faculty.  Advised administration on student outreach and prospective student application/interview process.  Big Brother  Program in Neuroscience  August 2010 - December 2013  Volunteered as Big Brother mentor for 3 incoming doctoral students.  Advised little brothers on research lab choices, handling graduate coursework, and navigating university politics. Tulane University | New Orleans, LA Green Wave Ambassador Fall 2004  Spring 2005  Led guided tours of the campus for prospective students and their families, providing comprehensive information about academic programs, campus facilities, and student life.  Served as a host for visiting students, organizing and facilitating events to enhance their campus experience.  Engaged with visitors to answer questions, provide insights into the student experience, and assist with logistical needs.  Represented the university positively, contributing to recruitment and outreach efforts by sharing personal experiences and highlighting unique aspects of the campus community.  Student Calling Center Representative Fall 2005  Spring 2007  Contacted alumni to provide updates about university events, achievements, and developments.  Engaged alumni in meaningful conversations to foster a connection between them and the university.  Solicited donations, explaining the impact of their contributions on university programs, scholarships, and facilities.  Maintained accurate records of interactions and feedback, contributing to the continuous improvement of alumni relations and fundraising strategies.  PUBLICATIONS  Aroni S, Marino RAM, Girven KS, Irving JM, Cheer JF, Sparta DR. (2021) Repeated binge ethanol drinking enhances electrical activity of central amygdala corticotropin releasing factor neurons in vivo. Neuropharmacology.  Girven, K., Irving, J., Aroni, S., Sparta, D. The Role of Interconnections between the vBNST and insula in the modulation of reward processing. Manuscript in preparation.  Cachope, R., Mateo, Y., Mathur, B.N., Irving, J., Wang, H.-L., Morales, M., Lovinger, D.M., and Cheer, J.F. (2012). Selective Activation of Cholinergic Interneurons Enhances Accumbal Phasic Dopamine Release: Setting the Tone for Reward Processing. Cell Reports 2, 3341.  Mateo, Y., Atwood, B., Wang, H.-L., Zhang, S., Irving, J., Gildish, I., Cachope, R., Bellochio, L., Guzman, M., Morales, M., Cheer, J.F., and Lovinger, D.M. Cortical afferents expressing CB1 receptors control accumbal phasic dopamine release caused by selective activation of cholinergic interneurons. Manuscript submitted for publication. POSTER ABTRACTS  Irving, J.M., Maehler, C.J., Qadir, H., Girven, K.S., Sparta, D.R. Central Amygdala Corticotropin Releasing FactorNeurons Encode and Modulate Binge Drinking and Relapse American College of Neuropsychopharmacology Annual Meeting 2016.  Irving, J.M., Maehler, C.J., Girven, K.S., Sparta, D.R. The Role of Extended Amygdala Corticotropin Neurons in Binge Ethanol Drinking. Society for Neuroscience Annual Meeting 2016.  Irving, J.M., Maehler, C.J., Sparta, D.R. Optogenetic and Pharmacogenetic Interrogation of Central Amygdala Corticotropin Neurons on Binge Ethanol Drinking. Research Society on Alcoholism Annual Meeting 2016.  Irving, J.M., Gluskin, K.H., Cheer, J.F. Optogenetic activation of accumbal fast-spiking interneurons is reinforcing. Society for Neuroscience Annual Meeting 2014.  Kashtelyan, V., Irving, J.M., Fitoussi, A., Wang, H., Morales, M., Cheer, J.F. Conditional deletion of CB1 receptors on cholinergic terminals and its functional consequences. Society for Neuroscience Meeting Annual 2014.  Irving, J.M., Mateo, Y., Cheer, J.F. Optogenetic Stimulation of Cholinergic Interneurons in the Nucleus Accumbens Causes Dopamine Release. Society for Neuroscience Meeting 2011. \\n Irving, J.M., Mateo, Y., Cheer, J.F. Endogenous Activity of Cholinergic Interneurons in the Nucleus Accumbens is Sufficient to Evoke Dopamine Release. Graduate Research Conference 2012.  PROFERRED COMMUNICATIONS   Irving, J.M., Sparta, D.R. Modulation of Binge Drinking by Central Amygdala Corticotropin-Releasing Factor Neurons. Department of Anatomy & Neurobiology, Second-Monday Program, University of Maryland School of Medicine, 2016.  Irving, J.M., Cheer, J.F. The Role of Local Activity of the Nucleus Accumbens in Reward: Interneurons and Gamma Oscillations,, Public Dissertation Defense, 2016.  Irving, J.M..Cheer, J.F., Selective activation of cholinergic interneurons enhances accumbal phasic dopamine release: setting the tone for reward processing., Department of Anatomy & Neurobiology, Second-Monday Program, University of Maryland, Baltimore, 2012.  Irving, J.M..Cheer, J.F., Selective activation of cholinergic interneurons enhances accumbal phasic dopamine release: setting the tone for reward processing., Program in Neuroscience Retreat, Notre Dame of Maryland, 2012.  Irving, J.M., Cheer, J.F., The Role of CB1 Receptors on GABAergic Interneurons of the Nucleus Accumbens in Motivated-Behavior and Modulation of Accumbal Gamma Rhythms University of Maryland, Baltimore, Thesis Proposal, 2014.  Irving. J.M., Cheer, J.F., The Reinforcing Effects of Gamma-Frequency Stimulation of Accumbal Parvalbumin Interneurons and the Role of CB1 Receptors, University of Pittsburgh, Department of Psychiatry, 2015. DATA SCIENCE PROJECTS Computer Vision Classification of American Sign Language  GitHub Link Applied tensorflow and transfer learning to classify an image as the correct letter of the ASL alphabet.  COMING SOON AI Job Application Assistant  App Link  GitHub Link Developed a Streamlit application to assist job seekers with resumes and cover letters  Developed a Streamlit application to assist job seekers by analyzing resumes and job listings using AI.  Integrated ChatGPT for tailored advice, resume improvements, and cover letter creation.  Automated job application process with AI-driven insights and recommendations.  Enhanced user experience with an interactive and user-friendly interface.  Provided actionable advice to job seekers, improving their chances of success.  Key Technologies Used: Streamlit, LangChain, OpenAI API  NLP Analysis of Amazon Reviews + AI Recommendations - GitHub Link Natural Language Processing Analysis, Modeling, and Deployment with Actionable Insights  Designed and deployed a user-centric Streamlit dashboard, integrating live sentiment predictions and interactive analysis of trends to guide strategic decision-making.  Conducted sentiment analysis on over 5 million Amazon Grocery & Gourmet Food reviews, utilizing NLP and machine learning techniques (Logistic Regression, Tf-idf vectorization) to identify key factors affecting customer satisfaction and achieve 95% accuracy in sentiment classification.  Employed Hugging Face transformers and Lang Chain/ChatGPT within the dashboard with a vectorized database used for summarization and insights, translating vast consumer feedback into actionable product enhancement strategies.  Key Technologies Used: Python, Hugging Face, OpenAI API, LangChain, spacy, scikit-learn. How to Make a Successful Movie  GitHub Link Constructing and analyzing an extensive movie database with hypothesis-testing insights + Tableau Dashboard  Integrated and normalized datasets from IMDB and TMDB API for comprehensive movie analysis.  Engineered a MySQL database on AWS RDS for robust data storage and retrieval.  Designed an interactive Tableau dashboard to communicate findings to stakeholders, enhancing decision-making processes (see GitHub link).  Applied A/B Testing to identify key factors influencing movie performance and success to provide business recommendations on what movies to create for high box office returns on factors like MPAA rating, runtime, and genre.  Key Technologies Used: Python, SQL, Tableau, TMDB API, Pandas, sqlalchemy, MySQL Workbench, statsmodels, AWS RDS How to Spot a Troll  GitHub Link Classifying Russian Troll Tweets vs Authentic Tweets  Performed EDA on 3 million tweets from accounts from the Internet Research Agency (the Russian Troll Farm) to identify an appropriate control dataset (which time period and content to extract to construct control group).   Harvested control tweets for use in supervised learning using the TwitterAPI and TweetDeck to target the top 40 most frequent mentions, which produced 40,000 control tweets.   Conducted natural language processing (NLP) on 80,000 tweets using nltk, Word2Vec, and Keras to tokenize, vectorize, and train word embeddings for Logistic Regression and multiple Keras Neural Networks.   Final models achieved 90% accuracy with a dense neural network (training time: 32 sec) and 88% accuracy using Logistic Regression (training time: 0.6 sec)   Key Technologies Used: Python, Tweepy, Neural Networks (Tensorflow & Keras),  \\nRecidivism Risk Assessment  GitHub Link Classifying which released prisoners in Iowa will return to a life of crime using Next-Gen Gradient Boosted Trees  Developed a predictive model to classify which released prisoners in Iowa are likely to return to crime using Gradient Boosted Trees. with over 70% accuracy (via scikit-learn and Catboost).  Researched Iowa\\'s state sentencing guidelines and sentencing enhancements to engineer new numerical features to capture the severity of the crimes committed and the duration of sentences.  Achieved high recall rates for predicting recidivism using XGBoost.  Identified key features influencing recidivism, such as age, release type, and offense subtype.  Provided actionable insights and recommendations to the Iowa Department of Corrections.  Implemented various machine learning models and utilized SHAP for feature importance analysis.  Key Technologies: Python, Jupyter Notebooks, XGBoost, CatBoost, SHAP, SMOTE   Forecasting Stock Market Fluctuations with Trumps Tweets  GitHub Link Combining Natural Language Processing of Trumps Tweets with Time Series Forecasting S&P500 Price   Employed Natural Language Processing with nltk and word embeddings (both Word2Vec & GloVe pre-trained) to classify Trumps tweets by S&P 500 price change (increase/decrease/no change) 60 minutes after tweeting.  Compared tweet NLP classification models using Keras neural networks (LSTM, GRU, and CNN) to predict the direction of stock market price change from NLP alone.  Used Keras neural networks for time series forecasting of S&P 500 price.  Compared multiple data sources: price alone, price + 7 market technical indicators.  Compared forecasting models: Keras LSTM vs. XGBoost Regressor.  Final model stacked NLP classification predictions with S&P 500 time series forecasting and additional tweet features (sentiment analysis with Vader, number of retweets/favorites, uppercase-to-lowercase ratio). PROFESSIONAL SKILLS Programming: Python, OOP, SQL (MySQL, SQLAlchemy), MATLAB, HTML/CSS, Git/GitHub, NexScript, MedState Notation Data Analysis: ETL (numpy, pandas), AB Testing (scipy, statsmodels), Machine Learning (scikit-learn, Catboost, XGBoost), Deep Learning (Tensorflow, Keras) Natural Language Processing: nltk, spaCy, Tensorflow, HuggingFace transformers, LLMs(OpenAI, LangChain) Visualization/Dashboarding: Plotly/Dash, Tableau, Streamlit Dashboards & Deployment, Seaborn/Matplotlib, Looker Software: Adobe Illustrator, Adobe Photoshop, GraphPad Prism, SPSS, Microsoft Office, VS Code, Jupyter Notebook/Lab, Google Suite, Plexon OfflineSorter, NeuroExplorer  LEADERSHIP & COMMUNITY INVOLVEMENT SECTION IS WORK-IN-PROGRESS  Key Club Lt. Governor \\n', 'job_listing': 'Robert Half\\nSenior Data Scientist\\n$115K/yr - $173K/yrMid-Senior level\\n10,001+ employees  Staffing and Recruiting\\n2 company alumni work here3 school alumni work here\\n3 of 3 skills match your profile - you may be a good fit\\nApply SavedCalifornia, United States4 hours ago29 applicants\\nRemoteFull-time\\nAm I a good fit for this job? How can I best position myself fo\\nMeet the hiring team\\nKelli Griffin3rd\\nLead Talent Acquisition Partner\\nJob posterMessage\\nAbout the job\\nReady to revolutionize the future of data-driven decision-making? Join our\\npioneering Data Science team as we embark on an exciting journey to unlock\\ninsights, drive innovation, and shape the landscape of our organization\\'s success.\\nIf you\\'re passionate about leveraging cutting-edge generative AI technologies\\nand transforming raw data into actionable insight, we want you on our team!\"\\nThe Senior Data Scientist will be responsible for leading advanced data analytics\\nprojects, leveraging Azure and Microsoft data services. This role demands a deep\\nunderstanding of data science methodologies, machine learning algorithms, and\\nbig data technologies. The incumbent will work closely with cross-functional\\nteams to understand business needs and formulate and execute data science\\nsolutions that drive significant business impact.\\nKey Responsibilities:\\nData Analytics and Modeling:\\nDevelop and implement advanced predictive models and statistical\\nanalysis using a variety of machine learning algorithms.\\nSuggest algorithms or models appropriate for specific use cases and\\napplications.\\nAnalyze and extract relevant information from large amounts of historical\\nbusiness data to help automate and optimize key processes with business\\nteams.\\nApply technical solutions to business problems and questions using large\\nscale data analytics and machine learning; create highly calibrated\\nsolutions for business problems.\\nWork closely with software engineering teams to drive real-time model\\nexperiments, implementations and new feature creations.\\nContinuously evaluate and refine models based on performance metrics.\\nUtilize cloud technologies such as Azure Machine Learning, Azure\\nDatabricks, and other Microsoft data services for data processing, modelHomeMy NetworkJobsMessagingNotificationsMe\\n For BusinessLear\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 1/7\\nSee lessbuilding, and deployment.\\nLarge Language Model Fine-tuning:\\nEnhance and evolve the performance of large language models by\\nrefining their capabilities through targeted fine-tuning.\\nSteer both the research trajectory and the practical engineering efforts of\\nthe team.\\nFormulate and enact algorithms for model enhancement, tweak critical\\nhyperparameters, and heighten overall model efficiency.\\nGuarantee the integrity and relevance of datasets by conducting thorough\\npreprocessing and data analysis within the fine-tuning workflow.\\nConduct assessments on fine-tuned models, making necessary\\nmodifications to boost their effectiveness.\\nFoster a cooperative environment within the team, providing guidance to\\npeers to ensure a smooth fine-tuning operation that yields superior\\nresults.\\nStay at the forefront of advancements in large language model\\ntechnologies and applications, perpetually refining technical expertise in\\nmodel fine-tuning.\\nData Management and Strategy:\\nCollaborate with IT and data engineering teams in an enterprise setting to\\nintegrate data science solutions into the broader tech stack and data\\nstrategy.\\nBusiness Collaboration and Insights:\\nWork closely with business stakeholders to identify opportunities for\\nleveraging company data to drive business solutions.\\nTranslate complex data-driven findings into actionable business insights\\nand communicate these effectively to non-technical stakeholders.\\nResearch and Development:\\nStay abreast of industry trends and advancements in data science and\\nAzure technologies.\\nConduct research to explore new methodologies and technologies that\\ncan enhance the organization\\'s data analytics capabilities.\\nPreferred Qualifications and Skills:\\nBachelor\\'s degree in Statistics, Computer Science, Mathematics or\\nequivalent required; Master\\'s or PhD highly preferred\\n5 years of professional experience in data science, with a record in\\ndesigning and implementing large-scale data science projects.\\n5 years of industry experience in predictive modeling and large data\\nanalysis\\nKnowledge of open-source large language models and experience with\\nevaluating and recommending appropriate models for specific use cases.\\n3+ years of experience in using big data platforms and technologies such\\nas Hadoop, Azure data lake, Azure Cosmos DB, Pig, Hive, HBase, etc.\\n3+ years of hands-on experience in statistical modeling, data mining,\\nlarge data analysis and predictive modeling; text mining a major plus\\n3+ years of experience in regression, classification and clustering\\nmethods such as GLM, LR, SVM, LVQ, SOM, Neural Networks\\nExperience with two or more of the following: Python, PERL, Matlab or\\nScala\\nExpertise in various machine learning frameworks and libraries (e.g.,\\nTensorFlow, PyTorch, Scikit-learn).\\nExcellent analytical, problem-solving, and communication skills.\\nExcellent communication skills, with a proven ability to translate technical\\nfindings into business recommendations and strategies.\\nCertifications in Azure data services or advanced analytics preferred\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 2/7\\nSet alert for similar jobs\\nData Scientist, California, United StatesSet alert\\nEmployer-provided\\nPay range in California, United States\\nExact compensation may vary based on skills, experience, and location.\\nBase salary\\n$115,000/yr - $173,000/yr\\nFeatured benefits\\nMedical insurance\\nVision insurance\\nDental insurance\\n401(k)\\nTuition assistance\\nQualifications\\n3 of 3 skills match your profile - you may be a good fit\\nSkills added by the job poster\\nBig Data  Large Language Models (LLM)  Natural Language Processing (NLP)\\nAdditional skills among applicants\\nData Analysis  Data Science  Data Visualization  Machine Learning  Microsoft\\nPower BI  Python (Programming Language)  R (Programming Language)  SQL \\nShow qualification details\\nPut your best foot forward with your application\\nHire a resume writer\\nGet a resume review\\nSee how you compare to other applicants\\nApplicants for this job\\n29Applicants\\n29Applicants in the past day\\nApplicant seniority level\\n15 Entry level applicants\\n10 Senior level applicants\\n1 Director level applicant Youve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 3/7\\nApplicant education level\\n19%have a Doctor of Philosophy (Similar to you)\\n59%have a Master\\'s Degree\\n15%have a Bachelor\\'s Degree\\n7%have other degrees\\nApplicants are in these locations\\n1-5 applicants\\nNew York City Metropolitan\\nArea\\n1-5 applicants\\nGreater Pittsburgh Region\\n1-5 applicants\\nDallas-Fort Worth Metroplex\\nSee if Robert Half is hiring people like you\\nThe latest hiring trends.\\n29,307\\nTotal employees3%\\nCompany-wide\\n2 year growth2%\\nEngineering\\n2 year growth\\nMedian employee tenure 6 yearsMay 2022 Nov 2022 May 2023 Nov 2023 May 202410,00020,00030,00040,000\\nRobert Half hires candidates from some of these companies and schools\\nRobert Half hired 2 people\\nfrom Coding Dojo.See all\\nRobert Half hired 3 people from\\nFlatiron School.See all\\nEngineering hires at Robert Half came\\nfrom these companies and more.Engineering hires at Robert Half came\\nfrom these schools and more.\\nReset map\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 4/7\\nMore jobsShow more Premium insightsSee more companies See more schools\\nAbout the company\\nRobert Half\\n3,147,224 followersFollow\\nStaffing and Recruiting10,001+ employees29,320 on LinkedIn\\nTrending employee content PreviousNext\\nShow more\\nRobert Half, the worlds first and largest specialized talent solutions firm,\\nconnects opportunities at great companies with highly skilled job seekers. We\\noffer contract, temporary and permanent placement solutions for roles in financshow more\\nInterested in working with us in the future?\\nPrivately share your profile with our recruiters  youll be noted as\\nexpressing interest for up to a year.Learn more\\nIm interested\\nLead Data Scientist\\nCigniti Technologies\\nUnited States (Remote)\\nActively recruiting\\n4 weeks agoEasy ApplySenior Data Scientist\\nDTN\\nUnited States (Remote)\\nActively recruiting\\n2 weeks ago\\nData Scientist\\nQuantum World Technologies\\nUnited States (Remote)\\nActively recruiting\\nSr. Data Scientist\\nAKASA\\nUnited States (Remote)\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 5/7\\nSee more jobs like this10 minutes agoEasy Apply 2 weeks ago\\nSenior Data Scientist\\nPhreesia\\nUnited States (Remote)\\nActively recruiting\\n3 weeks agoSr. Data Scientist\\nAppFolio\\nUnited States (Remote)\\nActively recruiting\\n1 week ago\\nSenior Data Scientist,\\nProduct\\nUniswap Labs\\nNew York, NY (Remote)\\nActively recruiting\\n1 week agoSenior Data Scientist\\nAustin Fraser\\nUnited States (Remote)\\nActively recruiting\\n6 days agoEasy Apply\\nSenior Data Scientist\\nWebflow\\nUnited States (Remote)\\n1 company alum works here\\n2 days agoSenior Data Scientist\\nXOi\\nUnited States (Remote)\\n2 weeks ago\\nLead Data Scientist\\nLittle Place Labs\\nUnited States (Remote)\\n1 month agoEasy ApplyStaff Data Scientist\\nDemandbase\\nUnited States (Remote)\\n3 school alumni work here\\n3 weeks ago\\nLearn skills to get a new job with these courses\\n135,378 viewers\\nThe New Rules of Work\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 6/7\\nAbout Accessibility Talent Solutions\\nCommunity Guidelines Careers Marketing Solutions\\nAd Choices Advertising\\nSales Solutions Mobile Small Business\\nSafety CenterQuestions?\\nVisit our Help Center.\\nManage your account and privacy\\nGo to your Settings.\\nRecommendation transparency\\nLearn more about Recommended Content.Select Language\\nLinkedIn Corporation  2024282,784 viewers\\nShow more on LinkedIn Learning\\nDeveloping Your Professional Image in a New Job\\nLooking for talent?Post a job\\nPrivacy & Terms\\nEnglish (English)\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 7/7\\n'}, template='\\n    You are a a specialized career coach for the {sector}, focused on delivering tailored, concise job application advice and practice.\\n    You are proficient in resume analysis, cover letter guidance, and interview preparation, adapting to each user\\'s unique requirements. \\n    You maintain a professional, {model_tone} tone, ensuring advice is efficient, clear, and easily understandable, with the goal of aiding their career progression. \\n    Ask the user for their resume and job listing if not provided and they are needed to answer .\" \\n    \\n    Use the following context, if provided, to help answer the questions:\\n    \\n    -------------\\n    My Resume:\\n    {resume}\\n    \\n    -------------\\n    The job listing:\\n    {job_listing}\\n    ')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, PromptTemplate, MessagesPlaceholder\n",
    "\n",
    "#Custom tools prompt\n",
    "system_prompt = get_system_prompt_formatted(sector=\"data science and analytics\",\n",
    "                            model_tone='friendly and encouraging',\n",
    "                            resume=long_resume, job_listing=job_text_senior_rh,\n",
    "                            return_formatted=True)\n",
    "\n",
    "manual_tools_prompt_messages = [SystemMessagePromptTemplate(prompt=system_prompt),\n",
    "                       MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
    "                       HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
    "                       MessagesPlaceholder(variable_name='agent_scratchpad')]\n",
    "\n",
    "manual_tools_prompt  = ChatPromptTemplate.from_messages(manual_tools_prompt_messages)\n",
    "manual_tools_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agent_scratchpad', 'input']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_tools_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'chat_history': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], partial_variables={'sector': 'data science and analytics', 'model_tone': 'friendly and encouraging', 'resume': '[LONG MASTER RESUME]  James M. Irving, Ph.D. 8222 Spadderdock Way, Laurel, MD, 20724 | (518) 322-6750 | james.irving.phd@gmail.com |  LinkedIn: james-irving-phd | GitHub: https://github.com/jirvingphd  SUMMARY V1 Innovative and enterprising data scientist with extensive experience in applying advanced data science techniques to real-world problems. Known for excellent problem-solving skills and the ability to rapidly master and implement new technologies. Committed to leveraging data to drive innovation and support data-driven decision-making. SUMMARY V2 Neuroscientist-turned-data scientist with an insatiable curiosity and a proven track record in mastering cutting-edge technologies. Exceptional communication and interpersonal skills paired with a robust history of problem-solving and critical thinking. Proven ability to self-teach complex concepts and technologies, including in vivo electrophysiology recordings and analysis. Successfully trained generations of collaborators, technicians, research fellows, and undergraduate volunteers by customizing the training to match the specific trainees experience and knowledge. COMPETENCIES  Data Analysis, Statistical Modeling, Machine Learning, Data Visualization  Experimental Design, Quantitative Research Methods, Time Series Analysis, Signal Processing  Cognitive Neuroscience, Behavioral Analysis, Database Management, Pattern Recognition  Python Programming, Deep Learning, Natural Language Processing, AI/LLM Implementation  Adaptive Communication Style, Problem-Solving & Critical Thinking EXPERIENCE  Coding Dojo | Remote Curriculum Writer - Data Science March 2023 - January 2024  Developed and delivered advanced courses in Time Series Modeling, NLP, and Model Deployment, enhancing data science skills for over 100 professionals.  Expanded a 16-week boot camp to a 24-week comprehensive training program, increasing curriculum depth by 50%, which boosted learner engagement and program satisfaction.  Implemented project management and automation tools using Monday.com, optimizing workflow efficiency and resolving operational bottlenecks.  Developed and implemented Monday.com boards, including public forms and executive-facing Gantt charts, to automate internal workflows and streamline curriculum management, resolving over 100 issues.  Integrated cutting-edge technologies like APIs, Web Scraping, and Computer Vision into the curriculum, aligning educational content with evolving industry standards and practical application needs.  Developed a workflow and process to test and identify datasets for curriculum use, including template Python notebooks for preprocessing, visualization, EDA, modeling, and interpretations.  Constructed the Dojo Environment Setup for Students, ensuring compatibility with various OS and facilitating smooth installation of necessary tools and libraries.  Created and maintained a GitHub Organization for curriculum-related activities, solutions, and packages, providing a centralized resource hub for students and instructors.  Designed an extended case study for the 6-month curriculum, applying all phases of CRISP-DM to a specially constructed subset of the Ames housing dataset, enhancing practical application and understanding of the data science lifecycle.  Achieved tight deadlines throughout the year despite unexpected demands related to getting the curriculum accredited ensuring timely delivery and high-quality content for the program.  Data Science Instructor November 2021 - March 2023  Achieved high Net Promoter Scores (NPS) exceeding 90% through engaging and interactive live lectures, demonstrating strong communication and pedagogical skills.  Revolutionized administrative workflow by automating tasks, resulting in a 99% reduction in student onboarding timefrom 5 hours to just 2 minutesdramatically enhancing operational efficiency and productivity. \\n Developed and delivered a highly acclaimed 4-week course with perfect feedback ratings, showcasing expertise in curriculum development and instructional delivery.  Designed and led over 16 interactive live lectures and code-along projects, enhancing student participation and creating a dynamic learning environment. Flatiron School | Remote Data Science Instructor  October 2019 - October 2021  Mentored and supervised over 60 students, helping them transition into successful data science careers with a high post-program employment rate.  Conducted weekly 90-minute study groups, accumulating over 270 hours of recorded lessons, significantly enhancing student comprehension and engagement.  Spearheaded the development and implementation of the \"Flex\" boot camp program, refining instructional design and delivery methods to meet diverse learning needs.  Created and maintained three student-progress-tracking Looker dashboards, providing real-time insights into student performance and facilitating timely interventions.  Guided students in selecting capstone project subjects, identifying job sectors of interest, and selecting appropriate data sources. Topics included time series analysis, NLP analysis, Covid cough classification (via Computer Vision),  and customer segmentation.  Offered bonus lectures on Object-Oriented Programming, dashboarding with Plotly and Dash, and advanced visualizations with matplotlib and seaborn.  Updated the entire lecture and activity content to accommodate a new teaching model, integrating recorded lectures from a national \"Central Lecturer\" with expanded hands-on activities. University of Maryland, School of Medicine | Baltimore, MD  Laboratory Manager  July 2017 - August 2018  Ensured full compliance with regulatory standards as the lab\\'s public representative, achieving a flawless inspection record.  Successfully represented lab and guided inspectors through 4 regulatory inspections from 2 agencies, demonstrating knowledge of and compliance with protocols and regulations.  Negotiated and finalized a $100,000 technical hardware contract with vendors, optimizing procurement processes and ensuring cost-effectiveness.  Managed and administered over 20 TBs of data storage systems, ensuring data accessibility, security, and efficient retrieval.  Overhauled mouse colony management procedures, reducing housing costs by 60%  (from approximately $3.8k/month to $1.5k/month ) through strategic resource allocation and process optimization.  Created and instituted new surgery logs to simplify record keeping while ensuring regularity compliance.  Managed lab supplies and equipment purchasing, maintaining appropriate documentation and financial records.  Consolidated and encrypted all sensitive and proprietary lab information vendor accounts, log-in information, and secure information into an encrypted data vault Postdoctoral Research Fellow  June 2015 - July 2017  Led neuroscience research using advanced techniques such as in vivo optogenetics and electrophysiology recordings, resulting in groundbreaking insights into neural functioning.  Developed approximately 30 custom analysis scripts in Matlab, NexScript, MedPC, and Arduino, enhancing data processing capabilities and facilitating comprehensive statistical analyses.  Mentored and guided a diverse team, fostering a collaborative learning environment and achieving research excellence (1 postdoc, 2 Ph.D. students, 3 lab techs, and 3 undergraduate volunteers.)  Demonstrated self-directed learning by mastering Matlab programming and creating custom-designed analysis programs for large datasets, streamlining data interpretation and enhancing research efficiency.  Researched the role of extended amygdala stress neurons in binge drinking, using multiple genetic tools and in vivo electrophysiology recordings.  Recorded changes in the activity of amygdala neurons during binge drinking. Identified neuron populations using a combination of single-unit recordings and optogenetic stimulation using targeted viral vectors.  Founded in vivo electrophysiology recordings and in vivo deep-brain structure calcium imaging in awake and behaving mice.  Directed several research projects simultaneously and managed a staff of postdoctoral fellows, technicians and student volunteers.  Programmed custom-designed analysis programs (~30) for large datasets in 4 programming languages (see skills).  Communicated research findings to mixed audiences with varying degrees of background knowledge and experience via seminars, presentations, as well as scientific posters.   Wrote user guides on various complicated technical procedures and techniques to train lab members and collaborators.  Trained and mentored 1 research fellow, 2 graduate students, 2 lab technicians, and 3 undergraduate volunteers on several complex technical procedures and the underlying scientific principles/theory.  Graduate Research Assistant \\nSeptember 2009 -  May 2015  Pioneered application of optogenetics with fast-scan cyclic voltammetry to discover previously unknown modulation of dopamine release via cholinergic interneurons.  Communicated research findings to audiences with varying degrees of background knowledge and familiarity in seminars, as well as scientific posters.  Trained and mentored 4 fellows, 3 graduate students, 5 lab technicians, 6 collaborators, and 1 undergraduate volunteer on various complex procedures and techniques.  Wrote user guides on various complex technical procedures and techniques to train current and future lab members Tulane University | New Orleans, LA Research Assistant January 2009  May 2009  Continued masters thesis study of the role of histone deacetylase (HDAC) inhibition in aggression under chronic stress.  Tested changes in stress hormones and protein expression in stressed rats with HDAC inhibition.  DISTINCTIONS & HONORS  Happy Camper Award, University of Maryland 2012  2013  Awarded to the Ph.D. student with the most positive attitude in the face of adversity, as voted by fellow students.  Summer Research Program Award, Tulane University  May 2008 to August 2008  Awarded for distinguished scientific research, including salary.  Tulane Distinguished Scholars, Tulane University  Fall 2004 - Fall 2007  Awarded for outstanding academic performance.  Tulane-Newcomb College Deans List  Fall 2004 - Fall 2005  Awarded for achieving a GPA greater than 3.7 EDUCATION Certificate of Completion, Data Science, Flatiron School, Online (February 2019 - August 2019)  Intensive 5-month program, approximately 50 hours per week Doctor of Philosophy, Neuroscience, University of Maryland, Baltimore, MD (August 2009 - May 2015)  Including specialized optional training: Entrepreneurship in Life Sciences course, Science Communication internship. Master of Science, Neuroscience, Tulane University, New Orleans, LA (January 2008 - December 2008) Bachelor of Science, Neuroscience (Sociology Minor), Tulane University, New Orleans, LA (August 2004 - December 2007) ADDITIONAL EXPERIENCE AND SERVICE University of Maryland | Baltimore, MD Science Communication Internship  Office of Public Affairs  June 2013 - September 2013  Selected as one of four founding members for an internship with Office of Public Affairs at the University of Maryland School of Medicine.  Trained in many aspects of university public affairs communications, relaying complex scientific material to a lay audience for both educational and promotional purposes.  Wrote press releases on university-associated research and novel findings to disseminate to inspire media coverage.  Wrote an in-depth interview featuring a university scientists high-impact research developing a novel anti-depressant.  Practiced live television interviews in the universitys satellite teleconferencing suite as both interviewer and interviewee.  Weekly training classes + independent assignments  5-10 hours/week.  Entrepreneurship in Life Sciences  Interdisciplinary Course January 2014 to June 2014  Trained by visiting experts in aspects of developing, promoting, and acquiring venture funding for a biomedical technology company.  \\n Wrote and presented funding proposals for venture capitalist firms for a resource-sharing/saving cloud-based software solution for universities.  Wrote a business plan, patent applications, and promotional materials.  Weekly classes + group work  10 hours/week.  Student Training Committee Member January 2013 - June 2015  Served graduate student community as proponent and liaison to the Ph.D. program administration.  Reformed graduate program policies and procedures for the mutual benefit of students and faculty.  Advised administration on student outreach and prospective student application/interview process.  Big Brother  Program in Neuroscience  August 2010 - December 2013  Volunteered as Big Brother mentor for 3 incoming doctoral students.  Advised little brothers on research lab choices, handling graduate coursework, and navigating university politics. Tulane University | New Orleans, LA Green Wave Ambassador Fall 2004  Spring 2005  Led guided tours of the campus for prospective students and their families, providing comprehensive information about academic programs, campus facilities, and student life.  Served as a host for visiting students, organizing and facilitating events to enhance their campus experience.  Engaged with visitors to answer questions, provide insights into the student experience, and assist with logistical needs.  Represented the university positively, contributing to recruitment and outreach efforts by sharing personal experiences and highlighting unique aspects of the campus community.  Student Calling Center Representative Fall 2005  Spring 2007  Contacted alumni to provide updates about university events, achievements, and developments.  Engaged alumni in meaningful conversations to foster a connection between them and the university.  Solicited donations, explaining the impact of their contributions on university programs, scholarships, and facilities.  Maintained accurate records of interactions and feedback, contributing to the continuous improvement of alumni relations and fundraising strategies.  PUBLICATIONS  Aroni S, Marino RAM, Girven KS, Irving JM, Cheer JF, Sparta DR. (2021) Repeated binge ethanol drinking enhances electrical activity of central amygdala corticotropin releasing factor neurons in vivo. Neuropharmacology.  Girven, K., Irving, J., Aroni, S., Sparta, D. The Role of Interconnections between the vBNST and insula in the modulation of reward processing. Manuscript in preparation.  Cachope, R., Mateo, Y., Mathur, B.N., Irving, J., Wang, H.-L., Morales, M., Lovinger, D.M., and Cheer, J.F. (2012). Selective Activation of Cholinergic Interneurons Enhances Accumbal Phasic Dopamine Release: Setting the Tone for Reward Processing. Cell Reports 2, 3341.  Mateo, Y., Atwood, B., Wang, H.-L., Zhang, S., Irving, J., Gildish, I., Cachope, R., Bellochio, L., Guzman, M., Morales, M., Cheer, J.F., and Lovinger, D.M. Cortical afferents expressing CB1 receptors control accumbal phasic dopamine release caused by selective activation of cholinergic interneurons. Manuscript submitted for publication. POSTER ABTRACTS  Irving, J.M., Maehler, C.J., Qadir, H., Girven, K.S., Sparta, D.R. Central Amygdala Corticotropin Releasing FactorNeurons Encode and Modulate Binge Drinking and Relapse American College of Neuropsychopharmacology Annual Meeting 2016.  Irving, J.M., Maehler, C.J., Girven, K.S., Sparta, D.R. The Role of Extended Amygdala Corticotropin Neurons in Binge Ethanol Drinking. Society for Neuroscience Annual Meeting 2016.  Irving, J.M., Maehler, C.J., Sparta, D.R. Optogenetic and Pharmacogenetic Interrogation of Central Amygdala Corticotropin Neurons on Binge Ethanol Drinking. Research Society on Alcoholism Annual Meeting 2016.  Irving, J.M., Gluskin, K.H., Cheer, J.F. Optogenetic activation of accumbal fast-spiking interneurons is reinforcing. Society for Neuroscience Annual Meeting 2014.  Kashtelyan, V., Irving, J.M., Fitoussi, A., Wang, H., Morales, M., Cheer, J.F. Conditional deletion of CB1 receptors on cholinergic terminals and its functional consequences. Society for Neuroscience Meeting Annual 2014.  Irving, J.M., Mateo, Y., Cheer, J.F. Optogenetic Stimulation of Cholinergic Interneurons in the Nucleus Accumbens Causes Dopamine Release. Society for Neuroscience Meeting 2011. \\n Irving, J.M., Mateo, Y., Cheer, J.F. Endogenous Activity of Cholinergic Interneurons in the Nucleus Accumbens is Sufficient to Evoke Dopamine Release. Graduate Research Conference 2012.  PROFERRED COMMUNICATIONS   Irving, J.M., Sparta, D.R. Modulation of Binge Drinking by Central Amygdala Corticotropin-Releasing Factor Neurons. Department of Anatomy & Neurobiology, Second-Monday Program, University of Maryland School of Medicine, 2016.  Irving, J.M., Cheer, J.F. The Role of Local Activity of the Nucleus Accumbens in Reward: Interneurons and Gamma Oscillations,, Public Dissertation Defense, 2016.  Irving, J.M..Cheer, J.F., Selective activation of cholinergic interneurons enhances accumbal phasic dopamine release: setting the tone for reward processing., Department of Anatomy & Neurobiology, Second-Monday Program, University of Maryland, Baltimore, 2012.  Irving, J.M..Cheer, J.F., Selective activation of cholinergic interneurons enhances accumbal phasic dopamine release: setting the tone for reward processing., Program in Neuroscience Retreat, Notre Dame of Maryland, 2012.  Irving, J.M., Cheer, J.F., The Role of CB1 Receptors on GABAergic Interneurons of the Nucleus Accumbens in Motivated-Behavior and Modulation of Accumbal Gamma Rhythms University of Maryland, Baltimore, Thesis Proposal, 2014.  Irving. J.M., Cheer, J.F., The Reinforcing Effects of Gamma-Frequency Stimulation of Accumbal Parvalbumin Interneurons and the Role of CB1 Receptors, University of Pittsburgh, Department of Psychiatry, 2015. DATA SCIENCE PROJECTS Computer Vision Classification of American Sign Language  GitHub Link Applied tensorflow and transfer learning to classify an image as the correct letter of the ASL alphabet.  COMING SOON AI Job Application Assistant  App Link  GitHub Link Developed a Streamlit application to assist job seekers with resumes and cover letters  Developed a Streamlit application to assist job seekers by analyzing resumes and job listings using AI.  Integrated ChatGPT for tailored advice, resume improvements, and cover letter creation.  Automated job application process with AI-driven insights and recommendations.  Enhanced user experience with an interactive and user-friendly interface.  Provided actionable advice to job seekers, improving their chances of success.  Key Technologies Used: Streamlit, LangChain, OpenAI API  NLP Analysis of Amazon Reviews + AI Recommendations - GitHub Link Natural Language Processing Analysis, Modeling, and Deployment with Actionable Insights  Designed and deployed a user-centric Streamlit dashboard, integrating live sentiment predictions and interactive analysis of trends to guide strategic decision-making.  Conducted sentiment analysis on over 5 million Amazon Grocery & Gourmet Food reviews, utilizing NLP and machine learning techniques (Logistic Regression, Tf-idf vectorization) to identify key factors affecting customer satisfaction and achieve 95% accuracy in sentiment classification.  Employed Hugging Face transformers and Lang Chain/ChatGPT within the dashboard with a vectorized database used for summarization and insights, translating vast consumer feedback into actionable product enhancement strategies.  Key Technologies Used: Python, Hugging Face, OpenAI API, LangChain, spacy, scikit-learn. How to Make a Successful Movie  GitHub Link Constructing and analyzing an extensive movie database with hypothesis-testing insights + Tableau Dashboard  Integrated and normalized datasets from IMDB and TMDB API for comprehensive movie analysis.  Engineered a MySQL database on AWS RDS for robust data storage and retrieval.  Designed an interactive Tableau dashboard to communicate findings to stakeholders, enhancing decision-making processes (see GitHub link).  Applied A/B Testing to identify key factors influencing movie performance and success to provide business recommendations on what movies to create for high box office returns on factors like MPAA rating, runtime, and genre.  Key Technologies Used: Python, SQL, Tableau, TMDB API, Pandas, sqlalchemy, MySQL Workbench, statsmodels, AWS RDS How to Spot a Troll  GitHub Link Classifying Russian Troll Tweets vs Authentic Tweets  Performed EDA on 3 million tweets from accounts from the Internet Research Agency (the Russian Troll Farm) to identify an appropriate control dataset (which time period and content to extract to construct control group).   Harvested control tweets for use in supervised learning using the TwitterAPI and TweetDeck to target the top 40 most frequent mentions, which produced 40,000 control tweets.   Conducted natural language processing (NLP) on 80,000 tweets using nltk, Word2Vec, and Keras to tokenize, vectorize, and train word embeddings for Logistic Regression and multiple Keras Neural Networks.   Final models achieved 90% accuracy with a dense neural network (training time: 32 sec) and 88% accuracy using Logistic Regression (training time: 0.6 sec)   Key Technologies Used: Python, Tweepy, Neural Networks (Tensorflow & Keras),  \\nRecidivism Risk Assessment  GitHub Link Classifying which released prisoners in Iowa will return to a life of crime using Next-Gen Gradient Boosted Trees  Developed a predictive model to classify which released prisoners in Iowa are likely to return to crime using Gradient Boosted Trees. with over 70% accuracy (via scikit-learn and Catboost).  Researched Iowa\\'s state sentencing guidelines and sentencing enhancements to engineer new numerical features to capture the severity of the crimes committed and the duration of sentences.  Achieved high recall rates for predicting recidivism using XGBoost.  Identified key features influencing recidivism, such as age, release type, and offense subtype.  Provided actionable insights and recommendations to the Iowa Department of Corrections.  Implemented various machine learning models and utilized SHAP for feature importance analysis.  Key Technologies: Python, Jupyter Notebooks, XGBoost, CatBoost, SHAP, SMOTE   Forecasting Stock Market Fluctuations with Trumps Tweets  GitHub Link Combining Natural Language Processing of Trumps Tweets with Time Series Forecasting S&P500 Price   Employed Natural Language Processing with nltk and word embeddings (both Word2Vec & GloVe pre-trained) to classify Trumps tweets by S&P 500 price change (increase/decrease/no change) 60 minutes after tweeting.  Compared tweet NLP classification models using Keras neural networks (LSTM, GRU, and CNN) to predict the direction of stock market price change from NLP alone.  Used Keras neural networks for time series forecasting of S&P 500 price.  Compared multiple data sources: price alone, price + 7 market technical indicators.  Compared forecasting models: Keras LSTM vs. XGBoost Regressor.  Final model stacked NLP classification predictions with S&P 500 time series forecasting and additional tweet features (sentiment analysis with Vader, number of retweets/favorites, uppercase-to-lowercase ratio). PROFESSIONAL SKILLS Programming: Python, OOP, SQL (MySQL, SQLAlchemy), MATLAB, HTML/CSS, Git/GitHub, NexScript, MedState Notation Data Analysis: ETL (numpy, pandas), AB Testing (scipy, statsmodels), Machine Learning (scikit-learn, Catboost, XGBoost), Deep Learning (Tensorflow, Keras) Natural Language Processing: nltk, spaCy, Tensorflow, HuggingFace transformers, LLMs(OpenAI, LangChain) Visualization/Dashboarding: Plotly/Dash, Tableau, Streamlit Dashboards & Deployment, Seaborn/Matplotlib, Looker Software: Adobe Illustrator, Adobe Photoshop, GraphPad Prism, SPSS, Microsoft Office, VS Code, Jupyter Notebook/Lab, Google Suite, Plexon OfflineSorter, NeuroExplorer  LEADERSHIP & COMMUNITY INVOLVEMENT SECTION IS WORK-IN-PROGRESS  Key Club Lt. Governor \\n', 'job_listing': 'Robert Half\\nSenior Data Scientist\\n$115K/yr - $173K/yrMid-Senior level\\n10,001+ employees  Staffing and Recruiting\\n2 company alumni work here3 school alumni work here\\n3 of 3 skills match your profile - you may be a good fit\\nApply SavedCalifornia, United States4 hours ago29 applicants\\nRemoteFull-time\\nAm I a good fit for this job? How can I best position myself fo\\nMeet the hiring team\\nKelli Griffin3rd\\nLead Talent Acquisition Partner\\nJob posterMessage\\nAbout the job\\nReady to revolutionize the future of data-driven decision-making? Join our\\npioneering Data Science team as we embark on an exciting journey to unlock\\ninsights, drive innovation, and shape the landscape of our organization\\'s success.\\nIf you\\'re passionate about leveraging cutting-edge generative AI technologies\\nand transforming raw data into actionable insight, we want you on our team!\"\\nThe Senior Data Scientist will be responsible for leading advanced data analytics\\nprojects, leveraging Azure and Microsoft data services. This role demands a deep\\nunderstanding of data science methodologies, machine learning algorithms, and\\nbig data technologies. The incumbent will work closely with cross-functional\\nteams to understand business needs and formulate and execute data science\\nsolutions that drive significant business impact.\\nKey Responsibilities:\\nData Analytics and Modeling:\\nDevelop and implement advanced predictive models and statistical\\nanalysis using a variety of machine learning algorithms.\\nSuggest algorithms or models appropriate for specific use cases and\\napplications.\\nAnalyze and extract relevant information from large amounts of historical\\nbusiness data to help automate and optimize key processes with business\\nteams.\\nApply technical solutions to business problems and questions using large\\nscale data analytics and machine learning; create highly calibrated\\nsolutions for business problems.\\nWork closely with software engineering teams to drive real-time model\\nexperiments, implementations and new feature creations.\\nContinuously evaluate and refine models based on performance metrics.\\nUtilize cloud technologies such as Azure Machine Learning, Azure\\nDatabricks, and other Microsoft data services for data processing, modelHomeMy NetworkJobsMessagingNotificationsMe\\n For BusinessLear\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 1/7\\nSee lessbuilding, and deployment.\\nLarge Language Model Fine-tuning:\\nEnhance and evolve the performance of large language models by\\nrefining their capabilities through targeted fine-tuning.\\nSteer both the research trajectory and the practical engineering efforts of\\nthe team.\\nFormulate and enact algorithms for model enhancement, tweak critical\\nhyperparameters, and heighten overall model efficiency.\\nGuarantee the integrity and relevance of datasets by conducting thorough\\npreprocessing and data analysis within the fine-tuning workflow.\\nConduct assessments on fine-tuned models, making necessary\\nmodifications to boost their effectiveness.\\nFoster a cooperative environment within the team, providing guidance to\\npeers to ensure a smooth fine-tuning operation that yields superior\\nresults.\\nStay at the forefront of advancements in large language model\\ntechnologies and applications, perpetually refining technical expertise in\\nmodel fine-tuning.\\nData Management and Strategy:\\nCollaborate with IT and data engineering teams in an enterprise setting to\\nintegrate data science solutions into the broader tech stack and data\\nstrategy.\\nBusiness Collaboration and Insights:\\nWork closely with business stakeholders to identify opportunities for\\nleveraging company data to drive business solutions.\\nTranslate complex data-driven findings into actionable business insights\\nand communicate these effectively to non-technical stakeholders.\\nResearch and Development:\\nStay abreast of industry trends and advancements in data science and\\nAzure technologies.\\nConduct research to explore new methodologies and technologies that\\ncan enhance the organization\\'s data analytics capabilities.\\nPreferred Qualifications and Skills:\\nBachelor\\'s degree in Statistics, Computer Science, Mathematics or\\nequivalent required; Master\\'s or PhD highly preferred\\n5 years of professional experience in data science, with a record in\\ndesigning and implementing large-scale data science projects.\\n5 years of industry experience in predictive modeling and large data\\nanalysis\\nKnowledge of open-source large language models and experience with\\nevaluating and recommending appropriate models for specific use cases.\\n3+ years of experience in using big data platforms and technologies such\\nas Hadoop, Azure data lake, Azure Cosmos DB, Pig, Hive, HBase, etc.\\n3+ years of hands-on experience in statistical modeling, data mining,\\nlarge data analysis and predictive modeling; text mining a major plus\\n3+ years of experience in regression, classification and clustering\\nmethods such as GLM, LR, SVM, LVQ, SOM, Neural Networks\\nExperience with two or more of the following: Python, PERL, Matlab or\\nScala\\nExpertise in various machine learning frameworks and libraries (e.g.,\\nTensorFlow, PyTorch, Scikit-learn).\\nExcellent analytical, problem-solving, and communication skills.\\nExcellent communication skills, with a proven ability to translate technical\\nfindings into business recommendations and strategies.\\nCertifications in Azure data services or advanced analytics preferred\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 2/7\\nSet alert for similar jobs\\nData Scientist, California, United StatesSet alert\\nEmployer-provided\\nPay range in California, United States\\nExact compensation may vary based on skills, experience, and location.\\nBase salary\\n$115,000/yr - $173,000/yr\\nFeatured benefits\\nMedical insurance\\nVision insurance\\nDental insurance\\n401(k)\\nTuition assistance\\nQualifications\\n3 of 3 skills match your profile - you may be a good fit\\nSkills added by the job poster\\nBig Data  Large Language Models (LLM)  Natural Language Processing (NLP)\\nAdditional skills among applicants\\nData Analysis  Data Science  Data Visualization  Machine Learning  Microsoft\\nPower BI  Python (Programming Language)  R (Programming Language)  SQL \\nShow qualification details\\nPut your best foot forward with your application\\nHire a resume writer\\nGet a resume review\\nSee how you compare to other applicants\\nApplicants for this job\\n29Applicants\\n29Applicants in the past day\\nApplicant seniority level\\n15 Entry level applicants\\n10 Senior level applicants\\n1 Director level applicant Youve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 3/7\\nApplicant education level\\n19%have a Doctor of Philosophy (Similar to you)\\n59%have a Master\\'s Degree\\n15%have a Bachelor\\'s Degree\\n7%have other degrees\\nApplicants are in these locations\\n1-5 applicants\\nNew York City Metropolitan\\nArea\\n1-5 applicants\\nGreater Pittsburgh Region\\n1-5 applicants\\nDallas-Fort Worth Metroplex\\nSee if Robert Half is hiring people like you\\nThe latest hiring trends.\\n29,307\\nTotal employees3%\\nCompany-wide\\n2 year growth2%\\nEngineering\\n2 year growth\\nMedian employee tenure 6 yearsMay 2022 Nov 2022 May 2023 Nov 2023 May 202410,00020,00030,00040,000\\nRobert Half hires candidates from some of these companies and schools\\nRobert Half hired 2 people\\nfrom Coding Dojo.See all\\nRobert Half hired 3 people from\\nFlatiron School.See all\\nEngineering hires at Robert Half came\\nfrom these companies and more.Engineering hires at Robert Half came\\nfrom these schools and more.\\nReset map\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 4/7\\nMore jobsShow more Premium insightsSee more companies See more schools\\nAbout the company\\nRobert Half\\n3,147,224 followersFollow\\nStaffing and Recruiting10,001+ employees29,320 on LinkedIn\\nTrending employee content PreviousNext\\nShow more\\nRobert Half, the worlds first and largest specialized talent solutions firm,\\nconnects opportunities at great companies with highly skilled job seekers. We\\noffer contract, temporary and permanent placement solutions for roles in financshow more\\nInterested in working with us in the future?\\nPrivately share your profile with our recruiters  youll be noted as\\nexpressing interest for up to a year.Learn more\\nIm interested\\nLead Data Scientist\\nCigniti Technologies\\nUnited States (Remote)\\nActively recruiting\\n4 weeks agoEasy ApplySenior Data Scientist\\nDTN\\nUnited States (Remote)\\nActively recruiting\\n2 weeks ago\\nData Scientist\\nQuantum World Technologies\\nUnited States (Remote)\\nActively recruiting\\nSr. Data Scientist\\nAKASA\\nUnited States (Remote)\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 5/7\\nSee more jobs like this10 minutes agoEasy Apply 2 weeks ago\\nSenior Data Scientist\\nPhreesia\\nUnited States (Remote)\\nActively recruiting\\n3 weeks agoSr. Data Scientist\\nAppFolio\\nUnited States (Remote)\\nActively recruiting\\n1 week ago\\nSenior Data Scientist,\\nProduct\\nUniswap Labs\\nNew York, NY (Remote)\\nActively recruiting\\n1 week agoSenior Data Scientist\\nAustin Fraser\\nUnited States (Remote)\\nActively recruiting\\n6 days agoEasy Apply\\nSenior Data Scientist\\nWebflow\\nUnited States (Remote)\\n1 company alum works here\\n2 days agoSenior Data Scientist\\nXOi\\nUnited States (Remote)\\n2 weeks ago\\nLead Data Scientist\\nLittle Place Labs\\nUnited States (Remote)\\n1 month agoEasy ApplyStaff Data Scientist\\nDemandbase\\nUnited States (Remote)\\n3 school alumni work here\\n3 weeks ago\\nLearn skills to get a new job with these courses\\n135,378 viewers\\nThe New Rules of Work\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 6/7\\nAbout Accessibility Talent Solutions\\nCommunity Guidelines Careers Marketing Solutions\\nAd Choices Advertising\\nSales Solutions Mobile Small Business\\nSafety CenterQuestions?\\nVisit our Help Center.\\nManage your account and privacy\\nGo to your Settings.\\nRecommendation transparency\\nLearn more about Recommended Content.Select Language\\nLinkedIn Corporation  2024282,784 viewers\\nShow more on LinkedIn Learning\\nDeveloping Your Professional Image in a New Job\\nLooking for talent?Post a job\\nPrivacy & Terms\\nEnglish (English)\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 7/7\\n'}, template='\\n    You are a a specialized career coach for the {sector}, focused on delivering tailored, concise job application advice and practice.\\n    You are proficient in resume analysis, cover letter guidance, and interview preparation, adapting to each user\\'s unique requirements. \\n    You maintain a professional, {model_tone} tone, ensuring advice is efficient, clear, and easily understandable, with the goal of aiding their career progression. \\n    Ask the user for their resume and job listing if not provided and they are needed to answer .\" \\n    \\n    Use the following context, if provided, to help answer the questions:\\n    \\n    -------------\\n    My Resume:\\n    {resume}\\n    \\n    -------------\\n    The job listing:\\n    {job_listing}\\n    ')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x172133700>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x1721305e0>, model_name='gpt-4', temperature=0.1, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'RateResume', 'description': 'Rates the resume against the job listing and provides a justification.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'ListMatchingQualifications', 'description': 'Lists the matching qualifications between the resume and job listing.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'ListMissingQualifications', 'description': 'Lists the missing qualifications in the resume based on the job listing.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'QuestionsForAdditionalInfo', 'description': 'Lists questions to determine if there is additional information that could be added to the resume.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}]})\n",
       "| OpenAIToolsAgentOutputParser()"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# from langchain.llms import OpenAI\n",
    "from langchain_openai import OpenAI,ChatOpenAI\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor, create_openai_tools_agent\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.1)\n",
    "\n",
    "tools_list =  [\n",
    "    rate_resume_tool,\n",
    "    matching_qualifications_tool,\n",
    "    missing_qualifications_tool,\n",
    "    additional_info_questions_tool\n",
    "    ]\n",
    "# Create the agent with the defined tools\n",
    "# agent = create_openai_functions_agent\n",
    "agent = create_openai_tools_agent(llm,\n",
    "                                      tools_list,\n",
    "                                    #   prompt=tools_prompt,\n",
    "                                    prompt=manual_tools_prompt)\n",
    "\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'chat_history': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], partial_variables={'sector': 'data science and analytics', 'model_tone': 'friendly and encouraging', 'resume': '[LONG MASTER RESUME]  James M. Irving, Ph.D. 8222 Spadderdock Way, Laurel, MD, 20724 | (518) 322-6750 | james.irving.phd@gmail.com |  LinkedIn: james-irving-phd | GitHub: https://github.com/jirvingphd  SUMMARY V1 Innovative and enterprising data scientist with extensive experience in applying advanced data science techniques to real-world problems. Known for excellent problem-solving skills and the ability to rapidly master and implement new technologies. Committed to leveraging data to drive innovation and support data-driven decision-making. SUMMARY V2 Neuroscientist-turned-data scientist with an insatiable curiosity and a proven track record in mastering cutting-edge technologies. Exceptional communication and interpersonal skills paired with a robust history of problem-solving and critical thinking. Proven ability to self-teach complex concepts and technologies, including in vivo electrophysiology recordings and analysis. Successfully trained generations of collaborators, technicians, research fellows, and undergraduate volunteers by customizing the training to match the specific trainees experience and knowledge. COMPETENCIES  Data Analysis, Statistical Modeling, Machine Learning, Data Visualization  Experimental Design, Quantitative Research Methods, Time Series Analysis, Signal Processing  Cognitive Neuroscience, Behavioral Analysis, Database Management, Pattern Recognition  Python Programming, Deep Learning, Natural Language Processing, AI/LLM Implementation  Adaptive Communication Style, Problem-Solving & Critical Thinking EXPERIENCE  Coding Dojo | Remote Curriculum Writer - Data Science March 2023 - January 2024  Developed and delivered advanced courses in Time Series Modeling, NLP, and Model Deployment, enhancing data science skills for over 100 professionals.  Expanded a 16-week boot camp to a 24-week comprehensive training program, increasing curriculum depth by 50%, which boosted learner engagement and program satisfaction.  Implemented project management and automation tools using Monday.com, optimizing workflow efficiency and resolving operational bottlenecks.  Developed and implemented Monday.com boards, including public forms and executive-facing Gantt charts, to automate internal workflows and streamline curriculum management, resolving over 100 issues.  Integrated cutting-edge technologies like APIs, Web Scraping, and Computer Vision into the curriculum, aligning educational content with evolving industry standards and practical application needs.  Developed a workflow and process to test and identify datasets for curriculum use, including template Python notebooks for preprocessing, visualization, EDA, modeling, and interpretations.  Constructed the Dojo Environment Setup for Students, ensuring compatibility with various OS and facilitating smooth installation of necessary tools and libraries.  Created and maintained a GitHub Organization for curriculum-related activities, solutions, and packages, providing a centralized resource hub for students and instructors.  Designed an extended case study for the 6-month curriculum, applying all phases of CRISP-DM to a specially constructed subset of the Ames housing dataset, enhancing practical application and understanding of the data science lifecycle.  Achieved tight deadlines throughout the year despite unexpected demands related to getting the curriculum accredited ensuring timely delivery and high-quality content for the program.  Data Science Instructor November 2021 - March 2023  Achieved high Net Promoter Scores (NPS) exceeding 90% through engaging and interactive live lectures, demonstrating strong communication and pedagogical skills.  Revolutionized administrative workflow by automating tasks, resulting in a 99% reduction in student onboarding timefrom 5 hours to just 2 minutesdramatically enhancing operational efficiency and productivity. \\n Developed and delivered a highly acclaimed 4-week course with perfect feedback ratings, showcasing expertise in curriculum development and instructional delivery.  Designed and led over 16 interactive live lectures and code-along projects, enhancing student participation and creating a dynamic learning environment. Flatiron School | Remote Data Science Instructor  October 2019 - October 2021  Mentored and supervised over 60 students, helping them transition into successful data science careers with a high post-program employment rate.  Conducted weekly 90-minute study groups, accumulating over 270 hours of recorded lessons, significantly enhancing student comprehension and engagement.  Spearheaded the development and implementation of the \"Flex\" boot camp program, refining instructional design and delivery methods to meet diverse learning needs.  Created and maintained three student-progress-tracking Looker dashboards, providing real-time insights into student performance and facilitating timely interventions.  Guided students in selecting capstone project subjects, identifying job sectors of interest, and selecting appropriate data sources. Topics included time series analysis, NLP analysis, Covid cough classification (via Computer Vision),  and customer segmentation.  Offered bonus lectures on Object-Oriented Programming, dashboarding with Plotly and Dash, and advanced visualizations with matplotlib and seaborn.  Updated the entire lecture and activity content to accommodate a new teaching model, integrating recorded lectures from a national \"Central Lecturer\" with expanded hands-on activities. University of Maryland, School of Medicine | Baltimore, MD  Laboratory Manager  July 2017 - August 2018  Ensured full compliance with regulatory standards as the lab\\'s public representative, achieving a flawless inspection record.  Successfully represented lab and guided inspectors through 4 regulatory inspections from 2 agencies, demonstrating knowledge of and compliance with protocols and regulations.  Negotiated and finalized a $100,000 technical hardware contract with vendors, optimizing procurement processes and ensuring cost-effectiveness.  Managed and administered over 20 TBs of data storage systems, ensuring data accessibility, security, and efficient retrieval.  Overhauled mouse colony management procedures, reducing housing costs by 60%  (from approximately $3.8k/month to $1.5k/month ) through strategic resource allocation and process optimization.  Created and instituted new surgery logs to simplify record keeping while ensuring regularity compliance.  Managed lab supplies and equipment purchasing, maintaining appropriate documentation and financial records.  Consolidated and encrypted all sensitive and proprietary lab information vendor accounts, log-in information, and secure information into an encrypted data vault Postdoctoral Research Fellow  June 2015 - July 2017  Led neuroscience research using advanced techniques such as in vivo optogenetics and electrophysiology recordings, resulting in groundbreaking insights into neural functioning.  Developed approximately 30 custom analysis scripts in Matlab, NexScript, MedPC, and Arduino, enhancing data processing capabilities and facilitating comprehensive statistical analyses.  Mentored and guided a diverse team, fostering a collaborative learning environment and achieving research excellence (1 postdoc, 2 Ph.D. students, 3 lab techs, and 3 undergraduate volunteers.)  Demonstrated self-directed learning by mastering Matlab programming and creating custom-designed analysis programs for large datasets, streamlining data interpretation and enhancing research efficiency.  Researched the role of extended amygdala stress neurons in binge drinking, using multiple genetic tools and in vivo electrophysiology recordings.  Recorded changes in the activity of amygdala neurons during binge drinking. Identified neuron populations using a combination of single-unit recordings and optogenetic stimulation using targeted viral vectors.  Founded in vivo electrophysiology recordings and in vivo deep-brain structure calcium imaging in awake and behaving mice.  Directed several research projects simultaneously and managed a staff of postdoctoral fellows, technicians and student volunteers.  Programmed custom-designed analysis programs (~30) for large datasets in 4 programming languages (see skills).  Communicated research findings to mixed audiences with varying degrees of background knowledge and experience via seminars, presentations, as well as scientific posters.   Wrote user guides on various complicated technical procedures and techniques to train lab members and collaborators.  Trained and mentored 1 research fellow, 2 graduate students, 2 lab technicians, and 3 undergraduate volunteers on several complex technical procedures and the underlying scientific principles/theory.  Graduate Research Assistant \\nSeptember 2009 -  May 2015  Pioneered application of optogenetics with fast-scan cyclic voltammetry to discover previously unknown modulation of dopamine release via cholinergic interneurons.  Communicated research findings to audiences with varying degrees of background knowledge and familiarity in seminars, as well as scientific posters.  Trained and mentored 4 fellows, 3 graduate students, 5 lab technicians, 6 collaborators, and 1 undergraduate volunteer on various complex procedures and techniques.  Wrote user guides on various complex technical procedures and techniques to train current and future lab members Tulane University | New Orleans, LA Research Assistant January 2009  May 2009  Continued masters thesis study of the role of histone deacetylase (HDAC) inhibition in aggression under chronic stress.  Tested changes in stress hormones and protein expression in stressed rats with HDAC inhibition.  DISTINCTIONS & HONORS  Happy Camper Award, University of Maryland 2012  2013  Awarded to the Ph.D. student with the most positive attitude in the face of adversity, as voted by fellow students.  Summer Research Program Award, Tulane University  May 2008 to August 2008  Awarded for distinguished scientific research, including salary.  Tulane Distinguished Scholars, Tulane University  Fall 2004 - Fall 2007  Awarded for outstanding academic performance.  Tulane-Newcomb College Deans List  Fall 2004 - Fall 2005  Awarded for achieving a GPA greater than 3.7 EDUCATION Certificate of Completion, Data Science, Flatiron School, Online (February 2019 - August 2019)  Intensive 5-month program, approximately 50 hours per week Doctor of Philosophy, Neuroscience, University of Maryland, Baltimore, MD (August 2009 - May 2015)  Including specialized optional training: Entrepreneurship in Life Sciences course, Science Communication internship. Master of Science, Neuroscience, Tulane University, New Orleans, LA (January 2008 - December 2008) Bachelor of Science, Neuroscience (Sociology Minor), Tulane University, New Orleans, LA (August 2004 - December 2007) ADDITIONAL EXPERIENCE AND SERVICE University of Maryland | Baltimore, MD Science Communication Internship  Office of Public Affairs  June 2013 - September 2013  Selected as one of four founding members for an internship with Office of Public Affairs at the University of Maryland School of Medicine.  Trained in many aspects of university public affairs communications, relaying complex scientific material to a lay audience for both educational and promotional purposes.  Wrote press releases on university-associated research and novel findings to disseminate to inspire media coverage.  Wrote an in-depth interview featuring a university scientists high-impact research developing a novel anti-depressant.  Practiced live television interviews in the universitys satellite teleconferencing suite as both interviewer and interviewee.  Weekly training classes + independent assignments  5-10 hours/week.  Entrepreneurship in Life Sciences  Interdisciplinary Course January 2014 to June 2014  Trained by visiting experts in aspects of developing, promoting, and acquiring venture funding for a biomedical technology company.  \\n Wrote and presented funding proposals for venture capitalist firms for a resource-sharing/saving cloud-based software solution for universities.  Wrote a business plan, patent applications, and promotional materials.  Weekly classes + group work  10 hours/week.  Student Training Committee Member January 2013 - June 2015  Served graduate student community as proponent and liaison to the Ph.D. program administration.  Reformed graduate program policies and procedures for the mutual benefit of students and faculty.  Advised administration on student outreach and prospective student application/interview process.  Big Brother  Program in Neuroscience  August 2010 - December 2013  Volunteered as Big Brother mentor for 3 incoming doctoral students.  Advised little brothers on research lab choices, handling graduate coursework, and navigating university politics. Tulane University | New Orleans, LA Green Wave Ambassador Fall 2004  Spring 2005  Led guided tours of the campus for prospective students and their families, providing comprehensive information about academic programs, campus facilities, and student life.  Served as a host for visiting students, organizing and facilitating events to enhance their campus experience.  Engaged with visitors to answer questions, provide insights into the student experience, and assist with logistical needs.  Represented the university positively, contributing to recruitment and outreach efforts by sharing personal experiences and highlighting unique aspects of the campus community.  Student Calling Center Representative Fall 2005  Spring 2007  Contacted alumni to provide updates about university events, achievements, and developments.  Engaged alumni in meaningful conversations to foster a connection between them and the university.  Solicited donations, explaining the impact of their contributions on university programs, scholarships, and facilities.  Maintained accurate records of interactions and feedback, contributing to the continuous improvement of alumni relations and fundraising strategies.  PUBLICATIONS  Aroni S, Marino RAM, Girven KS, Irving JM, Cheer JF, Sparta DR. (2021) Repeated binge ethanol drinking enhances electrical activity of central amygdala corticotropin releasing factor neurons in vivo. Neuropharmacology.  Girven, K., Irving, J., Aroni, S., Sparta, D. The Role of Interconnections between the vBNST and insula in the modulation of reward processing. Manuscript in preparation.  Cachope, R., Mateo, Y., Mathur, B.N., Irving, J., Wang, H.-L., Morales, M., Lovinger, D.M., and Cheer, J.F. (2012). Selective Activation of Cholinergic Interneurons Enhances Accumbal Phasic Dopamine Release: Setting the Tone for Reward Processing. Cell Reports 2, 3341.  Mateo, Y., Atwood, B., Wang, H.-L., Zhang, S., Irving, J., Gildish, I., Cachope, R., Bellochio, L., Guzman, M., Morales, M., Cheer, J.F., and Lovinger, D.M. Cortical afferents expressing CB1 receptors control accumbal phasic dopamine release caused by selective activation of cholinergic interneurons. Manuscript submitted for publication. POSTER ABTRACTS  Irving, J.M., Maehler, C.J., Qadir, H., Girven, K.S., Sparta, D.R. Central Amygdala Corticotropin Releasing FactorNeurons Encode and Modulate Binge Drinking and Relapse American College of Neuropsychopharmacology Annual Meeting 2016.  Irving, J.M., Maehler, C.J., Girven, K.S., Sparta, D.R. The Role of Extended Amygdala Corticotropin Neurons in Binge Ethanol Drinking. Society for Neuroscience Annual Meeting 2016.  Irving, J.M., Maehler, C.J., Sparta, D.R. Optogenetic and Pharmacogenetic Interrogation of Central Amygdala Corticotropin Neurons on Binge Ethanol Drinking. Research Society on Alcoholism Annual Meeting 2016.  Irving, J.M., Gluskin, K.H., Cheer, J.F. Optogenetic activation of accumbal fast-spiking interneurons is reinforcing. Society for Neuroscience Annual Meeting 2014.  Kashtelyan, V., Irving, J.M., Fitoussi, A., Wang, H., Morales, M., Cheer, J.F. Conditional deletion of CB1 receptors on cholinergic terminals and its functional consequences. Society for Neuroscience Meeting Annual 2014.  Irving, J.M., Mateo, Y., Cheer, J.F. Optogenetic Stimulation of Cholinergic Interneurons in the Nucleus Accumbens Causes Dopamine Release. Society for Neuroscience Meeting 2011. \\n Irving, J.M., Mateo, Y., Cheer, J.F. Endogenous Activity of Cholinergic Interneurons in the Nucleus Accumbens is Sufficient to Evoke Dopamine Release. Graduate Research Conference 2012.  PROFERRED COMMUNICATIONS   Irving, J.M., Sparta, D.R. Modulation of Binge Drinking by Central Amygdala Corticotropin-Releasing Factor Neurons. Department of Anatomy & Neurobiology, Second-Monday Program, University of Maryland School of Medicine, 2016.  Irving, J.M., Cheer, J.F. The Role of Local Activity of the Nucleus Accumbens in Reward: Interneurons and Gamma Oscillations,, Public Dissertation Defense, 2016.  Irving, J.M..Cheer, J.F., Selective activation of cholinergic interneurons enhances accumbal phasic dopamine release: setting the tone for reward processing., Department of Anatomy & Neurobiology, Second-Monday Program, University of Maryland, Baltimore, 2012.  Irving, J.M..Cheer, J.F., Selective activation of cholinergic interneurons enhances accumbal phasic dopamine release: setting the tone for reward processing., Program in Neuroscience Retreat, Notre Dame of Maryland, 2012.  Irving, J.M., Cheer, J.F., The Role of CB1 Receptors on GABAergic Interneurons of the Nucleus Accumbens in Motivated-Behavior and Modulation of Accumbal Gamma Rhythms University of Maryland, Baltimore, Thesis Proposal, 2014.  Irving. J.M., Cheer, J.F., The Reinforcing Effects of Gamma-Frequency Stimulation of Accumbal Parvalbumin Interneurons and the Role of CB1 Receptors, University of Pittsburgh, Department of Psychiatry, 2015. DATA SCIENCE PROJECTS Computer Vision Classification of American Sign Language  GitHub Link Applied tensorflow and transfer learning to classify an image as the correct letter of the ASL alphabet.  COMING SOON AI Job Application Assistant  App Link  GitHub Link Developed a Streamlit application to assist job seekers with resumes and cover letters  Developed a Streamlit application to assist job seekers by analyzing resumes and job listings using AI.  Integrated ChatGPT for tailored advice, resume improvements, and cover letter creation.  Automated job application process with AI-driven insights and recommendations.  Enhanced user experience with an interactive and user-friendly interface.  Provided actionable advice to job seekers, improving their chances of success.  Key Technologies Used: Streamlit, LangChain, OpenAI API  NLP Analysis of Amazon Reviews + AI Recommendations - GitHub Link Natural Language Processing Analysis, Modeling, and Deployment with Actionable Insights  Designed and deployed a user-centric Streamlit dashboard, integrating live sentiment predictions and interactive analysis of trends to guide strategic decision-making.  Conducted sentiment analysis on over 5 million Amazon Grocery & Gourmet Food reviews, utilizing NLP and machine learning techniques (Logistic Regression, Tf-idf vectorization) to identify key factors affecting customer satisfaction and achieve 95% accuracy in sentiment classification.  Employed Hugging Face transformers and Lang Chain/ChatGPT within the dashboard with a vectorized database used for summarization and insights, translating vast consumer feedback into actionable product enhancement strategies.  Key Technologies Used: Python, Hugging Face, OpenAI API, LangChain, spacy, scikit-learn. How to Make a Successful Movie  GitHub Link Constructing and analyzing an extensive movie database with hypothesis-testing insights + Tableau Dashboard  Integrated and normalized datasets from IMDB and TMDB API for comprehensive movie analysis.  Engineered a MySQL database on AWS RDS for robust data storage and retrieval.  Designed an interactive Tableau dashboard to communicate findings to stakeholders, enhancing decision-making processes (see GitHub link).  Applied A/B Testing to identify key factors influencing movie performance and success to provide business recommendations on what movies to create for high box office returns on factors like MPAA rating, runtime, and genre.  Key Technologies Used: Python, SQL, Tableau, TMDB API, Pandas, sqlalchemy, MySQL Workbench, statsmodels, AWS RDS How to Spot a Troll  GitHub Link Classifying Russian Troll Tweets vs Authentic Tweets  Performed EDA on 3 million tweets from accounts from the Internet Research Agency (the Russian Troll Farm) to identify an appropriate control dataset (which time period and content to extract to construct control group).   Harvested control tweets for use in supervised learning using the TwitterAPI and TweetDeck to target the top 40 most frequent mentions, which produced 40,000 control tweets.   Conducted natural language processing (NLP) on 80,000 tweets using nltk, Word2Vec, and Keras to tokenize, vectorize, and train word embeddings for Logistic Regression and multiple Keras Neural Networks.   Final models achieved 90% accuracy with a dense neural network (training time: 32 sec) and 88% accuracy using Logistic Regression (training time: 0.6 sec)   Key Technologies Used: Python, Tweepy, Neural Networks (Tensorflow & Keras),  \\nRecidivism Risk Assessment  GitHub Link Classifying which released prisoners in Iowa will return to a life of crime using Next-Gen Gradient Boosted Trees  Developed a predictive model to classify which released prisoners in Iowa are likely to return to crime using Gradient Boosted Trees. with over 70% accuracy (via scikit-learn and Catboost).  Researched Iowa\\'s state sentencing guidelines and sentencing enhancements to engineer new numerical features to capture the severity of the crimes committed and the duration of sentences.  Achieved high recall rates for predicting recidivism using XGBoost.  Identified key features influencing recidivism, such as age, release type, and offense subtype.  Provided actionable insights and recommendations to the Iowa Department of Corrections.  Implemented various machine learning models and utilized SHAP for feature importance analysis.  Key Technologies: Python, Jupyter Notebooks, XGBoost, CatBoost, SHAP, SMOTE   Forecasting Stock Market Fluctuations with Trumps Tweets  GitHub Link Combining Natural Language Processing of Trumps Tweets with Time Series Forecasting S&P500 Price   Employed Natural Language Processing with nltk and word embeddings (both Word2Vec & GloVe pre-trained) to classify Trumps tweets by S&P 500 price change (increase/decrease/no change) 60 minutes after tweeting.  Compared tweet NLP classification models using Keras neural networks (LSTM, GRU, and CNN) to predict the direction of stock market price change from NLP alone.  Used Keras neural networks for time series forecasting of S&P 500 price.  Compared multiple data sources: price alone, price + 7 market technical indicators.  Compared forecasting models: Keras LSTM vs. XGBoost Regressor.  Final model stacked NLP classification predictions with S&P 500 time series forecasting and additional tweet features (sentiment analysis with Vader, number of retweets/favorites, uppercase-to-lowercase ratio). PROFESSIONAL SKILLS Programming: Python, OOP, SQL (MySQL, SQLAlchemy), MATLAB, HTML/CSS, Git/GitHub, NexScript, MedState Notation Data Analysis: ETL (numpy, pandas), AB Testing (scipy, statsmodels), Machine Learning (scikit-learn, Catboost, XGBoost), Deep Learning (Tensorflow, Keras) Natural Language Processing: nltk, spaCy, Tensorflow, HuggingFace transformers, LLMs(OpenAI, LangChain) Visualization/Dashboarding: Plotly/Dash, Tableau, Streamlit Dashboards & Deployment, Seaborn/Matplotlib, Looker Software: Adobe Illustrator, Adobe Photoshop, GraphPad Prism, SPSS, Microsoft Office, VS Code, Jupyter Notebook/Lab, Google Suite, Plexon OfflineSorter, NeuroExplorer  LEADERSHIP & COMMUNITY INVOLVEMENT SECTION IS WORK-IN-PROGRESS  Key Club Lt. Governor \\n', 'job_listing': 'Robert Half\\nSenior Data Scientist\\n$115K/yr - $173K/yrMid-Senior level\\n10,001+ employees  Staffing and Recruiting\\n2 company alumni work here3 school alumni work here\\n3 of 3 skills match your profile - you may be a good fit\\nApply SavedCalifornia, United States4 hours ago29 applicants\\nRemoteFull-time\\nAm I a good fit for this job? How can I best position myself fo\\nMeet the hiring team\\nKelli Griffin3rd\\nLead Talent Acquisition Partner\\nJob posterMessage\\nAbout the job\\nReady to revolutionize the future of data-driven decision-making? Join our\\npioneering Data Science team as we embark on an exciting journey to unlock\\ninsights, drive innovation, and shape the landscape of our organization\\'s success.\\nIf you\\'re passionate about leveraging cutting-edge generative AI technologies\\nand transforming raw data into actionable insight, we want you on our team!\"\\nThe Senior Data Scientist will be responsible for leading advanced data analytics\\nprojects, leveraging Azure and Microsoft data services. This role demands a deep\\nunderstanding of data science methodologies, machine learning algorithms, and\\nbig data technologies. The incumbent will work closely with cross-functional\\nteams to understand business needs and formulate and execute data science\\nsolutions that drive significant business impact.\\nKey Responsibilities:\\nData Analytics and Modeling:\\nDevelop and implement advanced predictive models and statistical\\nanalysis using a variety of machine learning algorithms.\\nSuggest algorithms or models appropriate for specific use cases and\\napplications.\\nAnalyze and extract relevant information from large amounts of historical\\nbusiness data to help automate and optimize key processes with business\\nteams.\\nApply technical solutions to business problems and questions using large\\nscale data analytics and machine learning; create highly calibrated\\nsolutions for business problems.\\nWork closely with software engineering teams to drive real-time model\\nexperiments, implementations and new feature creations.\\nContinuously evaluate and refine models based on performance metrics.\\nUtilize cloud technologies such as Azure Machine Learning, Azure\\nDatabricks, and other Microsoft data services for data processing, modelHomeMy NetworkJobsMessagingNotificationsMe\\n For BusinessLear\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 1/7\\nSee lessbuilding, and deployment.\\nLarge Language Model Fine-tuning:\\nEnhance and evolve the performance of large language models by\\nrefining their capabilities through targeted fine-tuning.\\nSteer both the research trajectory and the practical engineering efforts of\\nthe team.\\nFormulate and enact algorithms for model enhancement, tweak critical\\nhyperparameters, and heighten overall model efficiency.\\nGuarantee the integrity and relevance of datasets by conducting thorough\\npreprocessing and data analysis within the fine-tuning workflow.\\nConduct assessments on fine-tuned models, making necessary\\nmodifications to boost their effectiveness.\\nFoster a cooperative environment within the team, providing guidance to\\npeers to ensure a smooth fine-tuning operation that yields superior\\nresults.\\nStay at the forefront of advancements in large language model\\ntechnologies and applications, perpetually refining technical expertise in\\nmodel fine-tuning.\\nData Management and Strategy:\\nCollaborate with IT and data engineering teams in an enterprise setting to\\nintegrate data science solutions into the broader tech stack and data\\nstrategy.\\nBusiness Collaboration and Insights:\\nWork closely with business stakeholders to identify opportunities for\\nleveraging company data to drive business solutions.\\nTranslate complex data-driven findings into actionable business insights\\nand communicate these effectively to non-technical stakeholders.\\nResearch and Development:\\nStay abreast of industry trends and advancements in data science and\\nAzure technologies.\\nConduct research to explore new methodologies and technologies that\\ncan enhance the organization\\'s data analytics capabilities.\\nPreferred Qualifications and Skills:\\nBachelor\\'s degree in Statistics, Computer Science, Mathematics or\\nequivalent required; Master\\'s or PhD highly preferred\\n5 years of professional experience in data science, with a record in\\ndesigning and implementing large-scale data science projects.\\n5 years of industry experience in predictive modeling and large data\\nanalysis\\nKnowledge of open-source large language models and experience with\\nevaluating and recommending appropriate models for specific use cases.\\n3+ years of experience in using big data platforms and technologies such\\nas Hadoop, Azure data lake, Azure Cosmos DB, Pig, Hive, HBase, etc.\\n3+ years of hands-on experience in statistical modeling, data mining,\\nlarge data analysis and predictive modeling; text mining a major plus\\n3+ years of experience in regression, classification and clustering\\nmethods such as GLM, LR, SVM, LVQ, SOM, Neural Networks\\nExperience with two or more of the following: Python, PERL, Matlab or\\nScala\\nExpertise in various machine learning frameworks and libraries (e.g.,\\nTensorFlow, PyTorch, Scikit-learn).\\nExcellent analytical, problem-solving, and communication skills.\\nExcellent communication skills, with a proven ability to translate technical\\nfindings into business recommendations and strategies.\\nCertifications in Azure data services or advanced analytics preferred\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 2/7\\nSet alert for similar jobs\\nData Scientist, California, United StatesSet alert\\nEmployer-provided\\nPay range in California, United States\\nExact compensation may vary based on skills, experience, and location.\\nBase salary\\n$115,000/yr - $173,000/yr\\nFeatured benefits\\nMedical insurance\\nVision insurance\\nDental insurance\\n401(k)\\nTuition assistance\\nQualifications\\n3 of 3 skills match your profile - you may be a good fit\\nSkills added by the job poster\\nBig Data  Large Language Models (LLM)  Natural Language Processing (NLP)\\nAdditional skills among applicants\\nData Analysis  Data Science  Data Visualization  Machine Learning  Microsoft\\nPower BI  Python (Programming Language)  R (Programming Language)  SQL \\nShow qualification details\\nPut your best foot forward with your application\\nHire a resume writer\\nGet a resume review\\nSee how you compare to other applicants\\nApplicants for this job\\n29Applicants\\n29Applicants in the past day\\nApplicant seniority level\\n15 Entry level applicants\\n10 Senior level applicants\\n1 Director level applicant Youve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 3/7\\nApplicant education level\\n19%have a Doctor of Philosophy (Similar to you)\\n59%have a Master\\'s Degree\\n15%have a Bachelor\\'s Degree\\n7%have other degrees\\nApplicants are in these locations\\n1-5 applicants\\nNew York City Metropolitan\\nArea\\n1-5 applicants\\nGreater Pittsburgh Region\\n1-5 applicants\\nDallas-Fort Worth Metroplex\\nSee if Robert Half is hiring people like you\\nThe latest hiring trends.\\n29,307\\nTotal employees3%\\nCompany-wide\\n2 year growth2%\\nEngineering\\n2 year growth\\nMedian employee tenure 6 yearsMay 2022 Nov 2022 May 2023 Nov 2023 May 202410,00020,00030,00040,000\\nRobert Half hires candidates from some of these companies and schools\\nRobert Half hired 2 people\\nfrom Coding Dojo.See all\\nRobert Half hired 3 people from\\nFlatiron School.See all\\nEngineering hires at Robert Half came\\nfrom these companies and more.Engineering hires at Robert Half came\\nfrom these schools and more.\\nReset map\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 4/7\\nMore jobsShow more Premium insightsSee more companies See more schools\\nAbout the company\\nRobert Half\\n3,147,224 followersFollow\\nStaffing and Recruiting10,001+ employees29,320 on LinkedIn\\nTrending employee content PreviousNext\\nShow more\\nRobert Half, the worlds first and largest specialized talent solutions firm,\\nconnects opportunities at great companies with highly skilled job seekers. We\\noffer contract, temporary and permanent placement solutions for roles in financshow more\\nInterested in working with us in the future?\\nPrivately share your profile with our recruiters  youll be noted as\\nexpressing interest for up to a year.Learn more\\nIm interested\\nLead Data Scientist\\nCigniti Technologies\\nUnited States (Remote)\\nActively recruiting\\n4 weeks agoEasy ApplySenior Data Scientist\\nDTN\\nUnited States (Remote)\\nActively recruiting\\n2 weeks ago\\nData Scientist\\nQuantum World Technologies\\nUnited States (Remote)\\nActively recruiting\\nSr. Data Scientist\\nAKASA\\nUnited States (Remote)\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 5/7\\nSee more jobs like this10 minutes agoEasy Apply 2 weeks ago\\nSenior Data Scientist\\nPhreesia\\nUnited States (Remote)\\nActively recruiting\\n3 weeks agoSr. Data Scientist\\nAppFolio\\nUnited States (Remote)\\nActively recruiting\\n1 week ago\\nSenior Data Scientist,\\nProduct\\nUniswap Labs\\nNew York, NY (Remote)\\nActively recruiting\\n1 week agoSenior Data Scientist\\nAustin Fraser\\nUnited States (Remote)\\nActively recruiting\\n6 days agoEasy Apply\\nSenior Data Scientist\\nWebflow\\nUnited States (Remote)\\n1 company alum works here\\n2 days agoSenior Data Scientist\\nXOi\\nUnited States (Remote)\\n2 weeks ago\\nLead Data Scientist\\nLittle Place Labs\\nUnited States (Remote)\\n1 month agoEasy ApplyStaff Data Scientist\\nDemandbase\\nUnited States (Remote)\\n3 school alumni work here\\n3 weeks ago\\nLearn skills to get a new job with these courses\\n135,378 viewers\\nThe New Rules of Work\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 6/7\\nAbout Accessibility Talent Solutions\\nCommunity Guidelines Careers Marketing Solutions\\nAd Choices Advertising\\nSales Solutions Mobile Small Business\\nSafety CenterQuestions?\\nVisit our Help Center.\\nManage your account and privacy\\nGo to your Settings.\\nRecommendation transparency\\nLearn more about Recommended Content.Select Language\\nLinkedIn Corporation  2024282,784 viewers\\nShow more on LinkedIn Learning\\nDeveloping Your Professional Image in a New Job\\nLooking for talent?Post a job\\nPrivacy & Terms\\nEnglish (English)\\nYouve saved this job.See saved jobs5/30/24, 4:50 PM Senior Data Scientist | Robert Half | LinkedIn\\nhttps://www.linkedin.com/jobs/view/3937740241/?eBP=CwEAAAGPy0Ok_MktygCPbpmzbN3WdhY0kWuWb2g13NRl8-92hj-zglXTd0_psjymZHkt5J29bnHqu4 7/7\\n'}, template='\\n    You are a a specialized career coach for the {sector}, focused on delivering tailored, concise job application advice and practice.\\n    You are proficient in resume analysis, cover letter guidance, and interview preparation, adapting to each user\\'s unique requirements. \\n    You maintain a professional, {model_tone} tone, ensuring advice is efficient, clear, and easily understandable, with the goal of aiding their career progression. \\n    Ask the user for their resume and job listing if not provided and they are needed to answer .\" \\n    \\n    Use the following context, if provided, to help answer the questions:\\n    \\n    -------------\\n    My Resume:\\n    {resume}\\n    \\n    -------------\\n    The job listing:\\n    {job_listing}\\n    ')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x172133700>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x1721305e0>, model_name='gpt-4', temperature=0.1, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'RateResume', 'description': 'Rates the resume against the job listing and provides a justification.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'ListMatchingQualifications', 'description': 'Lists the matching qualifications between the resume and job listing.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'ListMissingQualifications', 'description': 'Lists the missing qualifications in the resume based on the job listing.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'QuestionsForAdditionalInfo', 'description': 'Lists questions to determine if there is additional information that could be added to the resume.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}]})\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[Tool(name='RateResume', description='Rates the resume against the job listing and provides a justification.', func=<function rate_resume_vs_job at 0x17386e830>), Tool(name='ListMatchingQualifications', description='Lists the matching qualifications between the resume and job listing.', func=<function list_matching_qualifications at 0x173bdda20>), Tool(name='ListMissingQualifications', description='Lists the missing qualifications in the resume based on the job listing.', func=<function list_missing_qualifications at 0x1661fb2e0>), Tool(name='QuestionsForAdditionalInfo', description='Lists questions to determine if there is additional information that could be added to the resume.', func=<function questions_for_additional_info at 0x1755eec20>)])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools_list, verbose=True,\n",
    "                            #    memory=ConversationBufferWindowMemory(window_size=5, \n",
    "                                                                    #  return_messages=True)\n",
    "                                                                    \n",
    ")\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JMI: Different Step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `RateResume` with `Senior Data Scientist at Robert Half`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "rate_resume_vs_job() missing 1 required positional argument: 'job_listing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHow goes my resume compare against this job listing?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresume\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mlong_resume\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                       \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjob_listing\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mjob_text_senior_rh\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages/langchain/agents/agent.py:1432\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1432\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1435\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1438\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1440\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1441\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m   1442\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages/langchain/agents/agent.py:1138\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1131\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1136\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1138\u001b[0m         [\n\u001b[1;32m   1139\u001b[0m             a\n\u001b[1;32m   1140\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[1;32m   1141\u001b[0m                 name_to_tool_map,\n\u001b[1;32m   1142\u001b[0m                 color_mapping,\n\u001b[1;32m   1143\u001b[0m                 inputs,\n\u001b[1;32m   1144\u001b[0m                 intermediate_steps,\n\u001b[1;32m   1145\u001b[0m                 run_manager,\n\u001b[1;32m   1146\u001b[0m             )\n\u001b[1;32m   1147\u001b[0m         ]\n\u001b[1;32m   1148\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages/langchain/agents/agent.py:1138\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1131\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1136\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1138\u001b[0m         [\n\u001b[1;32m   1139\u001b[0m             a\n\u001b[1;32m   1140\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[1;32m   1141\u001b[0m                 name_to_tool_map,\n\u001b[1;32m   1142\u001b[0m                 color_mapping,\n\u001b[1;32m   1143\u001b[0m                 inputs,\n\u001b[1;32m   1144\u001b[0m                 intermediate_steps,\n\u001b[1;32m   1145\u001b[0m                 run_manager,\n\u001b[1;32m   1146\u001b[0m             )\n\u001b[1;32m   1147\u001b[0m         ]\n\u001b[1;32m   1148\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages/langchain/agents/agent.py:1223\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m agent_action\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent_action \u001b[38;5;129;01min\u001b[39;00m actions:\n\u001b[0;32m-> 1223\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_agent_action\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages/langchain/agents/agent.py:1245\u001b[0m, in \u001b[0;36mAgentExecutor._perform_agent_action\u001b[0;34m(self, name_to_tool_map, color_mapping, agent_action, run_manager)\u001b[0m\n\u001b[1;32m   1243\u001b[0m         tool_run_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_prefix\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1244\u001b[0m     \u001b[38;5;66;03m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[0;32m-> 1245\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[43mtool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43magent_action\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_run_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m     tool_run_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mtool_run_logging_kwargs()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages/langchain_core/tools.py:422\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    421\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(e)\n\u001b[0;32m--> 422\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    424\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(observation, color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages/langchain_core/tools.py:381\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m     parsed_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_input(tool_input)\n\u001b[1;32m    379\u001b[0m     tool_args, tool_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_args_and_kwargs(parsed_input)\n\u001b[1;32m    380\u001b[0m     observation \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 381\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    383\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(\u001b[38;5;241m*\u001b[39mtool_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_kwargs)\n\u001b[1;32m    384\u001b[0m     )\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_validation_error:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages/langchain_core/tools.py:588\u001b[0m, in \u001b[0;36mTool._run\u001b[0;34m(self, run_manager, *args, **kwargs)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc:\n\u001b[1;32m    580\u001b[0m     new_argument_supported \u001b[38;5;241m=\u001b[39m signature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m    584\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    585\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    586\u001b[0m         )\n\u001b[1;32m    587\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_argument_supported\n\u001b[0;32m--> 588\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m     )\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTool does not support sync\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: rate_resume_vs_job() missing 1 required positional argument: 'job_listing'"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke(input={'input':\"How goes my resume compare against this job listing?\",\n",
    "                                        'resume':long_resume,\n",
    "                                       'job_listing':job_text_senior_rh})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF DAY 06/24/24 -  \n",
    "\n",
    "```\n",
    "File /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages/langchain/chains/base.py:153, in Chain.invoke(self, input, config, **kwargs)\n",
    "    150 try:\n",
    "    151     self._validate_inputs(inputs)\n",
    "    152     outputs = (\n",
    "--> 153         self._call(inputs, run_manager=run_manager)\n",
    "    154         if new_arg_supported\n",
    "    155         else self._call(inputs)\n",
    "    156     )\n",
    "    158     final_outputs: Dict[str, Any] = self.prep_outputs(\n",
    "    159         inputs, outputs, return_only_outputs\n",
    "...\n",
    "--> 588         else self.func(*args, **kwargs)\n",
    "    589     )\n",
    "    590 raise NotImplementedError(\"Tool does not support sync\")\n",
    "\n",
    "TypeError: rate_resume_vs_job() missing 1 required positional argument: 'job_listing'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"stop here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Step 6: Use the Agent to Generate the Structured Response\n",
    "\n",
    "You can now use the agent to generate the structured response based on the resume and job listing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example resume and job listing\n",
    "resume = \"\"\"\n",
    "John Doe\n",
    "Data Scientist with 5 years of experience in data analytics and machine learning.\n",
    "Skills: Python, SQL, Machine Learning, Deep Learning.\n",
    "Education: M.Sc. in Computer Science.\n",
    "\"\"\"\n",
    "job_listing = \"\"\"\n",
    "We are looking for a Data Scientist with the following qualifications:\n",
    "- 5+ years of experience in data analytics.\n",
    "- Proficient in Python and SQL.\n",
    "- Experience with Machine Learning and Deep Learning.\n",
    "- M.Sc. or higher in Computer Science or related field.\n",
    "\"\"\"\n",
    "\n",
    "# Generate the structured response\n",
    "rating = agent.run(\"RateResume\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "matching_qualifications = agent.run(\"ListMatchingQualifications\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "missing_qualifications = agent.run(\"ListMissingQualifications\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "questions = agent.run(\"QuestionsForAdditionalInfo\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "\n",
    "# Output the results\n",
    "print(\"Rating:\")\n",
    "print(rating)\n",
    "print(\"\\nMatching Qualifications:\")\n",
    "print(matching_qualifications)\n",
    "print(\"\\nMissing Qualifications:\")\n",
    "print(missing_qualifications)\n",
    "print(\"\\nQuestions for Additional Info:\")\n",
    "\n",
    "\n",
    "# resume = \"\"\"\n",
    "# John Doe\n",
    "# Data Scientist with 5 years of experience in data analytics and machine learning.\n",
    "# Skills: Python, SQL, Machine Learning, Deep Learning.\n",
    "# Education: M.Sc. in Computer Science.\n",
    "# \"\"\"\n",
    "# job_listing = \"\"\"\n",
    "# We are looking for a Data Scientist with the following qualifications:\n",
    "# - 5+ years of experience in data analytics.\n",
    "# - Proficient in Python and SQL.\n",
    "# - Experience with Machine Learning and Deep Learning.\n",
    "# - M.Sc. or higher in Computer Science or related field.\n",
    "# \"\"\"\n",
    "\n",
    "# Generate the structured response\n",
    "rating = agent.run(\"RateResume\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "matching_qualifications = agent.run(\"ListMatchingQualifications\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "missing_qualifications = agent.run(\"ListMissingQualifications\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "questions = agent.run(\"QuestionsForAdditionalInfo\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "\n",
    "# Output the results\n",
    "print(\"Rating:\")\n",
    "print(rating)\n",
    "print(\"\\nMatching Qualifications:\")\n",
    "print(matching_qualifications)\n",
    "print(\"\\nMissing Qualifications:\")\n",
    "print(missing_qualifications)\n",
    "print(\"\\nQuestions for Additional Info:\")\n",
    "resume = \"\"\"\n",
    "John Doe\n",
    "Data Scientist with 5 years of experience in data analytics and machine learning.\n",
    "Skills: Python, SQL, Machine Learning, Deep Learning.\n",
    "Education: M.Sc. in Computer Science.\n",
    "\"\"\"\n",
    "job_listing = \"\"\"\n",
    "We are looking for a Data Scientist with the following qualifications:\n",
    "- 5+ years of experience in data analytics.\n",
    "- Proficient in Python and SQL.\n",
    "- Experience with Machine Learning and Deep Learning.\n",
    "- M.Sc. or higher in Computer Science or related field.\n",
    "\"\"\"\n",
    "\n",
    "# Generate the structured response\n",
    "rating = agent.run(\"RateResume\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "matching_qualifications = agent.run(\"ListMatchingQualifications\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "missing_qualifications = agent.run(\"ListMissingQualifications\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "questions = agent.run(\"QuestionsForAdditionalInfo\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "\n",
    "# Output the results\n",
    "print(\"Rating:\")\n",
    "print(rating)\n",
    "print(\"\\nMatching Qualifications:\")\n",
    "print(matching_qualifications)\n",
    "print(\"\\nMissing Qualifications:\")\n",
    "print(missing_qualifications)\n",
    "print(\"\\nQuestions for Additional Info:\")\n",
    "print(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Full Example Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here is the complete code for setting up and using the LangChain agent:\n",
    "\n",
    "```python\n",
    "import openai\n",
    "import os\n",
    "from langchain.agents import Tool, create_openai_functions_agent\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Initialize OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'your-openai-api-key'\n",
    "\n",
    "# Function to rate the resume against the job listing\n",
    "def rate_resume_vs_job(resume: str, job_listing: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    I need you to rate this resume against the following job listing out of 5 stars. Please provide a rating and a brief justification.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"gpt-4\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=150,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Function to list matching qualifications\n",
    "def list_matching_qualifications(resume: str, job_listing: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Identify and list the matching qualifications between the following resume and job listing.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"gpt-4\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=150,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Function to list missing qualifications\n",
    "def list_missing_qualifications(resume: str, job_listing: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Identify and list the missing qualifications in the following resume based on the job listing.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"gpt-4\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=150,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Function to list questions for additional information\n",
    "def questions_for_additional_info(resume: str, job_listing: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following resume and job listing, list questions that could help determine if there is additional information that could be added to the resume.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"gpt-4\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=150,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Define the tools\n",
    "rate_resume_tool = Tool(\n",
    "    name=\"RateResume\",\n",
    "    function=rate_resume_vs_job,\n",
    "    description=\"Rates the resume against the job listing and provides a justification.\"\n",
    ")\n",
    "\n",
    "matching_qualifications_tool = Tool(\n",
    "    name=\"ListMatchingQualifications\",\n",
    "    function=list_matching_qualifications,\n",
    "    description=\"Lists the matching qualifications between the resume and job listing.\"\n",
    ")\n",
    "\n",
    "missing_qualifications_tool = Tool(\n",
    "    name=\"ListMissingQualifications\",\n",
    "    function=list_missing_qualifications,\n",
    "    description=\"Lists the missing qualifications in the resume based on the job listing.\"\n",
    ")\n",
    "\n",
    "additional_info_questions_tool = Tool(\n",
    "    name=\"QuestionsForAdditionalInfo\",\n",
    "    function=questions_for_additional_info,\n",
    "    description=\"Lists questions to determine if there is additional information that could be added to the resume.\"\n",
    ")\n",
    "\n",
    "# Initialize the language model\n",
    "llm = OpenAI(model_name=\"gpt-4\")\n",
    "\n",
    "# Create the agent with the defined tools\n",
    "\n",
    "\n",
    "agent = create_openai_functions_agent(llm, [\n",
    "    rate_resume_tool,\n",
    "    matching_qualifications_tool,\n",
    "    missing_qualifications_tool,\n",
    "    additional_info_questions_tool\n",
    "])\n",
    "\n",
    "# Example resume and job listing\n",
    "resume = \"\"\"\n",
    "John Doe\n",
    "Data Scientist with 5 years of experience in data analytics and machine learning.\n",
    "Skills: Python, SQL, Machine Learning, Deep Learning.\n",
    "Education: M.Sc. in Computer Science.\n",
    "\"\"\"\n",
    "job_listing = \"\"\"\n",
    "We are looking for a Data Scientist with the following qualifications:\n",
    "- 5+ years of experience in data analytics.\n",
    "- Proficient in Python and SQL.\n",
    "- Experience with Machine Learning and Deep Learning.\n",
    "- M.Sc. or higher in Computer Science or related field.\n",
    "\"\"\"\n",
    "\n",
    "# Generate the structured response\n",
    "rating = agent.run(\"RateResume\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "matching_qualifications = agent.run(\"ListMatchingQualifications\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "missing_qualifications = agent.run(\"ListMissingQualifications\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "questions = agent.run(\"QuestionsForAdditionalInfo\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "\n",
    "# Output the results\n",
    "print(\"Rating:\")\n",
    "print(rating)\n",
    "print(\"\\nMatching Qualifications:\")\n",
    "print(matching_qualifications)\n",
    "print(\"\\nMissing Qualifications:\")\n",
    "print(missing_qualifications)\n",
    "print(\"\\nQuestions for Additional Info:\")\n",
    "print(questions)\n",
    "```\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This lesson demonstrates how to use LangChain to create an agent that can generate a structured response for a resume evaluation task. By defining custom tools and leveraging the power of OpenAI's GPT-4 model, you can control the structure of the returned response, ensuring that each part of the response is handled separately and effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOOKMARK: ~~05/31/24~~ 06/23/24\n",
    "- ~~Pivoted to CV project for job opportunity~~\n",
    "- [ ] Save the short tailored resume (resume separate from chat gpt conversation text.)\n",
    "- [ ] Feed resume through a second check to confirm there are no new words/tech/skills added.\n",
    "- [ ] (Optional) Examin the bullets and decide if the re-wording was bad or if additional re-wording is needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolutely, James! Let's focus on highlighting the most relevant experiences and skills from your extensive resume to align with the job listing for the Senior Data Scientist position at Robert Half. Here's a condensed, targeted version of your resume:\n",
      "\n",
      "---\n",
      "\n",
      "**James M. Irving, Ph.D.**  \n",
      "8222 Spadderdock Way, Laurel, MD, 20724 | (518) 322-6750 | james.irving.phd@gmail.com  \n",
      "LinkedIn: james-irving-phd | GitHub: https://github.com/jirvingphd  \n",
      "\n",
      "---\n",
      "\n",
      "### **Summary**\n",
      "\n",
      "Innovative data scientist with a robust background in neuroscience and extensive experience in applying advanced data science techniques to real-world problems. Proven track record in machine learning, data analysis, and model deployment, with a strong ability to communicate complex findings to non-technical stakeholders. Committed to leveraging data to drive business solutions and innovation.\n",
      "\n",
      "---\n",
      "\n",
      "### **Core Competencies**\n",
      "\n",
      "- Data Analysis & Statistical Modeling\n",
      "- Machine Learning & Predictive Modeling\n",
      "- Data Visualization & Dashboarding\n",
      "- Natural Language Processing (NLP)\n",
      "- Python Programming, SQL, MATLAB\n",
      "- Cloud Technologies: Azure Machine Learning, Azure Databricks\n",
      "- Big Data Technologies: Hadoop, Azure Data Lake, Azure Cosmos DB\n",
      "\n",
      "---\n",
      "\n",
      "### **Professional Experience**\n",
      "\n",
      "**Coding Dojo | Remote**  \n",
      "*Curriculum Writer - Data Science*  \n",
      "March 2023 - January 2024  \n",
      "- Developed and delivered advanced courses in Time Series Modeling, NLP, and Model Deployment.\n",
      "- Integrated cutting-edge technologies like APIs, Web Scraping, and Computer Vision into the curriculum.\n",
      "- Created and maintained a GitHub Organization for curriculum-related activities, solutions, and packages.\n",
      "\n",
      "*Data Science Instructor*  \n",
      "November 2021 - March 2023  \n",
      "- Achieved high Net Promoter Scores (NPS) exceeding 90% through engaging and interactive live lectures.\n",
      "- Automated administrative tasks, reducing student onboarding time by 99%.\n",
      "\n",
      "**Flatiron School | Remote**  \n",
      "*Data Science Instructor*  \n",
      "October 2019 - October 2021  \n",
      "- Mentored over 60 students, helping them transition into successful data science careers.\n",
      "- Developed and implemented the \"Flex\" boot camp program, refining instructional design and delivery methods.\n",
      "- Created and maintained student-progress-tracking Looker dashboards.\n",
      "\n",
      "**University of Maryland, School of Medicine | Baltimore, MD**  \n",
      "*Postdoctoral Research Fellow*  \n",
      "June 2015 - July 2017  \n",
      "- Led neuroscience research using advanced techniques such as in vivo optogenetics and electrophysiology recordings.\n",
      "- Developed custom analysis scripts in Matlab, enhancing data processing capabilities.\n",
      "- Mentored and guided a diverse team, fostering a collaborative learning environment.\n",
      "\n",
      "---\n",
      "\n",
      "### **Education**\n",
      "\n",
      "**Certificate of Completion, Data Science**  \n",
      "Flatiron School, Online (February 2019 - August 2019)  \n",
      "\n",
      "**Doctor of Philosophy, Neuroscience**  \n",
      "University of Maryland, Baltimore, MD (August 2009 - May 2015)  \n",
      "\n",
      "**Master of Science, Neuroscience**  \n",
      "Tulane University, New Orleans, LA (January 2008 - December 2008)  \n",
      "\n",
      "**Bachelor of Science, Neuroscience (Sociology Minor)**  \n",
      "Tulane University, New Orleans, LA (August 2004 - December 2007)  \n",
      "\n",
      "---\n",
      "\n",
      "### **Selected Data Science Projects**\n",
      "\n",
      "**NLP Analysis of Amazon Reviews + AI Recommendations**  \n",
      "- Conducted sentiment analysis on over 5 million Amazon reviews, achieving 95% accuracy in sentiment classification.\n",
      "- Designed and deployed a user-centric Streamlit dashboard for live sentiment predictions and trend analysis.\n",
      "\n",
      "**Recidivism Risk Assessment**  \n",
      "- Developed a predictive model using Gradient Boosted Trees to classify which released prisoners in Iowa are likely to return to crime, achieving over 70% accuracy.\n",
      "\n",
      "**Forecasting Stock Market Fluctuations with Trumps Tweets**  \n",
      "- Employed NLP and time series forecasting to predict S&P 500 price changes based on Trump's tweets, integrating multiple data sources and machine learning models.\n",
      "\n",
      "---\n",
      "\n",
      "### **Technical Skills**\n",
      "\n",
      "- **Programming:** Python, SQL (MySQL, SQLAlchemy), MATLAB\n",
      "- **Data Analysis:** ETL (numpy, pandas), AB Testing (scipy, statsmodels), Machine Learning (scikit-learn, Catboost, XGBoost)\n",
      "- **NLP:** nltk, spaCy, Tensorflow, HuggingFace transformers\n",
      "- **Visualization/Dashboarding:** Plotly/Dash, Tableau, Streamlit, Seaborn/Matplotlib, Looker\n",
      "- **Cloud Technologies:** Azure Machine Learning, Azure Databricks, Azure Data Lake, Azure Cosmos DB\n",
      "\n",
      "---\n",
      "\n",
      "### **Certifications**\n",
      "\n",
      "- [Include any relevant certifications, especially in Azure data services or advanced analytics, if applicable]\n",
      "\n",
      "---\n",
      "\n",
      "This version of your resume is tailored to highlight your most relevant experiences and skills for the Senior Data Scientist position at Robert Half. It focuses on your expertise in data science methodologies, machine learning, NLP, and your ability to work with cloud technologies and big data platforms, aligning with the job requirements.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(dict(input=resume_prompt, resume=long_resume, job=job_text_senior_rh))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Required citation of ONET\n",
    "```html\n",
    "<p style=\"text-align: center\"><a href=\"https://services.onetcenter.org/\" title=\"This site incorporates information from O*NET Web Services. Click to learn more.\"><img src=\"https://www.onetcenter.org/image/link/onet-in-it.svg\" style=\"width: 130px; height: 60px; border: none\" alt=\"O*NET in-it\"></a></p>\n",
    "<p>This site incorporates information from <a href=\"https://services.onetcenter.org/\">O*NET Web Services</a> by the U.S. Department of Labor, Employment and Training Administration (USDOL/ETA). O*NET&reg; is a trademark of USDOL/ETA.</p>\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGPT's Version of Agent Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/38d519b6-0803-4398-99ee-06f820153e54"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure the model correctly interprets the response format as part of the output and not additional input variables, we need to clarify the structure and constraints within the prompt. We'll use a clear delimiter to indicate that the model should generate the output in the specified JSON format.\n",
    "\n",
    "Here's how you can modify the functions and prompts to avoid confusion:\n",
    "\n",
    "### Step-by-Step Guide\n",
    "\n",
    "#### Step 1: Set Up the Environment\n",
    "\n",
    "Ensure you have the necessary packages installed:\n",
    "\n",
    "```bash\n",
    "pip install langchain openai\n",
    "```\n",
    "\n",
    "#### Step 2: Initialize the OpenAI API\n",
    "\n",
    "Set up your OpenAI API key:\n",
    "\n",
    "```python\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# Set up your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'your-openai-api-key'\n",
    "```\n",
    "\n",
    "#### Step 3: Define Functions with Clear JSON Output\n",
    "\n",
    "Modify the functions to produce JSON output with a clear indication that the format is part of the response, not additional variables.\n",
    "\n",
    "**Example Functions**:\n",
    "```python\n",
    "import json\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.parsers import OutputParser\n",
    "\n",
    "# Initialize the language model\n",
    "llm = OpenAI(model_name=\"gpt-4\")\n",
    "\n",
    "# Function to rate the resume against the job listing\n",
    "def rate_resume_vs_job(resume: str, job_listing: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Rate this resume against the following job listing out of 5 stars. Provide the rating and a brief justification in JSON format.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "\n",
    "    Response format:\n",
    "    {{\n",
    "        \"rating\": <number>,\n",
    "        \"justification\": \"<string>\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt))\n",
    "    return chain.run({})\n",
    "\n",
    "# Function to list matching qualifications\n",
    "def list_matching_qualifications(resume: str, job_listing: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Identify and list the matching qualifications between the following resume and job listing in JSON format.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "\n",
    "    Response format:\n",
    "    {{\n",
    "        \"matching_qualifications\": [\"<qualification1>\", \"<qualification2>\", ...]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt))\n",
    "    return chain.run({})\n",
    "\n",
    "# Function to list missing qualifications\n",
    "def list_missing_qualifications(resume: str, job_listing: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Identify and list the missing qualifications in the following resume based on the job listing in JSON format.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "\n",
    "    Response format:\n",
    "    {{\n",
    "        \"missing_qualifications\": [\"<qualification1>\", \"<qualification2>\", ...]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt))\n",
    "    return chain.run({})\n",
    "\n",
    "# Function to list questions for additional information\n",
    "def questions_for_additional_info(resume: str, job_listing: str, matching_qualifications: str, missing_qualifications: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following matching and missing qualifications, list questions that could help determine if there is additional information that could be added to the resume in JSON format.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "\n",
    "    Matching Qualifications:\n",
    "    {matching_qualifications}\n",
    "\n",
    "    Missing Qualifications:\n",
    "    {missing_qualifications}\n",
    "\n",
    "    Response format:\n",
    "    {{\n",
    "        \"questions\": [\"<question1>\", \"<question2>\", ...]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt))\n",
    "    return chain.run({})\n",
    "```\n",
    "\n",
    "#### Step 4: Define Tools for LangChain Agent\n",
    "\n",
    "Create tools that the LangChain agent can use to perform these tasks.\n",
    "\n",
    "```python\n",
    "from langchain.agents import Tool\n",
    "\n",
    "rate_resume_tool = Tool(\n",
    "    name=\"RateResume\",\n",
    "    function=rate_resume_vs_job,\n",
    "    description=\"Rates the resume against the job listing and provides a justification in JSON format.\"\n",
    ")\n",
    "\n",
    "matching_qualifications_tool = Tool(\n",
    "    name=\"ListMatchingQualifications\",\n",
    "    function=list_matching_qualifications,\n",
    "    description=\"Lists the matching qualifications between the resume and job listing in JSON format.\"\n",
    ")\n",
    "\n",
    "missing_qualifications_tool = Tool(\n",
    "    name=\"ListMissingQualifications\",\n",
    "    function=list_missing_qualifications,\n",
    "    description=\"Lists the missing qualifications in the resume based on the job listing in JSON format.\"\n",
    ")\n",
    "\n",
    "additional_info_questions_tool = Tool(\n",
    "    name=\"QuestionsForAdditionalInfo\",\n",
    "    function=questions_for_additional_info,\n",
    "    description=\"Lists questions to determine if there is additional information that could be added to the resume based on matching and missing qualifications in JSON format.\"\n",
    ")\n",
    "```\n",
    "\n",
    "#### Step 5: Create the Agent with JSON Output Parsing\n",
    "\n",
    "Initialize the language model and create an agent that uses the defined tools. Include the JSON output parser to handle the responses.\n",
    "\n",
    "```python\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "\n",
    "# Create a prompt template for the agent\n",
    "agent_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Given the resume and job listing, decide which task to perform:\n",
    "- RateResume: Rate the resume against the job listing and provide a justification.\n",
    "- ListMatchingQualifications: List the matching qualifications between the resume and job listing.\n",
    "- ListMissingQualifications: List the missing qualifications in the resume based on the job listing.\n",
    "- QuestionsForAdditionalInfo: List questions to determine if there is additional information that could be added to the resume based on matching and missing qualifications.\n",
    "Provide the name of the task followed by the appropriate inputs in the required format.\n",
    "\"\"\")\n",
    "\n",
    "# Create the agent with the defined tools and output parser\n",
    "agent = create_openai_functions_agent(llm, [\n",
    "    rate_resume_tool,\n",
    "    matching_qualifications_tool,\n",
    "    missing_qualifications_tool,\n",
    "    additional_info_questions_tool\n",
    "], prompt=agent_prompt, output_parser=OutputParser.from_json())\n",
    "```\n",
    "\n",
    "#### Step 6: Use the Agent to Generate the Structured Response\n",
    "\n",
    "You can now use the agent to generate the structured response based on the resume and job listing.\n",
    "\n",
    "```python\n",
    "# Example resume and job listing\n",
    "resume = \"\"\"\n",
    "John Doe\n",
    "Data Scientist with 5 years of experience in data analytics and machine learning.\n",
    "Skills: Python, SQL, Machine Learning, Deep Learning.\n",
    "Education: M.Sc. in Computer Science.\n",
    "\"\"\"\n",
    "job_listing = \"\"\"\n",
    "We are looking for a Data Scientist with the following qualifications:\n",
    "- 5+ years of experience in data analytics.\n",
    "- Proficient in Python and SQL.\n",
    "- Experience with Machine Learning and Deep Learning.\n",
    "- M.Sc. or higher in Computer Science or related field.\n",
    "\"\"\"\n",
    "\n",
    "# Generate the structured response\n",
    "rating_response = agent.run(\"RateResume\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "rating = json.loads(rating_response)\n",
    "print(\"Rating:\", rating['rating'])\n",
    "print(\"Justification:\", rating['justification'])\n",
    "\n",
    "matching_response = agent.run(\"ListMatchingQualifications\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "matching_qualifications = json.loads(matching_response)['matching_qualifications']\n",
    "print(\"\\nMatching Qualifications:\", matching_qualifications)\n",
    "\n",
    "missing_response = agent.run(\"ListMissingQualifications\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "missing_qualifications = json.loads(missing_response)['missing_qualifications']\n",
    "print(\"\\nMissing Qualifications:\", missing_qualifications)\n",
    "\n",
    "questions_response = agent.run(\"QuestionsForAdditionalInfo\", {\n",
    "    \"resume\": resume,\n",
    "    \"job_listing\": job_listing,\n",
    "    \"matching_qualifications\": matching_qualifications,\n",
    "    \"missing_qualifications\": missing_qualifications\n",
    "})\n",
    "questions = json.loads(questions_response)['questions']\n",
    "print(\"\\nQuestions for Additional Info:\", questions)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Full Example Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here is the complete code for setting up and using the LangChain agent with JSON output parsing:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Prompt must have input variable `agent_scratchpad`, but wasn't found. Found [] instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 141\u001b[0m\n\u001b[1;32m    131\u001b[0m agent_prompt \u001b[38;5;241m=\u001b[39m PromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124mGiven the resume and job listing, decide which task to perform:\u001b[39m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124m- RateResume: Rate the resume against the job listing and provide a justification.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124mProvide the name of the task followed by the appropriate inputs in the required format.\u001b[39m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# Create the agent with the defined tools and output parser\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_openai_functions_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrate_resume_tool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatching_qualifications_tool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmissing_qualifications_tool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_info_questions_tool\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent_prompt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, output_parser=JsonOutputParser())#OutputParser.from_json())\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages/langchain/agents/openai_functions_agent/base.py:304\u001b[0m, in \u001b[0;36mcreate_openai_functions_agent\u001b[0;34m(llm, tools, prompt)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create an agent that uses OpenAI function calling.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;124;03m        )\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_scratchpad\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m    302\u001b[0m     prompt\u001b[38;5;241m.\u001b[39minput_variables \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(prompt\u001b[38;5;241m.\u001b[39mpartial_variables)\n\u001b[1;32m    303\u001b[0m ):\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt must have input variable `agent_scratchpad`, but wasn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt found. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;241m.\u001b[39minput_variables\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m     )\n\u001b[1;32m    308\u001b[0m llm_with_tools \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mbind(functions\u001b[38;5;241m=\u001b[39m[convert_to_openai_function(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tools])\n\u001b[1;32m    309\u001b[0m agent \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    310\u001b[0m     RunnablePassthrough\u001b[38;5;241m.\u001b[39massign(\n\u001b[1;32m    311\u001b[0m         agent_scratchpad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: format_to_openai_function_messages(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;241m|\u001b[39m OpenAIFunctionsAgentOutputParser()\n\u001b[1;32m    318\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Prompt must have input variable `agent_scratchpad`, but wasn't found. Found [] instead."
     ]
    }
   ],
   "source": [
    "\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "from langchain.agents import Tool, create_openai_functions_agent\n",
    "# from langchain.llms import OpenAI\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "# from langchain.parsers import OutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "\n",
    "\n",
    "# Initialize OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'your-openai-api-key'\n",
    "\n",
    "# Initialize the language model\n",
    "# llm = OpenAI(model_name=\"gpt-4\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\")\n",
    "\n",
    "# Function to rate the resume against the job listing\n",
    "def rate_resume_vs_job(resume: str, job_listing: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Rate this resume against the following job listing out of 5 stars. Provide the rating and a brief justification in JSON format.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "\n",
    "    Response format:\n",
    "    {{\n",
    "        \"rating\": 5,\n",
    "        \"justification\": \"The resume perfectly matches the job requirements.\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt))\n",
    "    return chain.run({})\n",
    "\n",
    "# Function to list matching qualifications\n",
    "def list_matching_qualifications(resume: str, job_listing: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Identify and list the matching qualifications between the following resume and job listing in JSON format.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "\n",
    "    Response format:\n",
    "    {{\n",
    "        \"matching_qualifications\": [\"Python\", \"SQL\", \"Machine Learning\", \"Deep Learning\"]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt))\n",
    "    return chain.run({})\n",
    "\n",
    "# Function to list missing qualifications\n",
    "def list_missing_qualifications(resume: str, job_listing: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Identify and list the missing qualifications in\n",
    "\n",
    " the following resume based on the job listing in JSON format.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "\n",
    "    Response format:\n",
    "    {{\n",
    "        \"missing_qualifications\": [\"Experience with Big Data\"]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt))\n",
    "    return chain.run({})\n",
    "\n",
    "# Function to list questions for additional information\n",
    "def questions_for_additional_info(resume: str, job_listing: str, matching_qualifications: str, missing_qualifications: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following matching and missing qualifications, list questions that could help determine if there is additional information that could be added to the resume in JSON format.\n",
    "\n",
    "    Resume:\n",
    "    {resume}\n",
    "\n",
    "    Job Listing:\n",
    "    {job_listing}\n",
    "\n",
    "    Matching Qualifications:\n",
    "    {matching_qualifications}\n",
    "\n",
    "    Missing Qualifications:\n",
    "    {missing_qualifications}\n",
    "\n",
    "    Response format:\n",
    "    {{\n",
    "        \"questions\": [\"Do you have experience with Big Data?\", \"Have you worked on projects that involved large-scale data processing?\"]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt))\n",
    "    return chain.run({})\n",
    "\n",
    "# Define the tools\n",
    "rate_resume_tool = Tool(\n",
    "    \"RateResume\",\n",
    "    rate_resume_vs_job,\n",
    "    description=\"Rates the resume against the job listing and provides a justification in JSON format.\"\n",
    ")\n",
    "\n",
    "matching_qualifications_tool = Tool(\n",
    "    \"ListMatchingQualifications\",\n",
    "    list_matching_qualifications,\n",
    "    description=\"Lists the matching qualifications between the resume and job listing in JSON format.\"\n",
    ")\n",
    "\n",
    "missing_qualifications_tool = Tool(\n",
    "    \"ListMissingQualifications\",\n",
    "    list_missing_qualifications,\n",
    "    description=\"Lists the missing qualifications in the resume based on the job listing in JSON format.\"\n",
    ")\n",
    "\n",
    "additional_info_questions_tool = Tool(\n",
    "    \"QuestionsForAdditionalInfo\",\n",
    "    questions_for_additional_info,\n",
    "    description=\"Lists questions to determine if there is additional information that could be added to the resume based on matching and missing qualifications in JSON format.\"\n",
    ")\n",
    "\n",
    "# Create a prompt template for the agent\n",
    "agent_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Given the resume and job listing, decide which task to perform:\n",
    "- RateResume: Rate the resume against the job listing and provide a justification.\n",
    "- ListMatchingQualifications: List the matching qualifications between the resume and job listing.\n",
    "- ListMissingQualifications: List the missing qualifications in the resume based on the job listing.\n",
    "- QuestionsForAdditionalInfo: List questions to determine if there is additional information that could be added to the resume based on matching and missing qualifications.\n",
    "Provide the name of the task followed by the appropriate inputs in the required format.\n",
    "\"\"\")\n",
    "\n",
    "# Create the agent with the defined tools and output parser\n",
    "agent = create_openai_functions_agent(llm, [\n",
    "    rate_resume_tool,\n",
    "    matching_qualifications_tool,\n",
    "    missing_qualifications_tool,\n",
    "    additional_info_questions_tool\n",
    "], prompt=agent_prompt)#, output_parser=JsonOutputParser())#OutputParser.from_json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example resume and job listing\n",
    "resume = \"\"\"\n",
    "John Doe\n",
    "Data Scientist with 5 years of experience in data analytics and machine learning.\n",
    "Skills: Python, SQL, Machine Learning, Deep Learning.\n",
    "Education: M.Sc. in Computer Science.\n",
    "\"\"\"\n",
    "job_listing = \"\"\"\n",
    "We are looking for a Data Scientist with the following qualifications:\n",
    "- 5+ years of experience in data analytics.\n",
    "- Proficient in Python and SQL.\n",
    "- Experience with Machine Learning and Deep Learning.\n",
    "- M.Sc. or higher in Computer Science or related field.\n",
    "\"\"\"\n",
    "\n",
    "# Generate the structured response\n",
    "rating_response = agent.run(\"RateResume\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "rating = json.loads(rating_response)\n",
    "print(\"Rating:\", rating['rating'])\n",
    "print(\"Justification:\", rating['justification'])\n",
    "\n",
    "matching_response = agent.run(\"ListMatchingQualifications\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "matching_qualifications = json.loads(matching_response)['matching_qualifications']\n",
    "print(\"\\nMatching Qualifications:\", matching_qualifications)\n",
    "\n",
    "missing_response = agent.run(\"ListMissingQualifications\", {\"resume\": resume, \"job_listing\": job_listing})\n",
    "missing_qualifications = json.loads(missing_response)['missing_qualifications']\n",
    "print(\"\\nMissing Qualifications:\", missing_qualifications)\n",
    "\n",
    "questions_response = agent.run(\"QuestionsForAdditionalInfo\", {\n",
    "    \"resume\": resume,\n",
    "    \"job_listing\": job_listing,\n",
    "    \"matching_qualifications\": matching_qualifications,\n",
    "    \"missing_qualifications\": missing_qualifications\n",
    "})\n",
    "questions = json.loads(questions_response)['questions']\n",
    "print(\"\\nQuestions for Additional Info:\", questions)\n",
    "```\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "By clarifying the response format and using JSON parsing, you can ensure the language model generates structured outputs that are easier to handle and integrate into your application. This approach provides a robust way to manage and process complex interactions with the language model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dojo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
